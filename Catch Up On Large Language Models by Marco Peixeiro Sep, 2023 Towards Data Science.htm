<!DOCTYPE html>
<html class=" sldthtjw idc0_348" lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><!-- base href="https://towardsdatascience.com/catch-up-on-large-language-models-8daf784f46f8" --><style>body{margin-left:0;margin-right:0;margin-top:0}#bN015htcoyT__google-cache-hdr{background:#f8f9fa;font:13px arial,sans-serif;text-align:left;color:#202124;border:0;margin:0;border-bottom:1px solid #dadce0;line-height:16px;padding:16px 28px 24px 28px}#bN015htcoyT__google-cache-hdr *{display:inline;font:inherit;text-align:inherit;color:inherit;line-height:inherit;background:none;border:0;margin:0;padding:0;letter-spacing:0}#bN015htcoyT__google-cache-hdr a{text-decoration:none;color:#1a0dab;}#bN015htcoyT__google-cache-hdr a:hover{text-decoration:underline}#bN015htcoyT__google-cache-hdr a:visited{color:#681da8}#bN015htcoyT__google-cache-hdr div{display:block;margin-top:4px}#bN015htcoyT__google-cache-hdr b{font-weight:bold;display:inline-block;direction:ltr}</style></head><body data-new-gr-c-s-check-loaded="8.907.0" data-gr-ext-installed=""><div id="bN015htcoyT__google-cache-hdr"><div><span>To jest kopia z pamięci podręcznej Google adresu <a href="https://towardsdatascience.com/catch-up-on-large-language-models-8daf784f46f8">https://towardsdatascience.com/catch-up-on-large-language-models-8daf784f46f8</a>.</span>&nbsp;<span>Zdjęcie przedstawia stan strony z 18 Wrz 2023 03:17:40 GMT.</span>&nbsp;<span><a href="https://towardsdatascience.com/catch-up-on-large-language-models-8daf784f46f8">Aktualna strona</a> może wyglądać inaczej.</span>&nbsp;<a href="http://support.google.com/websearch/bin/answer.py?hl=pl&amp;p=cached&amp;answer=1687222"><span>Więcej informacji</span>.</a></div><div><span style="display:inline-block;margin-top:8px;margin-right:104px;white-space:nowrap"><span style="margin-right:28px"><span style="font-weight:bold">Pełna wersja</span></span><span style="margin-right:28px"><a href="http://webcache.googleusercontent.com/search?q=cache:https://towardsdatascience.com/catch-up-on-large-language-models-8daf784f46f8&amp;sca_esv=566281724&amp;strip=1&amp;vwsrc=0"><span>Wersja tekstowa</span></a></span><span style="margin-right:28px"><a href="http://webcache.googleusercontent.com/search?q=cache:https://towardsdatascience.com/catch-up-on-large-language-models-8daf784f46f8&amp;sca_esv=566281724&amp;strip=0&amp;vwsrc=1"><span>Wyświetl źródło</span></a></span></span></div><span style="display:inline-block;margin-top:8px;color:#70757a"><span>Wskazówka: aby szybko znaleźć wyszukiwane hasło na stronie, naciśnij <b>Ctrl+F</b> lub <b>⌘-F</b> (Mac) i użyj paska wyszukiwania.</span></span></div><div style="position:relative;"><title data-rh="true">Catch Up On Large Language Models | by Marco Peixeiro | Sep, 2023 | Towards Data Science</title><meta data-rh="true" charset="utf-8"><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-09-05T14:12:42.987Z"><meta data-rh="true" name="title" content="Catch Up On Large Language Models | by Marco Peixeiro | Sep, 2023 | Towards Data Science"><meta data-rh="true" property="og:title" content="Catch Up On Large Language Models"><meta data-rh="true" property="al:android:url" content="medium://p/8daf784f46f8"><meta data-rh="true" property="al:ios:url" content="medium://p/8daf784f46f8"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="If you are here, it means that like me you were overwhelmed by the constant flow of information, and hype posts surrounding large language models (LLMs). This article is my attempt at helping you…"><meta data-rh="true" property="og:description" content="A practical guide to large language models without the hype"><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/catch-up-on-large-language-models-8daf784f46f8"><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/catch-up-on-large-language-models-8daf784f46f8"><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:1200/0*0sgM1HGAs_IcVD2U"><meta data-rh="true" property="article:author" content="https://medium.com/@marcopeixeiro"><meta data-rh="true" name="author" content="Marco Peixeiro"><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" property="twitter:title" content="Catch Up On Large Language Models"><meta data-rh="true" name="twitter:site" content="@TDataScience"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/8daf784f46f8"><meta data-rh="true" property="twitter:description" content="A practical guide to large language models without the hype"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:1200/0*0sgM1HGAs_IcVD2U"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:label1" content="Reading time"><meta data-rh="true" name="twitter:data1" content="15 min read"><meta data-rh="true" name="twitter:tile:template:testing" content="2"><meta data-rh="true" name="twitter:tile:image" content="https://miro.medium.com/v2/resize:fit:1200/0*0sgM1HGAs_IcVD2U"><meta data-rh="true" name="twitter:tile:info1:icon" content="Person"><meta data-rh="true" name="twitter:tile:info1:text" content="Marco Peixeiro"><meta data-rh="true" name="twitter:tile:info2:icon" content="Calendar"><meta data-rh="true" name="twitter:tile:info2:text" content="Sep 5, 2023"><meta data-rh="true" name="twitter:cta" content="Read on Medium"><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/resize:fill:256:256/1*VzTUkfeGymHP4Bvav-T-lA.png"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@marcopeixeiro"><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/catch-up-on-large-language-models-8daf784f46f8"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/8daf784f46f8"><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F0*0sgM1HGAs_IcVD2U"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcatch-up-on-large-language-models-8daf784f46f8","dateCreated":"2023-09-05T10:02:41.832Z","datePublished":"2023-09-05T10:02:41.832Z","dateModified":"2023-09-09T18:16:26.089Z","headline":"Catch Up On Large Language Models - Towards Data Science","name":"Catch Up On Large Language Models - Towards Data Science","description":"If you are here, it means that like me you were overwhelmed by the constant flow of information, and hype posts surrounding large language models (LLMs). This article is my attempt at helping you…","identifier":"8daf784f46f8","author":{"@type":"Person","name":"Marco Peixeiro","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@marcopeixeiro"},"creator":["Marco Peixeiro"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":192,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:384\u002F1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fcatch-up-on-large-language-models-8daf784f46f8","isAccessibleForFree":"False","hasPart":{"@type":"WebPageElement","isAccessibleForFree":"False","cssSelector":".meteredContent"}}</script><style type="text/css" data-fela-rehydration="739" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="739" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{height:25px}.av{fill:rgba(41, 41, 41, 1)}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:#F9F9F9}.bb path{fill:#6B6B6B}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:#242424}.bk::placeholder{color:#6B6B6B}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:#F2F2F2}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.ds{margin-left:8px}.dt{color:#6B6B6B}.du{font-size:13px}.dv{height:100%}.el{color:#FFFFFF}.em{fill:#FFFFFF}.eo{background:rgba(102, 138, 170, 1)}.ep{border-color:rgba(102, 138, 170, 1)}.et:disabled{cursor:inherit !important}.eu:disabled{opacity:0.3}.ev:disabled:hover{background:rgba(102, 138, 170, 1)}.ew:disabled:hover{border-color:rgba(102, 138, 170, 1)}.ex{border-radius:99em}.ey{border-width:1px}.ez{border-style:solid}.fa{box-sizing:border-box}.fb{text-decoration:none}.fe{margin-right:32px}.ff{position:relative}.fg{fill:#6B6B6B}.fj{background:transparent}.fk svg{margin-left:4px}.fl svg{fill:#6B6B6B}.fn{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fo{position:absolute}.fv{margin:0 24px}.fz{background:rgba(255, 255, 255, 1)}.ga{border:1px solid #F2F2F2}.gb{box-shadow:0 1px 4px #F2F2F2}.gc{max-height:100vh}.gd{overflow-y:auto}.ge{left:0}.gf{top:calc(100vh + 100px)}.gg{bottom:calc(100vh + 100px)}.gh{width:10px}.gi{pointer-events:none}.go{margin-right:8px}.gp{max-width:728px}.gq{margin-right:4px}.gr{margin-top:2px}.gs{box-sizing:content-box}.gt{word-break:break-word}.gu{word-wrap:break-word}.gv:after{display:block}.gw:after{content:""}.gx:after{clear:both}.gy{line-height:1.23}.gz{letter-spacing:0}.ha{font-style:normal}.hb{font-weight:700}.hr{margin-top:0px}.hs{margin-bottom:-0.27em}.ht{line-height:1.394}.ij{@media all and (max-width: 551.98px):8px}.ik{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.il{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.im{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.in{@media all and (min-width: 1080px):16px}.it{align-items:baseline}.iu{width:48px}.iv{height:48px}.iw{border:2px solid rgba(255, 255, 255, 1)}.ix{z-index:0}.iy{box-shadow:none}.iz{border:1px solid rgba(0, 0, 0, 0.05)}.jb{margin-left:-12px}.jc{width:28px}.jd{height:28px}.je{z-index:1}.jf{width:24px}.jg{margin-bottom:2px}.jh{flex-wrap:nowrap}.ji{font-size:16px}.jj{line-height:24px}.jl{margin-left:2px}.jm{margin-top:1px}.jn{cursor:initial}.jo{margin:0 8px}.jp{display:inline}.jq{color:rgba(102, 138, 170, 1)}.jr{fill:rgba(102, 138, 170, 1)}.ju{flex:0 0 auto}.jx{flex-wrap:wrap}.ka{white-space:pre-wrap}.kb{overflow:hidden}.kc{max-height:20px}.kd{text-overflow:ellipsis}.ke{display:-webkit-box}.kf{-webkit-line-clamp:1}.kg{-webkit-box-orient:vertical}.kh{word-break:break-all}.kj{padding-left:8px}.kk{padding-right:8px}.ll> *{flex-shrink:0}.lm{overflow-x:scroll}.ln::-webkit-scrollbar{display:none}.lo{scrollbar-width:none}.lp{-ms-overflow-style:none}.lq{width:74px}.lr{flex-direction:row}.lu{-webkit-user-select:none}.lv{border:0}.lw{fill:rgba(117, 117, 117, 1)}.lz{outline:0}.ma{user-select:none}.mb> svg{pointer-events:none}.mk{cursor:progress}.ml{margin-left:4px}.mm{opacity:1}.mn{padding:4px 0}.mq{width:16px}.mr path{fill:#242424}.ms{padding:8px 2px}.mv svg path{fill:#6B6B6B}.mw svg{color:#6B6B6B}.nn{margin-left:auto}.no{margin-right:auto}.np{max-width:5472px}.nv{clear:both}.nx{cursor:zoom-in}.ny{z-index:auto}.oa{max-width:100%}.ob{height:auto}.oc{margin-top:10px}.od{text-align:center}.og{text-decoration:underline}.oh{line-height:1.58}.oi{letter-spacing:-0.004em}.oj{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.pc{margin-bottom:-0.46em}.pd{line-height:1.12}.pe{letter-spacing:-0.022em}.pf{font-weight:600}.py{margin-bottom:-0.28em}.qe{font-style:italic}.qi{list-style-type:disc}.qj{margin-left:30px}.qk{padding-left:0px}.qq{line-height:1.18}.re{margin-bottom:-0.31em}.rf{max-width:772px}.rg{max-width:1245px}.rh{max-width:908px}.ri{max-width:693px}.rj{max-width:1415px}.rk{max-width:818px}.rl{max-width:888px}.rm{max-width:820px}.rn{max-width:1416px}.ro{overflow-x:auto}.rp{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.rq{padding:32px}.rr{border:1px solid #E5E5E5}.rs{line-height:1.4}.rt{margin-top:-0.2em}.ru{margin-bottom:-0.2em}.rv{white-space:pre}.rw{min-width:fit-content}.rx{max-width:705px}.ry{max-width:691px}.rz{max-width:638px}.sa{max-width:866px}.sb{max-width:624px}.sc{max-width:305px}.sd{margin-bottom:26px}.se{margin-top:6px}.sf{margin-top:8px}.sg{padding:8px 16px}.sh{border-radius:100px}.si{transition:background 300ms ease}.sk{white-space:nowrap}.sl{border-top:none}.sr{height:52px}.ss{max-height:52px}.st{position:static}.sv{max-width:155px}.tb{margin-right:20px}.th{align-items:flex-end}.ti{width:76px}.tj{height:76px}.tk{border:2px solid #F9F9F9}.tl{height:72px}.tm{width:72px}.tn{margin-left:-16px}.to{width:36px}.tp{height:36px}.tq{width:auto}.tr{stroke:#F2F2F2}.ts{color:#F2F2F2}.tt{fill:#F2F2F2}.tu{background:#F2F2F2}.tv{border-color:#F2F2F2}.ub{font-weight:500}.uc{font-size:24px}.ud{line-height:30px}.ue{letter-spacing:-0.016em}.ul{margin-top:16px}.um{height:0px}.un{border-bottom:solid 1px #E5E5E5}.ut{margin-top:72px}.uu{padding:24px 0}.uv{margin-bottom:0px}.uw{margin-right:16px}.ux{display:inline-flex}.vd{margin-bottom:32px}.ve{margin-top:40px}.vf{align-items:stretch}.wp{flex-grow:0}.wv{display:grid}.ww{grid-template-columns:repeat(12, 1fr)}.wx{grid-template-rows:auto 1fr}.xi{grid-area:image}.xj{grid-area:content}.xp{border-radius:2px}.xq{aspect-ratio:2}.xr{object-fit:cover}.xs{object-position:50% 50%}.xy{height:20px}.xz{width:20px}.ya{padding-right:4px}.yv{padding-top:8px}.yw{max-height:40px}.yx{-webkit-line-clamp:2}.zn{margin-left:20px}.zo{justify-content:flex-end}.zp{flex:0 0 0}.zq{margin-top:32px}.zx{fill:#242424}.zy{background:0}.zz{border-color:#242424}.abc:disabled:hover{color:#242424}.abd:disabled:hover{fill:#242424}.abe:disabled:hover{border-color:#242424}.aby{padding-bottom:40px}.abz{padding-top:88px}.aca{margin-bottom:40px}.acb{margin-top:4px}.acc{border-right:3px solid #F9F9F9}.acd{z-index:3}.ace{z-index:2}.acf{margin-left:-24px}.acg{margin-left:-36px}.ach{border-radius:0 3px 3px 0}.aci{width:93px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.eq:hover{background:rgba(90, 118, 144, 1)}.er:hover{border-color:rgba(90, 118, 144, 1)}.es:hover{cursor:pointer}.fh:hover{color:#242424}.fi:hover{fill:#242424}.fm:hover svg{fill:#242424}.fp:hover{background-color:none}.ja:hover{background-color:rgba(0, 0, 0, 0.1)}.jk:hover{text-decoration:underline}.js:hover:not(:disabled){color:rgba(90, 118, 144, 1)}.jt:hover:not(:disabled){fill:rgba(90, 118, 144, 1)}.ly:hover{fill:rgba(8, 8, 8, 1)}.mo:hover{fill:#000000}.mp:hover p{color:#000000}.mt:hover:not(:disabled) svg path{fill:#000000}.mx:hover svg{color:#000000}.sj:hover{background-color:#F2F2F2}.tw:hover{background:#F2F2F2}.tx:hover{border-color:#F2F2F2}.ty:hover{cursor:wait}.tz:hover{color:#F2F2F2}.ua:hover{fill:#F2F2F2}.aba:hover{color:#000000}.abb:hover{border-color:#242424}.bc:focus-within path{fill:#242424}.lx:focus{fill:rgba(8, 8, 8, 1)}.mu:focus svg path{fill:#000000}.my:focus svg{color:#000000}.nz:focus{transform:scale(1.01)}.mc:active{border-style:none}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ee{font-size:14px}.ef{line-height:20px}.ek{padding:5px 12px}.fd{display:flex}.fu{margin-bottom:68px}.fy{max-width:680px}.gn{margin-top:24px}.ho{font-size:42px}.hp{line-height:52px}.hq{letter-spacing:-0.011em}.ig{font-size:22px}.ih{margin-top:0.92em}.ii{line-height:28px}.is{align-items:center}.kx{border-top:solid 1px #F2F2F2}.ky{border-bottom:solid 1px #F2F2F2}.kz{margin:32px 0 0}.la{padding:3px 8px}.lj> *{margin-right:24px}.lk> :last-child{margin-right:0}.mj{margin-top:0px}.nu{margin-top:56px}.oy{font-size:20px}.oz{margin-top:2em}.pa{line-height:32px}.pb{letter-spacing:-0.003em}.pu{font-size:24px}.pv{margin-top:1.95em}.pw{line-height:30px}.px{letter-spacing:-0.016em}.qd{margin-top:0.86em}.qh{margin-top:2.14em}.qp{margin-top:1.14em}.rb{margin-top:1.72em}.rc{line-height:24px}.rd{letter-spacing:0}.sq{margin-bottom:88px}.ta{display:inline-block}.tg{padding-top:72px}.uk{flex:0 0 auto}.us{margin-top:40px}.vc{margin:0}.vs{width:calc(100% + 32px)}.vt{margin-left:-16px}.vu{margin-right:-16px}.wl{padding-left:16px}.wm{padding-right:16px}.wn{flex-basis:50%}.wo{max-width:50%}.wu{padding-bottom:56px}.xg{gap:24px 0}.xh{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.xo{display:block}.xx{margin-bottom:16px}.yj{padding-bottom:16px}.yk{flex:1 0 auto}.yt{max-height:48px}.yu{-webkit-line-clamp:2}.zc{padding-top:16px}.zl{max-width:56%}.zm{flex:1 0 0}.zt{margin-bottom:24px}.zw{flex-direction:row}.abj{width:min-width}.abs{margin-left:16px}.abx{margin-top:96px}.acl{margin-bottom:56px}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.mi{margin-top:0px}.oe{margin-left:auto}.of{text-align:center}.sz{display:inline-block}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.mh{margin-top:0px}.sy{display:inline-block}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.mf{margin-top:0px}.mg{margin-right:0px}.sx{display:inline-block}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.dw{font-size:13px}.dx{line-height:20px}.eg{padding:0px 8px 1px}.fq{margin-bottom:4px}.gj{margin-top:8px}.hc{font-size:32px}.hd{line-height:38px}.he{letter-spacing:-0.014em}.hu{font-size:18px}.hv{margin-top:0.79em}.hw{line-height:24px}.io{align-items:flex-start}.jv{flex-direction:column}.jy{margin-bottom:2px}.kl{margin:24px -24px 0}.km{padding:0}.lb> *{margin-right:8px}.lc> :last-child{margin-right:24px}.ls{margin-left:0px}.md{margin-top:0px}.me{margin-right:0px}.mz{border:1px solid #F2F2F2}.na{border-radius:99em}.nb{padding:0px 16px 0px 12px}.nc{height:38px}.nd{align-items:center}.nf svg{margin-right:8px}.nq{margin-top:40px}.ok{margin-top:1.56em}.ol{line-height:28px}.om{letter-spacing:-0.003em}.pg{font-size:20px}.ph{margin-top:1.2em}.pi{letter-spacing:0}.pz{margin-top:0.67em}.ql{margin-top:1.34em}.qr{font-size:16px}.qs{margin-top:1.23em}.sm{margin-bottom:80px}.sw{display:inline-block}.tc{padding-top:48px}.uf{align-self:flex-end}.ug{flex:0 0 auto}.uo{margin-top:32px}.uy{margin:0}.vg{width:calc(100% + 24px)}.vh{margin-left:-12px}.vi{margin-right:-12px}.vv{padding-left:12px}.vw{padding-right:12px}.vx{flex-basis:100%}.vy{max-width:100%}.wq{padding-bottom:32px}.wy{gap:24px 0}.wz{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.xk{display:block}.xt{margin-bottom:16px}.yb{padding-bottom:16px}.yc{flex:1 0 auto}.yl{max-height:48px}.ym{-webkit-line-clamp:2}.yy{padding-top:16px}.zd{max-width:56%}.ze{flex:1 0 0}.abf{width:100%}.abk{margin-left:0}.abl{margin-top:16px}.abt{margin-top:72px}.ne:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.ec{font-size:14px}.ed{line-height:20px}.ej{padding:5px 12px}.fc{display:flex}.ft{margin-bottom:68px}.fx{max-width:680px}.gm{margin-top:24px}.hl{font-size:42px}.hm{line-height:52px}.hn{letter-spacing:-0.011em}.id{font-size:22px}.ie{margin-top:0.92em}.if{line-height:28px}.ir{align-items:center}.kt{border-top:solid 1px #F2F2F2}.ku{border-bottom:solid 1px #F2F2F2}.kv{margin:32px 0 0}.kw{padding:3px 8px}.lh> *{margin-right:24px}.li> :last-child{margin-right:0}.nt{margin-top:56px}.ou{font-size:20px}.ov{margin-top:2em}.ow{line-height:32px}.ox{letter-spacing:-0.003em}.pq{font-size:24px}.pr{margin-top:1.95em}.ps{line-height:30px}.pt{letter-spacing:-0.016em}.qc{margin-top:0.86em}.qg{margin-top:2.14em}.qo{margin-top:1.14em}.qy{margin-top:1.72em}.qz{line-height:24px}.ra{letter-spacing:0}.sp{margin-bottom:88px}.tf{padding-top:72px}.uj{flex:0 0 auto}.ur{margin-top:40px}.vb{margin:0}.vp{width:calc(100% + 32px)}.vq{margin-left:-16px}.vr{margin-right:-16px}.wh{padding-left:16px}.wi{padding-right:16px}.wj{flex-basis:50%}.wk{max-width:50%}.wt{padding-bottom:56px}.xe{gap:24px 0}.xf{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.xn{display:block}.xw{margin-bottom:16px}.yh{padding-bottom:16px}.yi{flex:1 0 auto}.yr{max-height:48px}.ys{-webkit-line-clamp:2}.zb{padding-top:16px}.zj{max-width:56%}.zk{flex:1 0 0}.zs{margin-bottom:24px}.zv{flex-direction:row}.abi{width:min-width}.abq{margin-left:16px}.abr{margin-top:0px}.abw{margin-top:96px}.ack{margin-bottom:56px}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:flex-end}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.ea{font-size:13px}.eb{line-height:20px}.ei{padding:0px 8px 1px}.fs{margin-bottom:68px}.fw{max-width:680px}.gl{margin-top:24px}.hi{font-size:42px}.hj{line-height:52px}.hk{letter-spacing:-0.011em}.ia{font-size:22px}.ib{margin-top:0.92em}.ic{line-height:28px}.iq{align-items:center}.kp{border-top:solid 1px #F2F2F2}.kq{border-bottom:solid 1px #F2F2F2}.kr{margin:32px 0 0}.ks{padding:3px 8px}.lf> *{margin-right:24px}.lg> :last-child{margin-right:0}.ns{margin-top:56px}.oq{font-size:20px}.or{margin-top:2em}.os{line-height:32px}.ot{letter-spacing:-0.003em}.pm{font-size:24px}.pn{margin-top:1.95em}.po{line-height:30px}.pp{letter-spacing:-0.016em}.qb{margin-top:0.86em}.qf{margin-top:2.14em}.qn{margin-top:1.14em}.qv{margin-top:1.72em}.qw{line-height:24px}.qx{letter-spacing:0}.so{margin-bottom:88px}.te{padding-top:72px}.ui{flex:0 0 auto}.uq{margin-top:40px}.va{margin:0}.vm{width:calc(100% + 28px)}.vn{margin-left:-14px}.vo{margin-right:-14px}.wd{padding-left:14px}.we{padding-right:14px}.wf{flex-basis:50%}.wg{max-width:50%}.ws{padding-bottom:56px}.xc{gap:24px 0}.xd{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.xm{display:block}.xv{margin-bottom:16px}.yf{padding-bottom:16px}.yg{flex:1 0 auto}.yp{max-height:48px}.yq{-webkit-line-clamp:2}.za{padding-top:16px}.zh{max-width:56%}.zi{flex:1 0 0}.zr{margin-bottom:24px}.zu{flex-direction:row}.abh{width:min-width}.abo{margin-left:16px}.abp{margin-top:0px}.abv{margin-top:96px}.acj{margin-bottom:56px}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dy{font-size:13px}.dz{line-height:20px}.eh{padding:0px 8px 1px}.fr{margin-bottom:4px}.gk{margin-top:8px}.hf{font-size:32px}.hg{line-height:38px}.hh{letter-spacing:-0.014em}.hx{font-size:18px}.hy{margin-top:0.79em}.hz{line-height:24px}.ip{align-items:flex-start}.jw{flex-direction:column}.jz{margin-bottom:2px}.kn{margin:24px 0 0}.ko{padding:0}.ld> *{margin-right:8px}.le> :last-child{margin-right:8px}.lt{margin-left:0px}.ng{border:1px solid #F2F2F2}.nh{border-radius:99em}.ni{padding:0px 16px 0px 12px}.nj{height:38px}.nk{align-items:center}.nm svg{margin-right:8px}.nr{margin-top:40px}.on{margin-top:1.56em}.oo{line-height:28px}.op{letter-spacing:-0.003em}.pj{font-size:20px}.pk{margin-top:1.2em}.pl{letter-spacing:0}.qa{margin-top:0.67em}.qm{margin-top:1.34em}.qt{font-size:16px}.qu{margin-top:1.23em}.sn{margin-bottom:80px}.td{padding-top:48px}.uh{flex:0 0 auto}.up{margin-top:32px}.uz{margin:0}.vj{width:calc(100% + 24px)}.vk{margin-left:-12px}.vl{margin-right:-12px}.vz{padding-left:12px}.wa{padding-right:12px}.wb{flex-basis:100%}.wc{max-width:100%}.wr{padding-bottom:32px}.xa{gap:24px 0}.xb{grid-template-areas:"image image image image image image image image image image image image" "content content content content content content content content content content content content"}.xl{display:block}.xu{margin-bottom:16px}.yd{padding-bottom:16px}.ye{flex:1 0 auto}.yn{max-height:48px}.yo{-webkit-line-clamp:2}.yz{padding-top:16px}.zf{max-width:56%}.zg{flex:1 0 0}.abg{width:100%}.abm{margin-left:0}.abn{margin-top:16px}.abu{margin-top:72px}.nl:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="print">.su{display:none}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.ki{max-height:none}</style><style type="text/css" data-fela-rehydration="739" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.nw{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="dt ag du be ak b am an ao ap aq ar as at s u j i d q dv z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F8daf784f46f8&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection" rel="noopener follow">Open in app<svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="ds"><path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path></svg></a><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8" rel="noopener follow">Sign In</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/" rel="noopener follow"><svg viewBox="0 0 1043.63 592.71" class="au av"><g data-name="Layer 2"><g data-name="Layer 1"><path d="M588.67 296.36c0 163.67-131.78 296.35-294.33 296.35S0 460 0 296.36 131.78 0 294.34 0s294.33 132.69 294.33 296.36M911.56 296.36c0 154.06-65.89 279-147.17 279s-147.17-124.94-147.17-279 65.88-279 147.16-279 147.17 124.9 147.17 279M1043.63 296.36c0 138-23.17 249.94-51.76 249.94s-51.75-111.91-51.75-249.94 23.17-249.94 51.75-249.94 51.76 111.9 51.76 249.94"></path></g></g></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search Medium"></div></div></div><div class="h k w fc fd"><div class="fe ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story" rel="noopener follow"><div class="be b bf z dt ff fg ab q fh fi"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg><div class="ds l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fe ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" href="https://medium.com/search" rel="noopener follow"><div class="be b bf z dt ff fg ab q fh fi"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Search"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div></a></div></div><div class="fe h k j"><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ec ed ej ee ef ek el em eo ep eq er es et eu ev ew ex ey ez fa bl fb" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8" rel="noopener follow">Sign In</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ax fj am ab q ao fk fl fm" aria-label="user options menu" data-testid="headerUserIcon"><div class="l ff"><img alt="" class="l fa bx by bz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20dmbNkD5D-u45r44go_cf0g.png" loading="lazy" role="presentation" width="32" height="32"><div class="fn bx l by bz fo n ax fp"></div></div><svg width="12px" height="12px" viewBox="0 0 15 15"><path d="M3.85 5.15a.5.5 0 0 0-.7.7l4.35 4.36 4.35-4.36a.5.5 0 1 0-.7-.7L7.5 8.79 3.85 5.15z" fill-rule="evenodd"></path></svg></button></div></div></div><div class="l"><div class="fq fr fs ft fu l"><div class="ab ca"><div class="ch bg fv fw fx fy"></div></div><article class="meteredContent"><div class="l"><div class="l"><span class="l"></span><section><div><div class="fo ge gf gg gh gi"></div><div><div class="speechify-ignore l"><div class="gj gk gl gm gn l"></div><div class="ab ca"><div class="cp ds go bg gp ch l"></div></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="ck l"><div class="gs ab"><div class="bl" aria-hidden="false"><button class="l ax ao am" aria-label="Member-only story"><div class="h k j i d"><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div><div class="s u w fc fd q"><svg width="16" height="16" viewBox="0 0 20 20" fill="none" class="gq gr"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg><p class="be b bf z dt">Member-only story</p></div></button></div></div></div></div></div></div></div><div class="gt gu gv gw gx"><div class="ab ca"><div class="ch bg fv fw fx fy"><div><h1 id="2e03" class="pw-post-title gy gz ha be hb hc hd he hf hg hh hi hj hk hl hm hn ho hp hq hr hs bj" data-testid="storyTitle">Catch Up On Large Language Models</h1></div><div><h2 id="b445" class="pw-subtitle-paragraph ht gz ha be b hu hv hw hx hy hz ia ib ic id ie if ig ih ii cp dt">A practical guide to large language models without the hype</h2><div class="ij ik il im in"><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="io ip iq ir is ab"><div><div class="ab it"><a href="https://medium.com/@marcopeixeiro" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="l iu iv bx iw ix"><div class="l ff"><img alt="Marco Peixeiro" class="l fa bx dc dd cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25200HKbgLGe-BeQE3o240uafw_003.jpg" loading="lazy" data-testid="authorPhoto" width="44" height="44"><div class="iy bx l dc dd fo n iz ja"></div></div></div></div></div></a><a href="https://towardsdatascience.com/" rel="noopener follow"><div class="jb ab ff"><div><div class="bl" aria-hidden="false"><div class="l jc jd bx iw je"><div class="l ff"><img alt="Towards Data Science" class="l fa bx bq jf cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20CJe3891yB1A1mzMdqemkdg.jpg" loading="lazy" data-testid="publicationPhoto" width="24" height="24"><div class="iy bx l bq jf fo n iz ja"></div></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="jg ab q"><div class="ab q jh"><div class="ab q"><div><div class="bl" aria-hidden="false"><p class="be b ji jj bj"><a class="af ag ah ai aj ak al am an ao ap aq ar jk" data-testid="authorName" href="https://medium.com/@marcopeixeiro" rel="noopener follow">Marco Peixeiro</a></p></div></div></div><div class="jl jm l"><div class="ab jn"><div class="ab"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M15.16 8c0 .65-.46 1.14-.86 1.57-.23.25-.47.5-.56.72-.1.22-.09.55-.1.88 0 .6-.01 1.3-.48 1.78-.48.48-1.16.5-1.75.5-.32 0-.65.01-.86.1-.2.07-.46.33-.7.57-.42.41-.9.88-1.54.88s-1.12-.47-1.54-.88a2.87 2.87 0 0 0-.7-.58c-.22-.09-.54-.08-.87-.09-.59 0-1.27-.02-1.74-.5s-.48-1.17-.49-1.78c0-.33-.01-.67-.1-.88-.07-.2-.32-.47-.55-.71-.4-.44-.87-.93-.87-1.58s.46-1.14.87-1.58c.23-.24.47-.5.56-.71.09-.22.08-.55.09-.88 0-.6.02-1.3.49-1.78s1.15-.5 1.74-.5c.33 0 .66-.01.86-.1.2-.08.47-.33.7-.57.43-.41.91-.88 1.55-.88.63 0 1.12.47 1.54.88.24.24.49.48.7.58.22.09.54.08.86.09.6 0 1.27.02 1.75.5.47.48.48 1.17.49 1.78 0 .33 0 .67.09.88.08.2.33.47.56.71.4.44.86.93.86 1.58z" fill="#437AFF"></path><path d="M7.33 10.5c.2 0 .38.08.52.22.13.14.21.33.21.53 0 .07.03.13.07.18a.24.24 0 0 0 .35 0 .25.25 0 0 0 .07-.18c0-.2.08-.39.22-.53a.73.73 0 0 1 .52-.22h1.96c.13 0 .25-.05.34-.15a.5.5 0 0 0 .15-.35V6a.5.5 0 0 0-.15-.35.48.48 0 0 0-.34-.15H9.78c-.33 0-.64.13-.87.37-.23.23-.36.55-.36.88v2.5c0 .07-.02.13-.07.18a.24.24 0 0 1-.35 0 .25.25 0 0 1-.07-.18v-2.5c0-.33-.13-.65-.36-.88a1.21 1.21 0 0 0-.86-.37H5.37a.48.48 0 0 0-.35.15.5.5 0 0 0-.14.35v4c0 .13.05.26.14.35.1.1.22.15.35.15h1.96z" fill="#fff"></path></svg></div></div></div><span class="jo jp" aria-hidden="true"><span class="be b bf z dt">·</span></span><p class="be b ji jj dt"><span><a class="jq jr ah ai aj ak al am an ao ap aq ar eu js jt" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l ju"><span class="be b bf z dt"><div class="ab cm jv jw jx"><div class="jy jz ab"><div class="be b bf z dt ab ka"><span class="gq l ju">Published in</span><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" data-testid="publicationName" href="https://towardsdatascience.com/" rel="noopener follow"><p class="be b bf z kb kc kd ke kf kg kh ki bj">Towards Data Science</p></a></div></div></div><div class="h k"><span class="jo jp" aria-hidden="true"><span class="be b bf z dt">·</span></span></div></div><span class="be b bf z dt"><div class="ab ae"><span data-testid="storyReadTime">15 min read</span><div class="kj kk l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dt">·</span></span></div><span data-testid="storyPublishDate">Sep 5</span></div></span></div></span></div></div></div><div class="ab co kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la"><div class="h k w fc fd q"><div class="lq l"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8daf784f46f8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div></div><div><div class="bl" aria-hidden="false"><button class="ao lv mm mn ab q fg mo mp" aria-label="responses" data-testid="headerResponseButton"><svg width="24" height="24" viewBox="0 0 24 24" class="hr"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">2</span></p></button></div></div></div><div class="ab q lb lc ld le lf lg lh li lj lk ll lm ln lo lp"><div class="mq k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8daf784f46f8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af fg ah ai aj ak al ms an ao ap eu mt mu mv"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div></div><div class="fa ux cm"><div class="l ae"><div class="ab ca"><div class="uy uz va vb vc oa ch bg"><div class="ab"><div class="bl bg" aria-hidden="false"><div><div class="bl" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af fg ah ai aj ak al ms an ao ap eu mw mx mp my mz na nb nc s nd ne nf ng nh ni nj u nk nl nm"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fg ah ai aj ak al ms an ao ap eu mw mx mp my mz na nb nc s nd ne nf ng nh ni nj u nk nl nm"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Share</p></div></button></div></div></div></div></div></div></div></div></div><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no np"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_006.jpg 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%200sgM1HGAs_IcVD2U.jpg 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_003.jpg 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_007.jpg 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_004.jpg 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_002.jpg 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_005.jpg 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_006.jpg 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%200sgM1HGAs_IcVD2U.jpg 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_003.jpg 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_007.jpg 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_004.jpg 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_002.jpg 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%25200sgM1HGAs_IcVD2U_005.jpg 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="eager" role="presentation" width="700" height="467"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">Photo by <a class="af og" href="https://unsplash.com/@kris_ricepees?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Gary Bendig</a> on <a class="af og" href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="a456" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">If you are here, it means that like me you were overwhelmed by the constant flow of information, and hype posts surrounding <strong class="oj hb">large language models</strong> (LLMs).</p><p id="5d3d" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">This
 article is my attempt at helping you catch up on the subject of large 
language models without the hype. After all, it is a transformative 
technology, and I believe it is important for us to understand it, 
hopefully making you curious to learn even more and build something with
 it.</p><p id="2881" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the following sections, we will define what LLMs are and how they work,
 of course covering the Transformer architecture. We also explore the 
different methods of training LLMs and conclude the article with a 
hands-on project where we use Flan-T5 for sentiment analysis using 
Python.</p><p id="72ef" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Let’s get started!</p><h1 id="cd3e" class="pd pe ha be pf pg ph hw pi pj pk hz pl pm pn po pp pq pr ps pt pu pv pw px py bj">LLMs and generative AI: are they the same thing?</h1><p id="cf4d" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Generative AI is a subset of machine learning that focuses on models who’s primary function is to generate <em class="qe">something</em>: text, images, video, code, etc.</p><p id="1d26" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Generative
 models train on enormous amounts of data created by humans to learn 
patterns and structure which allow them to create new data.</p><p id="6699" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Examples of generative models include:</p><ul class=""><li id="557f" class="oh oi ha oj b hu ok ol om hx on oo op oq qf os ot ou qg ow ox oy qh pa pb pc qi qj qk bj"><strong class="oj hb">Image generation</strong>: DALL-E, Midjourney</li><li id="5b28" class="oh oi ha oj b hu ql ol om hx qm oo op oq qn os ot ou qo ow ox oy qp pa pb pc qi qj qk bj"><strong class="oj hb">Code generation</strong>: OpenAI Codex</li><li id="6009" class="oh oi ha oj b hu ql ol om hx qm oo op oq qn os ot ou qo ow ox oy qp pa pb pc qi qj qk bj"><strong class="oj hb">Text generation</strong>: GPT-3, Flan-T5, LLaMA</li></ul><p id="4441" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Large
 language models are part of the generative AI landscape, since they 
take an input text and repeatedly predict the next word until the output
 is complete.</p><p id="0960" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">However,
 as language models grew larger, they were able to perform other tasks 
in natural language processing, like summarization, sentiment analysis, 
named entity recognition, translation and more.</p><p id="7f42" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">With that in mind, let’s now focus our attention on how LLMs work.</p><h1 id="bf72" class="pd pe ha be pf pg ph hw pi pj pk hz pl pm pn po pp pq pr ps pt pu pv pw px py bj">How LLMs work</h1><p id="482a" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">One
 of the reasons why we now have large language models is because of the 
seminal work of Google and University of Toronto when they released the 
paper <a class="af og" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">Attention Is All You Need</a> in 2017.</p><p id="6c51" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">This paper introduced the <strong class="oj hb">Transformer</strong> architecture, which is behind the LLMs we know and use today.</p><p id="3706" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">This
 architecture unlocked large scale models, making it possible to train 
very large models on multiple GPUs, and the models are able to process 
the inputs in parallel, giving them the opportunity to treat very large 
sequences of data.</p><h2 id="e2b0" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Overview of the Transformer architecture</h2><p id="7596" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">The
 following is meant to be a high-level overview of the Transformer 
architecture. There are many resources that dive deeper into it, but the
 goal here is just to understand the way it works so we can understand 
how different LLMs specialize in different tasks.</p><p id="339f" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">At any time, for more details, I suggest you read the <a class="af og" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>.</p><p id="ba14" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">So, let’s start with a simplified visualization of the Transformer architecture.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rf"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_004.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20R6-UardPkvP1qGuwuZYIxA.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_007.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_006.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_005.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_003.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_003.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_006.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_005.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_002.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_004.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20R6-UardPkvP1qGuwuZYIxA.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_007.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="1075"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">A simplified visualization of the Transformer architecture. Image by the author.</figcaption></figure><p id="8f06" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">From
 the figure above, we can see that the main components of the 
Transformer are the encoder and decoder. Inside each, we also find the <strong class="oj hb">attention</strong> component.</p><p id="64d2" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Let’s explore each component in more detail to understand how the Transformer architecture works.</p><h2 id="a633" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Tokenize the inputs</h2><p id="801f" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">We know LLMs work with text, but computers work with numbers, not letters. Therefore, the input must be <em class="qe">tokenized</em>.</p><p id="d199" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Tokenization is the process in which words of a sentence are represented as numbers.</p><p id="007a" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Basically,
 every possible word a model can work with is in a dictionary with a 
number associated to it. With tokenization, we can retrieve the number 
associated with the word, to represent a sentence as a sequence of 
numbers, as shown below.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rg"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_003.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20yeSEOW_WS0Cv5De_rUwpTQ.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_006.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_007.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_004.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_005.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_002.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_004.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_007.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_005.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20yeSEOW_WS0Cv5De_rUwpTQ.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_003.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520yeSEOW_WS0Cv5De_rUwpTQ_006.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="484"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">Example of tokenization. The sentence is tokenized and then sent to the embedding of the Transformer. Image by the author.</figcaption></figure><p id="1279" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the figure above, we see an example of how the sentence “It rained this
 morning” can be tokenized before being set to the embedding layer of 
the Transformer.</p><p id="690d" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Note
 that there are many ways of tokenizing a sentence. In the example 
above, the tokenizer can represents parts of a word, which is why <em class="qe">rained</em> is separated into <em class="qe">rain </em>and <em class="qe">ed</em>. Other tokenizers would have a number for full words only.</p><h2 id="9fd1" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">The word embedding layer</h2><p id="2c76" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">At this point, we have a series of numbers that represent words, but how can the computer understand their meaning?</p><p id="7adc" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">This is achieved by the word embedding layers.</p><p id="8b01" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Word
 embedding is a learned representation of words, such that words with a 
similar meaning will have a similar representation. The model will learn
 different properties of words and represent them in a fixed space, 
where each axis can represent the property of a word.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rh"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_003.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%201jCTO4aexx_rlTIByr8TTw.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_007.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_006.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_005.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_004.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_005.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%201jCTO4aexx_rlTIByr8TTw.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_003.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_007.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_004.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_002.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25201jCTO4aexx_rlTIByr8TTw_006.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="623"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">Visualization
 of word embeddings. We can see that “morning” and “sunrise” have a 
similar representation since the angle in the 3D space is smaller. 
Similarly, “rain” and “thunder” are closer to one another. Image by the 
author.</figcaption></figure><p id="edc7" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the figure above, we can see how a 3D word embedding can look like. We 
see that “morning” and “sunrise” are closer to one another, and 
therefore have a similar representation. This can be can be computed 
using cosine similarity.</p><p id="0f7a" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">On the other hand, “rain” and “thunder” are close to each other, and far from “morning” and “sunrise”.</p><p id="70f3" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Now,
 we can only show a 3D space, but in reality, embeddings can have 
hundreds of dimensions. In fact, the original Transformer architecture 
used an embedding space of 512 dimensions. This means that the model 
could learn 512 different properties of words to represent them in a 
space of 512 dimensions.</p><h2 id="00ee" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">What about word order?</h2><p id="e761" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">You may have noticed that by representing words in embeddings, we lose their order in the sentence.</p><p id="aef1" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Of
 course, with natural language, word order is very important, and so 
that’s why we use positional encoding, so the model knows the order of 
the words in a sentence.</p><p id="f865" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">It is the combination of the word embeddings and the positional encoding that gets sent to the encoder.</p><h2 id="7c1f" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Inside the encoder</h2><p id="1f71" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Our inputs travel inside the encoder where they will go through the <strong class="oj hb">self-attention</strong> mechanism.</p><p id="5351" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">This
 is where the model can learn the dependencies between each token in a 
sentence. It learns the importance of each word in relation to all other
 words in a sentence.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div class="nn no ri"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_004.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2067N0T5Gl0WsShGMtU8Dcyg.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_005.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_003.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_007.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_006.webp 1386w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 693px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_003.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_002.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2067N0T5Gl0WsShGMtU8Dcyg.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_005.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_004.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_007.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252067N0T5Gl0WsShGMtU8Dcyg_006.png 1386w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 693px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="693" height="433"></picture></div><figcaption class="oc od gp nn no oe of be b bf z dt">Example
 of an attention map for the word “rained”. The stroke width is 
representative of the importance. Here, we can see that “rained” is 
strongly connected to “this” and “morning”. Image by the author.</figcaption></figure><p id="f7bd" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the figure above, we have a stylized example of an attention map for 
the word “rained”. The stroke width represents the importance.</p><p id="961c" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 this example, we can see that self-attention captures the importance of
 “rained” with “this” and “morning”, meaning that it understands the 
context of this sentence.</p><p id="7a69" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">While
 this example remains simple, since we have a very short sentence, the 
self-attention mechanism works very well on longer sentences, 
effectively capturing context and the overall meaning of a sentence.</p><p id="5c17" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Furthermore, the model does not have a single attention head. In fact, it has multiple attention heads, also called <em class="qe">multi-headed self-attention</em>, where each head can learn a different aspect of language.</p><p id="b263" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">For example, in the paper <a class="af og" href="https://arxiv.org/pdf/1706.03762.pdf" rel="noopener ugc nofollow" target="_blank">Attention Is All You Need</a>, the authors found that one head was involved in <em class="qe">anaphora resolution</em>, which is identifying the link between an entity and its repeated references.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rj"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_005.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20NNf9gN5H9oa7g_Eevf0AUw.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_006.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_007.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_003.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_004.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_003.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_004.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20NNf9gN5H9oa7g_Eevf0AUw.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_007.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_006.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_002.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520NNf9gN5H9oa7g_Eevf0AUw_005.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="95"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">Example of anaphora resolution. Here, the word “keys” is referenced again in the sentence as “they”. Image by the author.</figcaption></figure><p id="7fc3" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Above,
 we see an example of anaphora resolution, where the word “keys” is 
later referenced as “they”, and so one attention head can specialize in 
identifying those links.</p><p id="68f6" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Note that we do not decide what aspect of language each attention head will learn.</p><p id="aa31" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">At this point, the model has a deep representation of the structure of meaning of a sentence. This is sent to the decoder.</p><h2 id="22b1" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Inside the decoder</h2><p id="4afe" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">The decoder accepts a deep representation of the input tokens. This informs the self-attention mechanism inside the decoder.</p><p id="7751" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">As a reminder, here is the Transformer architecture again, so we can remember what it looks like.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rf"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_004.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20R6-UardPkvP1qGuwuZYIxA.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_007.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_006.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_005.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_003.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_003.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_006.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_005.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_002.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_004.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20R6-UardPkvP1qGuwuZYIxA.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520R6-UardPkvP1qGuwuZYIxA_007.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="1075"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">A simplified visualization of the Transformer architecture. Image by the author.</figcaption></figure><p id="00ab" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">A <strong class="oj hb">start-of-sequence</strong> token is inserted as an input of the decoder, to signal it to start generating new tokens.</p><p id="51ed" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">New
 tokens are generated according to the understanding of the input 
sequence generated by the encoder and its self-attention mechanism.</p><p id="e0a5" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the figure above, we can see that the output of the decoder gets sent 
to a softmax layer. This generates a vector of probabilities for each 
possible token. The one with the largest probability is then output by 
the model.</p><p id="f063" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">That output token is then sent back to the embeddings as an input to the decoder, until an <strong class="oj hb">end-of-sequence</strong> token is generated by the model. At that point, the output sequence is complete.</p><p id="545a" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">This
 concludes the basic architecture behind large language models. With the
 Transformer architecture and its ability to process data in parallel, 
it was possible to train models on huge amounts of data, making LLMs a 
reality.</p><p id="da16" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Now,
 there is more to this, as LLMs do not all use the full Transformer 
architecture, and that influences the way they are trained. Let’s 
explore this in more detail.</p><h1 id="34f3" class="pd pe ha be pf pg ph hw pi pj pk hz pl pm pn po pp pq pr ps pt pu pv pw px py bj">How LLMs are trained</h1><p id="bf67" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">We
 have seen the underlying mechanisms that power large language models, 
and as mentioned, not all models use the full Transformer architecture.</p><p id="9974" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In fact, some models may use the encoder portion only, while others use the decoder portion only.</p><p id="1c04" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">This means that the models are also trained differently and will therefore specialize in particular tasks.</p><h2 id="d70e" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Encoder-only models</h2><p id="0eab" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Encoder-only models, also called <strong class="oj hb">autoencoding</strong> models are best suited for tasks like sentiment analysis, named entity recognition, and word classification</p><p id="0b56" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Popular examples of autoencoding models are BERT and ROBERTA.</p><p id="8ed3" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Those models are trained using <strong class="oj hb">masked language modeling</strong>
 (MLM). With that training method, words in an input sentence are 
randomly masked, and the objective of the model is then to reconstruct 
the original text.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rk"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_004.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20wt6YLLnOl_bLCFiUUjzaGw.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_005.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_007.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_006.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_003.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_003.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_004.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_002.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_007.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_006.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520wt6YLLnOl_bLCFiUUjzaGw_005.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20wt6YLLnOl_bLCFiUUjzaGw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="718"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">Illustrating
 masked language modeling (MLM) for autoencoding models. Here, a random 
word was masked in the input sentence, and the model must reconstruct 
the original sentence. Image by the author.</figcaption></figure><p id="fc39" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the figure above, we can see what masked language modeling looks like. A
 word is hidden and the sentence is fed to the model, which must then 
learn to predict the right word to get the correct original sentence.</p><p id="1486" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">With that method, autoencoding models develop <strong class="oj hb">bidrectional context</strong>, since they see what precedes and follows the token they must predict, and not just what comes before.</p><p id="d033" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Again,
 in the figure above, the model sees “it rained” and “morning”, so it 
sees both the beginning and the end of the sentence, allowing it to 
predict the word “this” to reconstruct the sentence correctly.</p><p id="a528" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Note that with autoencoding models, the input and output sequences have the same length.</p><h2 id="d4c1" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Decoder-only models</h2><p id="b28c" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Decoder-only models are also called <em class="qe">autoregressive </em>models. These models are best suited for text generation, but new functions arise when the models get very large.</p><p id="6177" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Example of autoregressive models are GPT and BLOOM.</p><p id="89fc" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">These models are trained using <strong class="oj hb">causal language modeling</strong>
 (CLM). With causal language modeling, the model only sees the tokens 
preceding the mask, meaning that it does not see the end of the 
sequence.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rl"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_003.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20aKCJpE4rEvP8Gg4MhweBeA.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_006.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_007.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_004.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_005.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_007.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_006.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_005.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_003.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_002.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520aKCJpE4rEvP8Gg4MhweBeA_004.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20aKCJpE4rEvP8Gg4MhweBeA.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="661"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">Illustrating
 causal language modeling. Here, the model only sees the tokens leading 
to the mask. Then, it must infer the next tokens until the sentence is 
complete. Image by the author.</figcaption></figure><p id="d500" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">As
 we see above, with causal language modeling, the model only sees the 
tokens leading to the mask, and not what comes after. Then, it must 
predict the next tokens until the sentence is complete.</p><p id="8976" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the example above, the model would output “this”, and that token would 
be fed back as an input, so the model can then predict “morning”.</p><p id="fd66" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Unlike masked language modeling, model build unidirectional context, since they do not see what comes after the mask.</p><p id="f1b8" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Of course, with decoder-only models, the output sequence can have a different length than the input sequence.</p><h2 id="aa17" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Encoder-decoder models</h2><p id="3aa4" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Encoder-decoder models are also called <em class="qe">sequence-to-sequence </em>models, and they use the full Transformer architecture.</p><p id="d8d9" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Those models are often used for translation, text summarization and question answering.</p><p id="6cf4" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Popular examples of sequence-to-sequence models are T5 and BART.</p><p id="028c" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">To train these models, the <strong class="oj hb">span corruption</strong> method is used. Here, a random sequence of tokens is masked and designated as a <em class="qe">sentinel</em> token. Then, the model must reconstruct the masked sequence autoregressively.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rm"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_003.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20D6wZ3fShZXtUsOCpJo3Esg.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_007.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_006.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_005.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_004.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_007.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_004.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_003.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_002.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_006.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520D6wZ3fShZXtUsOCpJo3Esg_005.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20D6wZ3fShZXtUsOCpJo3Esg.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="839"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">Illustration
 of span corruption. Here, a sequence of tokens is masked and replaced 
by a sentinel token. The model must then reconstructed the masked 
sequence autoregressively. Image by the author.</figcaption></figure><p id="5856" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the figure above, we can see that a sequence of two tokens were masked 
and replaced by a sentinel token. The model is then trained to 
reconstruct the sentinel token to obtain the original sentence.</p><p id="6973" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Here, the masked input is sent to the encoder, and the decoder is responsible for reconstructing the masked sequence.</p><h2 id="2bd1" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">A note on model size</h2><p id="1c43" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">While
 we have specified certain tasks for which certain models perform best, 
researchers have observed that large models are capable of various 
tasks.</p><p id="453a" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Therefore,
 very large decoder-only models can be very good at translation, even 
though encoder-decoder models specialize in that task.</p><p id="184c" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">With all of that in mind, let’s now start working with a large language in Python.</p><h1 id="da1a" class="pd pe ha be pf pg ph hw pi pj pk hz pl pm pn po pp pq pr ps pt pu pv pw px py bj">Work with a large language model</h1><p id="3c05" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Before
 we get hands-on experience with a large language model, let’s just 
cover some technical terms involved when working with LLMs.</p><p id="e53f" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">First, the text that we feed the LLM is called <em class="qe">prompt</em>, and the output of the model is called <em class="qe">completion</em>.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rn"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_003.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20kl7LZTzyN81aQdRe5dqSDA.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_007.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_006.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_004.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_005.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_004.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_002.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_005.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_003.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20kl7LZTzyN81aQdRe5dqSDA.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_007.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520kl7LZTzyN81aQdRe5dqSDA_006.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="124"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">The
 prompt is the text we feed to the model with the instructions. The 
output of the model is called completion. Image by the author.</figcaption></figure><p id="3553" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Inside the prompt is where we give the instructions to the LLM to achieve the task that we want.</p><p id="e3a5" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">This is also where <strong class="oj hb">prompt engineering</strong> is performed. With prompt engineering, we can perform <strong class="oj hb">in-context learning</strong>, which is when we give examples to the model of how certain tasks should be performed. We will see an example of that later on.</p><p id="086f" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">For now, let’s interact with an LLM using Python for sentiment analysis.</p><h1 id="c084" class="pd pe ha be pf pg ph hw pi pj pk hz pl pm pn po pp pq pr ps pt pu pv pw px py bj">Hands-on project: sentiment analysis with Flan-T5</h1><p id="10e1" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">For this mini project, we use Flan-T5 for sentiment analysis of various financial news.</p><p id="6069" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Flan-T5
 is an improved version of the T5 model, which is a sequence-to-sequence
 model. Researchers basically took the T5 model and fine-tuned it on 
different tasks covering more languages. For more details, you can refer
 to the <a class="af og" href="https://arxiv.org/pdf/2210.11416.pdf" rel="noopener ugc nofollow" target="_blank">original paper</a>.</p><p id="dc44" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">As for the dataset, we will use the <em class="qe">financial_phrasebank</em> dataset published by Pekka Malo and Ankur Sinha under the Creative Commons Attribute license.</p><p id="e014" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">The
 dataset contains a total of 4840 sentences from English language 
financial news that were categorized as positive, negative or neutral. A
 group of five to eight annotators classified each sentence, and 
depending on the agreement rate, the size of the dataset will vary (4850
 rows for a 50% agreement rate, and 2260 rows for a 100% agreement 
rate).</p><p id="10bc" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">For more information on the dataset and how it was compiled, refer to the <a class="af og" href="https://huggingface.co/datasets/financial_phrasebank" rel="noopener ugc nofollow" target="_blank">full dataset details page.</a></p><p id="d327" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Of course, all code show below is available on <a class="af og" href="https://github.com/marcopeix/learn_llm/blob/main/1_llm_get_started.ipynb" rel="noopener ugc nofollow" target="_blank">GitHub</a>.</p><h2 id="88df" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Setup your environment</h2><p id="8313" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">For the following experiment to work, make sure to have a virtual environment with the following packages installed:</p><ul class=""><li id="f6be" class="oh oi ha oj b hu ok ol om hx on oo op oq qf os ot ou qg ow ox oy qh pa pb pc qi qj qk bj">torch</li><li id="4deb" class="oh oi ha oj b hu ql ol om hx qm oo op oq qn os ot ou qo ow ox oy qp pa pb pc qi qj qk bj">torchdata</li><li id="8d40" class="oh oi ha oj b hu ql ol om hx qm oo op oq qn os ot ou qo ow ox oy qp pa pb pc qi qj qk bj">transformers</li><li id="ffe1" class="oh oi ha oj b hu ql ol om hx qm oo op oq qn os ot ou qo ow ox oy qp pa pb pc qi qj qk bj">datasets</li><li id="4622" class="oh oi ha oj b hu ql ol om hx qm oo op oq qn os ot ou qo ow ox oy qp pa pb pc qi qj qk bj">pandas</li><li id="9d7c" class="oh oi ha oj b hu ql ol om hx qm oo op oq qn os ot ou qo ow ox oy qp pa pb pc qi qj qk bj">matplotlib</li><li id="1ae5" class="oh oi ha oj b hu ql ol om hx qm oo op oq qn os ot ou qo ow ox oy qp pa pb pc qi qj qk bj">scikit-learn</li></ul><p id="4863" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Note that the libraries <em class="qe">transformers </em>and <em class="qe">datasets</em> are from HuggingFace, making it super easy for us to access and experiment with LLMs.</p><p id="5450" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Once the environment is setup, we can start by importing the required libraries.</p><pre class="nq nr ns nt nu ro rp rq bo rr ba bj"><span id="46a9" class="rs pe ha rp b bf rt ru l rv rw">import pandas as pd<br>import numpy as np<br>import matplotlib.pyplot as plt<br><br>from datasets import load_dataset<br>from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig</span></pre><h2 id="5a55" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Load the data</h2><p id="d0e3" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Then, we can load our dataset. Here, we use the dataset with 100% agreement rate.</p><pre class="nq nr ns nt nu ro rp rq bo rr ba bj"><span id="317e" class="rs pe ha rp b bf rt ru l rv rw">dataset_name = "financial_phrasebank"<br><br>dataset = load_dataset(dataset_name, "sentences_allagree")</span></pre><p id="0404" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">This dataset contains a total of 2264 sentences.</p><p id="4d56" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Note that the label is encoded. 1 means neutral, 0 means negative and 2 means positive. The count of each label is shown below.</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no rx"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_007.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20c8vK07LrsZCQMxpgszREbw.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_006.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_005.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_004.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_003.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_004.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_002.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_006.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_003.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20c8vK07LrsZCQMxpgszREbw.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_007.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520c8vK07LrsZCQMxpgszREbw_005.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="516"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">Frequency of each sentiment in the dataset. Image by the author.</figcaption></figure><p id="fba0" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Let’s store the actual label of each sentence in a DataFrame, making it easier for us to evaluate the model later on.</p><pre class="nq nr ns nt nu ro rp rq bo rr ba bj"><span id="2fc0" class="rs pe ha rp b bf rt ru l rv rw">labels_df = pd.DataFrame()<br><br>labels_from_dataset = [dataset['train'][i]['label'] for i in range(2264)]<br><br>labels_df['labels'] = labels_from_dataset</span></pre><h2 id="b27b" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Load the model</h2><p id="64e5" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Now,
 let’s load the model as well as the tokenizer. As mentioned above, we 
will load the Flan-T5 model. Note that the model is available in 
different sizes, but I decided to use the base version.</p><pre class="nq nr ns nt nu ro rp rq bo rr ba bj"><span id="cc5d" class="rs pe ha rp b bf rt ru l rv rw">model_name = "google/flan-t5-base"<br><br>model = AutoModelForSeq2SeqLM.from_pretrained(model_name)<br><br>tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)</span></pre><p id="dfcc" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">That’s it! We can now use this LLM to perform sentiment analysis on our dataset.</p><h2 id="7517" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Prompt the model for sentiment analysis</h2><p id="7a96" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">For the model to perform sentiment analysis, we need to do prompt engineering to specify that task.</p><p id="1ffe" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In this case we simply use “<em class="qe">Is the following sentence positive, negative or neutral?</em>”. We then pass the sentence of our dataset and let the model infer.</p><p id="d6b1" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Note that this is called <strong class="oj hb">zero-shot inference</strong>, since the model was not specifically trained for this particular task on this specific dataset.</p><pre class="nq nr ns nt nu ro rp rq bo rr ba bj"><span id="2c5d" class="rs pe ha rp b bf rt ru l rv rw">zero_shot_sentiment = []<br><br>for i in range(2264):<br>    sentence = dataset['train'][i]['sentence']<br><br>    prompt = f"""<br>Is the follwing sentence positive, negative or neutral?<br><br>{sentence}<br>    """<br><br>    inputs = tokenizer(prompt, return_tensors='pt')<br>    output = tokenizer.decode(<br>        model.generate(<br>            inputs["input_ids"],<br>            max_new_tokens=50<br>        )[0],<br>        skip_special_tokens=True<br>    )<br><br>    zero_shot_sentiment.append(output)</span></pre><p id="2818" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the Python code block above, we loop over each sentence in the dataset 
and pass it in our prompt. The prompt is tokenized and set to the model.
 We then decode the output to obtain a natural language response. 
Finally, we store the prediction of the model in a list.</p><p id="5293" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Then, let’s add these predictions to our DataFrame.</p><pre class="nq nr ns nt nu ro rp rq bo rr ba bj"><span id="1df9" class="rs pe ha rp b bf rt ru l rv rw">labels_df['zero_shot_sentiment'] = zero_shot_sentiment<br>labels_df['zero_shot_sentiment'] = labels_df['zero_shot_sentiment'].map({'neutral':1, 'positive':2, 'negative':0})</span></pre><h2 id="4184" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">Evaluate the model</h2><p id="55e2" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">To evaluate our model, let’s display the confusion matrix of the predictions, as well as the classification report.</p><pre class="nq nr ns nt nu ro rp rq bo rr ba bj"><span id="3b79" class="rs pe ha rp b bf rt ru l rv rw">from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay<br>from sklearn.metrics import classification_report<br><br>cm = confusion_matrix(labels_df['labels'], labels_df['zero_shot_sentiment'], labels=[0,1,2])<br><br>disp_cm = ConfusionMatrixDisplay(cm, display_labels=[0,1,2])<br><br>disp_cm.plot();<br><br>plt.grid(False)<br>plt.tight_layout()<br><br><br>clf_report = classification_report(labels_df['labels'], labels_df['zero_shot_sentiment'], labels=[0,1,2])<br><br>print(clf_report)</span></pre><figure class="nq nr ns nt nu nv nn no paragraph-image"><div class="nn no ry"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_006.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20QRuJ5Bz08a0cfbC8FVS3Lw.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_005.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_004.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_007.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_003.webp 1382w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 691px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_007.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_004.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_003.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_002.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_006.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20QRuJ5Bz08a0cfbC8FVS3Lw.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520QRuJ5Bz08a0cfbC8FVS3Lw_005.png 1382w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 691px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="691" height="562"></picture></div><figcaption class="oc od gp nn no oe of be b bf z dt">Confusion matrix of zero-shot sentiment analysis on financial news using Flan-T5. Image by the author.</figcaption></figure><figure class="nq nr ns nt nu nv nn no paragraph-image"><div class="nn no rz"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20a5AUQlUFvwgyxE7TJhUV_Q.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_006.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_007.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_004.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_005.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_003.webp 1276w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 638px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_004.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20a5AUQlUFvwgyxE7TJhUV_Q.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_006.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_005.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_007.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_003.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520a5AUQlUFvwgyxE7TJhUV_Q_002.png 1276w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 638px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="638" height="271"></picture></div><figcaption class="oc od gp nn no oe of be b bf z dt">Classification report for zero-shot sentiment analysis. Image by the author.</figcaption></figure><p id="5d8b" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">From
 the figure above, we can see that the model found all negative 
sentences, at the cost of precision since it mislabelled 611 neutral 
sentences and 92 positive sentences. Also, we can see a clear problem 
with identifying neutral sentences, as it mislabelled the vast majority.</p><p id="8d8c" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Therefore, let’s try to change our prompt to see if we can improve the model’s performance.</p><h2 id="84e7" class="qq pe ha be pf qr qs dx pi qt qu dz pl oq qv qw qx ou qy qz ra oy rb rc rd re bj">One-shot inference with in-context learning</h2><p id="bb00" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Here, we modify our prompt to include an example of a neutral sentence. This technique is called <strong class="oj hb">in-context learning</strong>, as we pass an example of how the model should behave inside the prompt.</p><p id="f15a" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Passing one example is called <strong class="oj hb">one-shot inference</strong>. It is possible to pass more examples, in which case it becomes <strong class="oj hb">few-shot inference</strong>.</p><p id="82eb" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">It
 is normal to show up to five examples to the LLM. If the performance 
does not improve, then it is likely that we need to fine-tune the model.</p><p id="6b30" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">For now, let’s see how one example impacts the performance.</p><pre class="nq nr ns nt nu ro rp rq bo rr ba bj"><span id="dc00" class="rs pe ha rp b bf rt ru l rv rw">one_shot_sentiment = []<br><br>for i in range(2264):<br>    sentence = dataset['train'][i]['sentence']<br><br>    prompt = f"""<br><br>Is the follwing sentence positive, negative or neutral?<br><br>Statement: "According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing ."<br>neutral<br><br>Is the follwing sentence positive, negative or neutral?<br>Statement: {sentence}<br><br>{sentence}<br>    """<br><br>    inputs = tokenizer(prompt, return_tensors='pt')<br>    output = tokenizer.decode(<br>        model.generate(<br>            inputs["input_ids"],<br>            max_new_tokens=50<br>        )[0],<br>        skip_special_tokens=True<br>    )<br><br>    one_shot_sentiment.append(output)</span></pre><p id="da08" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">In
 the code block above, we see that we give an example of a neutral 
sentence to help the model identify them. Then, we pass each sentence 
for the model to classify.</p><p id="d403" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Afterwards,
 we follow the same steps of adding a new columns containing the new 
predictions, and displaying the confusion matrix.</p><pre class="nq nr ns nt nu ro rp rq bo rr ba bj"><span id="4c51" class="rs pe ha rp b bf rt ru l rv rw">labels_df['one_shot_sentiment'] = one_shot_sentiment<br>labels_df['one_shot_sentiment'] = labels_df['one_shot_sentiment'].map({'neutral':1, 'positive':2, 'negative':0})<br><br>cm = confusion_matrix(labels_df['labels'], labels_df['one_shot_sentiment'], labels=[0,1,2])<br><br>disp_cm = ConfusionMatrixDisplay(cm, display_labels=[0,1,2])<br><br>disp_cm.plot();<br><br>plt.grid(False)<br>plt.tight_layout()</span></pre><figure class="nq nr ns nt nu nv nn no paragraph-image"><div role="button" tabindex="0" class="nw nx ff ny bg nz"><div class="nn no sa"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_003.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20V5cM_64w0ebsi4_dLUVR8Q.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_007.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_006.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_004.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_005.webp 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_002.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_006.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_004.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_005.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_007.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20V5cM_64w0ebsi4_dLUVR8Q.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520V5cM_64w0ebsi4_dLUVR8Q_003.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="700" height="593"></picture></div></div><figcaption class="oc od gp nn no oe of be b bf z dt">Confusion matrix of one-shot sentiment analysis of financial news using Flan-T5. Image by the author.</figcaption></figure><figure class="nq nr ns nt nu nv nn no paragraph-image"><div class="nn no sb"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%209B1lgOkSfALAyhV8MvmTiA.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_006.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_005.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_007.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_004.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_002.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_003.webp 1248w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 624px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_003.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%209B1lgOkSfALAyhV8MvmTiA.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_006.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_005.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_004.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_007.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25209B1lgOkSfALAyhV8MvmTiA_002.png 1248w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 624px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="624" height="263"></picture></div><figcaption class="oc od gp nn no oe of be b bf z dt">Classification report for one-shot sentiment analysis. Image by the author.</figcaption></figure><p id="c5b7" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">From
 the figure above, we can see a slight improvement. The weighted 
F1-score increased from 0.40 to 0.44. The model did better on the 
neutral class, but at the cost of a worse performance on the positive 
class.</p><p id="f6d5" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Adding
 examples of positive, negative, and neutral sentences may help, but I 
did not test it out. Otherwise, fine-tuning the model would be 
necessary, but that is the subject of another article.</p><h1 id="9c3a" class="pd pe ha be pf pg ph hw pi pj pk hz pl pm pn po pp pq pr ps pt pu pv pw px py bj">Conclusion</h1><p id="55d1" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">A
 lot of concepts were covered in this article, from the understanding 
the basics of LLMs, to actually using Flan-T5 for sentiment analysis in 
Python.</p><p id="6cfd" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">You
 now have the foundational knowledge to explore this world on your own 
and see how we can fine-tune LLMs, how we can train one, and how we can 
build applications around them.</p><p id="f63c" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">I hope that you learned something new, and that you are curious to learn even more.</p><p id="04b0" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj">Cheers 🍻</p><h1 id="da04" class="pd pe ha be pf pg ph hw pi pj pk hz pl pm pn po pp pq pr ps pt pu pv pw px py bj">Support me</h1><p id="2cc1" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj">Enjoying my work? Show your support with <a class="af og" href="http://buymeacoffee.com/dswm" rel="noopener ugc nofollow" target="_blank">Buy me a coffee</a>, a simple way for you to encourage me, and I get to enjoy a cup of coffee! If you feel like it, just click the button below 👇</p><figure class="nq nr ns nt nu nv nn no paragraph-image"><a href="http://buymeacoffee.com/dswm"><div class="nn no sc"><picture><source srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_002.webp 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_006.webp 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_004.webp 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_005.webp 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_007.webp 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_003.webp 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2018ybLoAAqbDSo_meOx9xew.webp 610w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 305px" type="image/webp"><source data-testid="og" srcset="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_007.png 640w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_004.png 720w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2018ybLoAAqbDSo_meOx9xew.png 750w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_005.png 786w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_003.png 828w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_002.png 1100w, Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%252018ybLoAAqbDSo_meOx9xew_006.png 610w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 305px"><img alt="" class="bg oa ob c" loading="lazy" role="presentation" width="305" height="89"></picture></div></a></figure><h1 id="0dfa" class="pd pe ha be pf pg ph hw pi pj pk hz pl pm pn po pp pq pr ps pt pu pv pw px py bj">References</h1><p id="e291" class="pw-post-body-paragraph oh oi ha oj b hu pz ol om hx qa oo op oq qb os ot ou qc ow ox oy qd pa pb pc gt bj"><a class="af og" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">Attention is All You Need</a> — Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin</p><p id="60fd" class="pw-post-body-paragraph oh oi ha oj b hu ok ol om hx on oo op oq or os ot ou ov ow ox oy oz pa pb pc gt bj"><a class="af og" href="https://www.deeplearning.ai/courses/generative-ai-with-llms/" rel="noopener ugc nofollow" target="_blank">Generative AI with LLM</a>s — deeplearning.ai</p></div></div></div></div></section></div></div></article><div class="ab ca"><div class="ch bg fv fw fx fy"></div></div></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="sd se ab jx"><div class="sf ab"><a class="go ax am ao" href="https://medium.com/tag/artificial-intelligence" rel="noopener follow"><div class="sg ff cw sh ga si sj be b bf z bj sk">Artificial Intelligence</div></a></div><div class="sf ab"><a class="go ax am ao" href="https://medium.com/tag/nlp" rel="noopener follow"><div class="sg ff cw sh ga si sj be b bf z bj sk">NLP</div></a></div><div class="sf ab"><a class="go ax am ao" href="https://medium.com/tag/large-language-models" rel="noopener follow"><div class="sg ff cw sh ga si sj be b bf z bj sk">Large Language Models</div></a></div><div class="sf ab"><a class="go ax am ao" href="https://medium.com/tag/deep-learning" rel="noopener follow"><div class="sg ff cw sh ga si sj be b bf z bj sk">Deep Learning</div></a></div><div class="sf ab"><a class="go ax am ao" href="https://medium.com/tag/editors-pick" rel="noopener follow"><div class="sg ff cw sh ga si sj be b bf z bj sk">Editors Pick</div></a></div></div></div></div><div class="l"></div><footer class="sl sm sn so sp sq sr ss gs ab q st je c"><div class="l ae"><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="ab co su"><div class="ab q lr"><div class="sv l"><span class="l sw sx sy e d"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8daf784f46f8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div></span><span class="l h g f sz ta"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F8daf784f46f8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false"><button class="ao lv mm mn ab q fg mo mp" aria-label="responses" data-testid="footerResponseButton"><svg width="24" height="24" viewBox="0 0 24 24" class="hr"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b bf z dt"><span class="pw-responses-count ml hr">2</span></p></button></div></div></div></div><div class="ab q"><div class="tb l ju"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F8daf784f46f8&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8" rel="noopener follow"><button aria-controls="addToCatalogBookmarkButton" aria-expanded="false" aria-label="Add to list bookmark button" class="af fg ah ai aj ak al ms an ao ap eu mt mu mv"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></button></a></span></div></div></div><div class="tb l ju"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fg ah ai aj ak al ms an ao ap eu mw mx mp my"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="tc td te tf tg l bw"><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="ck ab th co"><div class="ab it"><a href="https://medium.com/@marcopeixeiro" rel="noopener follow"><div class="l ti tj bx tk ix"><div class="l ff"><img alt="Marco Peixeiro" class="l fa bx tl tm cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%200HKbgLGe-BeQE3o240uafw.jpg" loading="lazy" width="72" height="72"><div class="iy bx l tl tm fo n iz ja"></div></div></div></a><a href="https://towardsdatascience.com/" rel="noopener follow"><div class="tn ab ff"><div><div class="bl" aria-hidden="false"><div class="l to tp bx tk je"><div class="l ff"><img alt="Towards Data Science" class="l fa bx by bz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%2520CJe3891yB1A1mzMdqemkdg_002.jpg" loading="lazy" width="32" height="32"><div class="iy bx l by bz fo n iz ja"></div></div></div></div></div></div></a></div><div class="j i d"><div class="ab"><span><a class="be b bf z el sg em eo ep eq er es et eu ev ew ex tq ey ez fa bl fb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9835bccb3d51&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8&amp;newsletterV3=741c1c8fcfbd&amp;newsletterV3Id=9835bccb3d51&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow"><button class="be b bf z ts am tt tu tv tw tx ty tz ua et eu ev ew ex ey ez fa bl fb" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="tr tp to"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/@marcopeixeiro" rel="noopener follow"><h2 class="pw-author-name be ub uc ud ue bj"><span class="gt">Written by <!-- -->Marco Peixeiro</span></h2></a><div class="jl jm ab uf ug uh ui uj uk"></div></div><div class="sf ab"><div class="l ju"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar jk" href="https://medium.com/@marcopeixeiro/followers" rel="noopener follow">10.5K Followers</a></span></div><div class="be b bf z kb kc kd ab kf kg kh ki dt ka"><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span class="l ju">Writer for </span><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://towardsdatascience.com/" rel="noopener follow"><p class="be b bf z kb kc kd ke kf kg kh ki bj">Towards Data Science</p></a></div></div></div></div><div class="ul l"><p class="be b bf z bj"><span class="gt">Senior data scientist | Author | Instructor. I write hands-on articles with a focus on practical skills.</span></p></div></div><div class="h k"><div class="ab"><span><a class="be b bf z el sg em eo ep eq er es et eu ev ew ex tq ey ez fa bl fb" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F741c1c8fcfbd&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F9835bccb3d51&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fcatch-up-on-large-language-models-8daf784f46f8&amp;newsletterV3=741c1c8fcfbd&amp;newsletterV3Id=9835bccb3d51&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow"><button class="be b bf z ts am tt tu tv tw tx ty tz ua et eu ev ew ex ey ez fa bl fb" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="tr tp to"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="um bg un uo up uq ur us"></div></div></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="vd ve l"><h2 class="be ub ji z gz bj">More from <!-- -->Marco Peixeiro<!-- --> and Towards Data Science</h2></div><div class="vf ab lr jx vg vh vi vj vk vl vm vn vo vp vq vr vs vt vu"><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Forecasting Intermittent Time Series in Python" rel="noopener follow" href="https://towardsdatascience.com/forecasting-intermittent-time-series-in-python-9fd028a0c9ee"><div class="xk xl xm xn xo"><img alt="Forecasting Intermittent Time Series in Python" class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%204rpR5yY-wfW_78IL.jpg" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@marcopeixeiro" rel="noopener follow"><div class="l ff"><img alt="Marco Peixeiro" class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25200HKbgLGe-BeQE3o240uafw_002.jpg" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://medium.com/@marcopeixeiro" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Marco Peixeiro</p><div class="jl gr l"><div class="ab jn"><div class="ab"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M15.16 8c0 .65-.46 1.14-.86 1.57-.23.25-.47.5-.56.72-.1.22-.09.55-.1.88 0 .6-.01 1.3-.48 1.78-.48.48-1.16.5-1.75.5-.32 0-.65.01-.86.1-.2.07-.46.33-.7.57-.42.41-.9.88-1.54.88s-1.12-.47-1.54-.88a2.87 2.87 0 0 0-.7-.58c-.22-.09-.54-.08-.87-.09-.59 0-1.27-.02-1.74-.5s-.48-1.17-.49-1.78c0-.33-.01-.67-.1-.88-.07-.2-.32-.47-.55-.71-.4-.44-.87-.93-.87-1.58s.46-1.14.87-1.58c.23-.24.47-.5.56-.71.09-.22.08-.55.09-.88 0-.6.02-1.3.49-1.78s1.15-.5 1.74-.5c.33 0 .66-.01.86-.1.2-.08.47-.33.7-.57.43-.41.91-.88 1.55-.88.63 0 1.12.47 1.54.88.24.24.49.48.7.58.22.09.54.08.86.09.6 0 1.27.02 1.75.5.47.48.48 1.17.49 1.78 0 .33 0 .67.09.88.08.2.33.47.56.71.4.44.86.93.86 1.58z" fill="#437AFF"></path><path d="M7.33 10.5c.2 0 .38.08.52.22.13.14.21.33.21.53 0 .07.03.13.07.18a.24.24 0 0 0 .35 0 .25.25 0 0 0 .07-.18c0-.2.08-.39.22-.53a.73.73 0 0 1 .52-.22h1.96c.13 0 .25-.05.34-.15a.5.5 0 0 0 .15-.35V6a.5.5 0 0 0-.15-.35.48.48 0 0 0-.34-.15H9.78c-.33 0-.64.13-.87.37-.23.23-.36.55-.36.88v2.5c0 .07-.02.13-.07.18a.24.24 0 0 1-.35 0 .25.25 0 0 1-.07-.18v-2.5c0-.33-.13-.65-.36-.88a1.21 1.21 0 0 0-.86-.37H5.37a.48.48 0 0 0-.35.15.5.5 0 0 0-.14.35v4c0 .13.05.26.14.35.1.1.22.15.35.15h1.96z" fill="#fff"></path></svg></div></div></div></a></div></div></div><div class="ya l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://towardsdatascience.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Towards Data Science</p></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/forecasting-intermittent-time-series-in-python-9fd028a0c9ee"><div title=""><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">Forecasting Intermittent Time Series in Python</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">A complete guide on intermittent time series forecasting in Python with a capstone project</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/forecasting-intermittent-time-series-in-python-9fd028a0c9ee"><span class="be b du z dt"><div class="ab q"><div class="gs ab"><div class="bl" aria-hidden="false"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>15 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Aug 7</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9fd028a0c9ee&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-intermittent-time-series-in-python-9fd028a0c9ee&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" rel="noopener follow" href="https://towardsdatascience.com/forecasting-intermittent-time-series-in-python-9fd028a0c9ee?responsesOpen=true&amp;sortBy=REVERSE_CHRON"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">1</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9fd028a0c9ee&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fforecasting-intermittent-time-series-in-python-9fd028a0c9ee" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="um bg un zq"></div></div></div></div></div></div></div></article></div></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application?" rel="noopener follow" href="https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7"><div class="xk xl xm xn xo"><img alt="RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application?" class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20Jq9bEbitg1Pv4oASwEQwJg.png" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://heiko-hotz.medium.com/" rel="noopener follow"><div class="l ff"><img alt="Heiko Hotz" class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%205VifPxEG2ZkTxCK2m4JcLQ.png" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://heiko-hotz.medium.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Heiko Hotz</p></a></div></div></div><div class="ya l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://towardsdatascience.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Towards Data Science</p></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7"><div title="RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application?"><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application?</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">The definitive guide for choosing the right method for your use case</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7"><span class="be b du z dt"><div class="ab q"><div class="gs ab"><div class="bl" aria-hidden="false"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>19 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Aug 24</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F94654b1eaba7&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Frag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7&amp;user=Heiko+Hotz&amp;userId=993c21f1b30f" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" rel="noopener follow" href="https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7?responsesOpen=true&amp;sortBy=REVERSE_CHRON"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">16</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F94654b1eaba7&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Frag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="um bg un zq"></div></div></div></div></div></div></div></article></div></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Man in a room holding a book and ethereal computation on the walls" rel="noopener follow" href="https://towardsdatascience.com/new-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b"><div class="xk xl xm xn xo"><img alt="Man in a room holding a book and ethereal computation on the walls" class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20SO1Nys1yLSFX9Ka-tOoR8A.png" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@hominum_universalis" rel="noopener follow"><div class="l ff"><img alt="Giuseppe Scalamogna" class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20-G8aVXnU_tDQVRDkJ4PtCA@2x.jpg" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://medium.com/@hominum_universalis" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Giuseppe Scalamogna</p></a></div></div></div><div class="ya l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://towardsdatascience.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Towards Data Science</p></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/new-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b"><div title=""><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">New ChatGPT Prompt Engineering Technique: Program Simulation</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">A potentially novel technique for turning a ChatGPT prompt into a mini-app.</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/new-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b"><span class="be b du z dt"><div class="ab q"><span>9 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Sep 3</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F56f49746aa7b&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b&amp;user=Giuseppe+Scalamogna&amp;userId=e039aa8b7221" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" rel="noopener follow" href="https://towardsdatascience.com/new-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b?responsesOpen=true&amp;sortBy=REVERSE_CHRON"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">11</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F56f49746aa7b&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fnew-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="um bg un zq"></div></div></div></div></div></div></div></article></div></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="The Complete Guide to Time Series Analysis and Forecasting" rel="noopener follow" href="https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775"><div class="xk xl xm xn xo"><img alt="The Complete Guide to Time Series Analysis and Forecasting" class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%209xhiP7nD8Ur2c3nrnApQkQ.jpg" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@marcopeixeiro" rel="noopener follow"><div class="l ff"><img alt="Marco Peixeiro" class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%25200HKbgLGe-BeQE3o240uafw_002.jpg" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://medium.com/@marcopeixeiro" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Marco Peixeiro</p><div class="jl gr l"><div class="ab jn"><div class="ab"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M15.16 8c0 .65-.46 1.14-.86 1.57-.23.25-.47.5-.56.72-.1.22-.09.55-.1.88 0 .6-.01 1.3-.48 1.78-.48.48-1.16.5-1.75.5-.32 0-.65.01-.86.1-.2.07-.46.33-.7.57-.42.41-.9.88-1.54.88s-1.12-.47-1.54-.88a2.87 2.87 0 0 0-.7-.58c-.22-.09-.54-.08-.87-.09-.59 0-1.27-.02-1.74-.5s-.48-1.17-.49-1.78c0-.33-.01-.67-.1-.88-.07-.2-.32-.47-.55-.71-.4-.44-.87-.93-.87-1.58s.46-1.14.87-1.58c.23-.24.47-.5.56-.71.09-.22.08-.55.09-.88 0-.6.02-1.3.49-1.78s1.15-.5 1.74-.5c.33 0 .66-.01.86-.1.2-.08.47-.33.7-.57.43-.41.91-.88 1.55-.88.63 0 1.12.47 1.54.88.24.24.49.48.7.58.22.09.54.08.86.09.6 0 1.27.02 1.75.5.47.48.48 1.17.49 1.78 0 .33 0 .67.09.88.08.2.33.47.56.71.4.44.86.93.86 1.58z" fill="#437AFF"></path><path d="M7.33 10.5c.2 0 .38.08.52.22.13.14.21.33.21.53 0 .07.03.13.07.18a.24.24 0 0 0 .35 0 .25.25 0 0 0 .07-.18c0-.2.08-.39.22-.53a.73.73 0 0 1 .52-.22h1.96c.13 0 .25-.05.34-.15a.5.5 0 0 0 .15-.35V6a.5.5 0 0 0-.15-.35.48.48 0 0 0-.34-.15H9.78c-.33 0-.64.13-.87.37-.23.23-.36.55-.36.88v2.5c0 .07-.02.13-.07.18a.24.24 0 0 1-.35 0 .25.25 0 0 1-.07-.18v-2.5c0-.33-.13-.65-.36-.88a1.21 1.21 0 0 0-.86-.37H5.37a.48.48 0 0 0-.35.15.5.5 0 0 0-.14.35v4c0 .13.05.26.14.35.1.1.22.15.35.15h1.96z" fill="#fff"></path></svg></div></div></div></a></div></div></div><div class="ya l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://towardsdatascience.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Towards Data Science</p></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775"><div title=""><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">The Complete Guide to Time Series Analysis and Forecasting</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">Understand
 moving average, exponential smoothing, stationarity, autocorrelation, 
SARIMA, and apply these techniques in two projects.</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775"><span class="be b du z dt"><div class="ab q"><div class="gs ab"><div class="bl" aria-hidden="false"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>13 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Aug 7, 2019</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F70d476bfe775&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775&amp;user=Marco+Peixeiro&amp;userId=741c1c8fcfbd" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" rel="noopener follow" href="https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775?responsesOpen=true&amp;sortBy=REVERSE_CHRON"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">18</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F70d476bfe775&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fthe-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="um bg un dj dk zr zs zt"></div><div class="ab jv jw zu zv zw"><a class="be b bf z bj sg zx zy zz aba mo abb es et eu abc abd abe ex abf abg abh abi abj ey ez fa bl fb" href="https://medium.com/@marcopeixeiro" rel="noopener follow"><div class="l od">See all from <!-- -->Marco Peixeiro</div></a><div class="abk abl abm abn abo abp abq abr abs mj l"><a class="be b bf z bj sg zx zy zz aba mo abb es et eu abc abd abe ex abf abg abh abi abj ey ez fa bl fb" href="https://towardsdatascience.com/" rel="noopener follow"><div class="l od">See all from <!-- -->Towards Data Science</div></a></div></div></div></div><div class="um bg un abt abu abv abw abx"></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="aby abz l"><h2 class="be ub pg hw pi pj hz pl pm po pp pq ps pt pu pw px bj">Recommended from Medium</h2><div class="nq nr ns nt nu l"><div class="vf ab lr jx vg vh vi vj vk vl vm vn vo vp vq vr vs vt vu"><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="The ChatGPT Hype Is Over — Now Watch How Google Will Kill ChatGPT." href="https://entreprenal.com/the-chatgpt-hype-is-over-now-watch-how-google-will-kill-chatgpt-426d5e3f7d05" rel="noopener follow"><div class="xk xl xm xn xo"><img alt="The ChatGPT Hype Is Over — Now Watch How Google Will Kill ChatGPT." class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%203FtLa-nHJB8KOb-Wu9bqbg.png" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://entreprenal.com/" rel="noopener follow"><div class="l ff"><img alt="AL Anany" class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20zwwpG0St4jn5uH0VVyjQng.png" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://entreprenal.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">AL Anany</p><div class="jl gr l"><div class="ab jn"><div class="ab"><svg width="16" height="16" viewBox="0 0 16 16" fill="none"><path d="M15.16 8c0 .65-.46 1.14-.86 1.57-.23.25-.47.5-.56.72-.1.22-.09.55-.1.88 0 .6-.01 1.3-.48 1.78-.48.48-1.16.5-1.75.5-.32 0-.65.01-.86.1-.2.07-.46.33-.7.57-.42.41-.9.88-1.54.88s-1.12-.47-1.54-.88a2.87 2.87 0 0 0-.7-.58c-.22-.09-.54-.08-.87-.09-.59 0-1.27-.02-1.74-.5s-.48-1.17-.49-1.78c0-.33-.01-.67-.1-.88-.07-.2-.32-.47-.55-.71-.4-.44-.87-.93-.87-1.58s.46-1.14.87-1.58c.23-.24.47-.5.56-.71.09-.22.08-.55.09-.88 0-.6.02-1.3.49-1.78s1.15-.5 1.74-.5c.33 0 .66-.01.86-.1.2-.08.47-.33.7-.57.43-.41.91-.88 1.55-.88.63 0 1.12.47 1.54.88.24.24.49.48.7.58.22.09.54.08.86.09.6 0 1.27.02 1.75.5.47.48.48 1.17.49 1.78 0 .33 0 .67.09.88.08.2.33.47.56.71.4.44.86.93.86 1.58z" fill="#437AFF"></path><path d="M7.33 10.5c.2 0 .38.08.52.22.13.14.21.33.21.53 0 .07.03.13.07.18a.24.24 0 0 0 .35 0 .25.25 0 0 0 .07-.18c0-.2.08-.39.22-.53a.73.73 0 0 1 .52-.22h1.96c.13 0 .25-.05.34-.15a.5.5 0 0 0 .15-.35V6a.5.5 0 0 0-.15-.35.48.48 0 0 0-.34-.15H9.78c-.33 0-.64.13-.87.37-.23.23-.36.55-.36.88v2.5c0 .07-.02.13-.07.18a.24.24 0 0 1-.35 0 .25.25 0 0 1-.07-.18v-2.5c0-.33-.13-.65-.36-.88a1.21 1.21 0 0 0-.86-.37H5.37a.48.48 0 0 0-.35.15.5.5 0 0 0-.14.35v4c0 .13.05.26.14.35.1.1.22.15.35.15h1.96z" fill="#fff"></path></svg></div></div></div></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://entreprenal.com/the-chatgpt-hype-is-over-now-watch-how-google-will-kill-chatgpt-426d5e3f7d05" rel="noopener follow"><div title=""><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">The ChatGPT Hype Is Over — Now Watch How Google Will Kill ChatGPT.</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">It never happens instantly. The business game is longer than you know.</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://entreprenal.com/the-chatgpt-hype-is-over-now-watch-how-google-will-kill-chatgpt-426d5e3f7d05" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="gs ab"><div class="bl" aria-hidden="false"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>6 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Sep 1</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F426d5e3f7d05&amp;operation=register&amp;redirect=https%3A%2F%2Fentreprenal.com%2Fthe-chatgpt-hype-is-over-now-watch-how-google-will-kill-chatgpt-426d5e3f7d05&amp;user=AL+Anany&amp;userId=4a25c00139e6" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" href="https://entreprenal.com/the-chatgpt-hype-is-over-now-watch-how-google-will-kill-chatgpt-426d5e3f7d05?responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">225</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F426d5e3f7d05&amp;operation=register&amp;redirect=https%3A%2F%2Fentreprenal.com%2Fthe-chatgpt-hype-is-over-now-watch-how-google-will-kill-chatgpt-426d5e3f7d05" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="um bg un zq"></div></div></div></div></div></div></div></article></div></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Advanced Prompt Engineering" rel="noopener follow" href="https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01"><div class="xk xl xm xn xo"><img alt="Advanced Prompt Engineering" class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20d6yWsvLaLTfieYQP5lQf6w.jpg" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://wolfecameron.medium.com/" rel="noopener follow"><div class="l ff"><img alt="Cameron R. Wolfe, Ph.D." class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20wv4savxpgdp3RXjMrCYrXQ.png" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://wolfecameron.medium.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Cameron R. Wolfe, Ph.D.</p></a></div></div></div><div class="ya l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://towardsdatascience.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Towards Data Science</p></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01"><div title=""><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">Advanced Prompt Engineering</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">What to do when few-shot learning isn’t enough…</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01"><span class="be b du z dt"><div class="ab q"><div class="gs ab"><div class="bl" aria-hidden="false"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>17 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Aug 7</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2Ff07f9e55fe01&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01&amp;user=Cameron+R.+Wolfe%2C+Ph.D.&amp;userId=28aa6026c553" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" rel="noopener follow" href="https://towardsdatascience.com/advanced-prompt-engineering-f07f9e55fe01?responsesOpen=true&amp;sortBy=REVERSE_CHRON"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">11</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff07f9e55fe01&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fadvanced-prompt-engineering-f07f9e55fe01" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div><div class="um bg un aca"></div><h2 class="be ub ji z gz bj">Lists</h2><div class="zq l"><div class="cm ab lr jx vg vh vi vj vk vl vm vn vo vp vq vr vs vt vu"><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@AMGAS14/list/natural-language-processing-0a856388a93a" rel="noopener follow"><div class="ach aci kb ab ju ff"><div class="ff xp acc bw acd"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%20fJ9bDkUv2rDzGR9H.png" loading="lazy" role="presentation" width="48" height="48"></div></div><div class="ff xp acc bw ace acf"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20uGiG0jByu8VRexukk_JYyg.png" loading="lazy" role="presentation" width="48" height="48"></div></div><div class="ff xp bw je acg"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%20L2JMa5UKK9Cmo9LG.jpg" loading="lazy" role="presentation" width="48" height="48"></div></div></div><div class="aw l"><h2 class="be ub ji z kb yw kd ke yx kg ki gz bj">Natural Language Processing</h2><div class="be b du z dt ab acb">608 stories<span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span>224<!-- --> <!-- -->saves</div></div></a></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@MediumStaff/list/ai-regulation-dfa78dfd2438" rel="noopener follow"><div class="ach aci kb ab ju ff"><div class="ff xp acc bw acd"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20era76EGCwdY2gWSFKutuSw.jpg" loading="lazy" role="presentation" width="48" height="48"></div></div><div class="ff xp acc bw ace acf"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20AiTJDz5wwQFiUCf_SrBOQA.jpg" loading="lazy" role="presentation" width="48" height="48"></div></div><div class="ff xp bw je acg"><div class="xp iv kb l"><img alt="A phone with a tweet on it describing a deepfake video of the Ukrainian president, with a labeled fake image in the background" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20zjPggFS8yoRtFbAP9R_3lw.jpg" loading="lazy" width="48" height="48"></div></div></div><div class="aw l"><h2 class="be ub ji z kb yw kd ke yx kg ki gz bj">AI Regulation</h2><div class="be b du z dt ab acb">6 stories<span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span>122<!-- --> <!-- -->saves</div></div></a></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@nicholas.michael.janulewicz/list/chatgpt-prompts-b4c47b8e12ee" rel="noopener follow"><div class="ach aci kb ab ju ff"><div class="ff xp acc bw acd"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20GHhSZx4-tYPOYtYojjwdAQ.jpg" loading="lazy" role="presentation" width="48" height="48"></div></div><div class="ff xp acc bw ace acf"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20efsUAIea1J-UOIVLMD24ng.png" loading="lazy" role="presentation" width="48" height="48"></div></div><div class="ff xp bw je acg"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20eX8r1Ctk5BCrKgtZ15YxKA.jpg" loading="lazy" role="presentation" width="48" height="48"></div></div></div><div class="aw l"><h2 class="be ub ji z kb yw kd ke yx kg ki gz bj">ChatGPT prompts </h2><div class="be b du z dt ab acb">24 stories<span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span>383<!-- --> <!-- -->saves</div></div></a></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" href="https://medium.com/@m.wasalski/list/chatgpt-3742c7a4727d" rel="noopener follow"><div class="ach aci kb ab ju ff"><div class="ff xp acc bw acd"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20dtz5Y7h7Dlc5TURKUUDaYw.gif" loading="lazy" role="presentation" width="48" height="48"></div></div><div class="ff xp acc bw ace acf"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%20V3E5F6rH0O512mT3.jpg" loading="lazy" role="presentation" width="48" height="48"></div></div><div class="ff xp bw je acg"><div class="xp iv kb l"><img alt="" class="" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20NQmmb6tdLZdSXfYv4Oli4w.png" loading="lazy" role="presentation" width="48" height="48"></div></div></div><div class="aw l"><h2 class="be ub ji z kb yw kd ke yx kg ki gz bj">ChatGPT</h2><div class="be b du z dt ab acb">21 stories<span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span>152<!-- --> <!-- -->saves</div></div></a></div></div></div><div class="um bg un abl dj abn dk gl acj gm ack gn acl"></div><div class="vf ab lr jx vg vh vi vj vk vl vm vn vo vp vq vr vs vt vu"><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Google Bert" href="https://medium.com/@shaikhrayyan123/a-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51" rel="noopener follow"><div class="xk xl xm xn xo"><img alt="Google Bert" class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20RFS-lLJhNbaJOZoE9sOCwA.png" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@shaikhrayyan123" rel="noopener follow"><div class="l ff"><img alt="Rayyan Shaikh" class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/0%204GQ2Vm8ARj9hsvGt.jpg" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://medium.com/@shaikhrayyan123" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Rayyan Shaikh</p></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@shaikhrayyan123/a-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51" rel="noopener follow"><div title="Mastering BERT: A Comprehensive Guide from Beginner to Advanced in Natural Language Processing…"><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">Mastering BERT: A Comprehensive Guide from Beginner to Advanced in Natural Language Processing…</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">Introduction: A Guide to Unlocking BERT: From Beginner to Expert</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@shaikhrayyan123/a-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><span>19 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Aug 26</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F2379699e2b51&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40shaikhrayyan123%2Fa-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51&amp;user=Rayyan+Shaikh&amp;userId=b4f876ff8ab2" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" href="https://medium.com/@shaikhrayyan123/a-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51?responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">13</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2379699e2b51&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40shaikhrayyan123%2Fa-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="um bg un zq"></div></div></div></div></div></div></div></article></div></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Top Large Language Models (LLMs) Interview Questions &amp; Answers" href="https://levelup.gitconnected.com/top-large-language-models-llms-interview-questions-answers-d7b83f94c4e" rel="noopener follow"><div class="xk xl xm xn xo"><img alt="Top Large Language Models (LLMs) Interview Questions &amp; Answers" class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20X0OFyPTgHIntKjgf87nyZA.png" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://yousefhosni.medium.com/" rel="noopener follow"><div class="l ff"><img alt="Youssef Hosni" class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20cBxasbWXomjJrHV2_Fh8zw.jpg" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://yousefhosni.medium.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Youssef Hosni</p></a></div></div></div><div class="ya l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://levelup.gitconnected.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Level Up Coding</p></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://levelup.gitconnected.com/top-large-language-models-llms-interview-questions-answers-d7b83f94c4e" rel="noopener follow"><div title=""><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">Top Large Language Models (LLMs) Interview Questions &amp; Answers</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">Demystifying Large Language Models (LLMs): Key Interview Questions and Expert Answers</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://levelup.gitconnected.com/top-large-language-models-llms-interview-questions-answers-d7b83f94c4e" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><div class="gs ab"><div class="bl" aria-hidden="false"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false"><svg width="16" height="16" viewBox="0 0 20 20" fill="none"><path d="M12.4 12.77l-1.81 4.99a.63.63 0 0 1-1.18 0l-1.8-4.99a.63.63 0 0 0-.38-.37l-4.99-1.81a.62.62 0 0 1 0-1.18l4.99-1.8a.63.63 0 0 0 .37-.38l1.81-4.99a.63.63 0 0 1 1.18 0l1.8 4.99a.63.63 0 0 0 .38.37l4.99 1.81a.63.63 0 0 1 0 1.18l-4.99 1.8a.63.63 0 0 0-.37.38z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>42 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Sep 5</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fgitconnected%2Fd7b83f94c4e&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Ftop-large-language-models-llms-interview-questions-answers-d7b83f94c4e&amp;user=Youssef+Hosni&amp;userId=859af34925b7" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" href="https://levelup.gitconnected.com/top-large-language-models-llms-interview-questions-answers-d7b83f94c4e?responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">3</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fd7b83f94c4e&amp;operation=register&amp;redirect=https%3A%2F%2Flevelup.gitconnected.com%2Ftop-large-language-models-llms-interview-questions-answers-d7b83f94c4e" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="um bg un zq"></div></div></div></div></div></div></div></article></div></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="The End of the Subscription Era is Coming" href="https://nickfthilton.medium.com/the-end-of-the-subscription-era-is-coming-ed197f252c6a" rel="noopener follow"><div class="xk xl xm xn xo"><img alt="The End of the Subscription Era is Coming" class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20xF5PSuatJOncVIF2EUP-jg.jpg" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://nickfthilton.medium.com/" rel="noopener follow"><div class="l ff"><img alt="Nick Hilton" class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/2%20rK52B7-RuC6qsXN1rrHtcw.jpg" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://nickfthilton.medium.com/" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Nick Hilton</p></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://nickfthilton.medium.com/the-end-of-the-subscription-era-is-coming-ed197f252c6a" rel="noopener follow"><div title=""><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">The End of the Subscription Era is Coming</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">You’re overpaying for your porn (and journalism)</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://nickfthilton.medium.com/the-end-of-the-subscription-era-is-coming-ed197f252c6a" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><span>10 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Aug 30</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fed197f252c6a&amp;operation=register&amp;redirect=https%3A%2F%2Fnickfthilton.medium.com%2Fthe-end-of-the-subscription-era-is-coming-ed197f252c6a&amp;user=Nick+Hilton&amp;userId=757310c731ab" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" href="https://nickfthilton.medium.com/the-end-of-the-subscription-era-is-coming-ed197f252c6a?responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">191</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fed197f252c6a&amp;operation=register&amp;redirect=https%3A%2F%2Fnickfthilton.medium.com%2Fthe-end-of-the-subscription-era-is-coming-ed197f252c6a" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div><div class="j i d"><div class="um bg un zq"></div></div></div></div></div></div></div></article></div></div><div class="vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn wo wp"><div class="wq wr ws wt wu dv l"><article class="dv"><div class="dv gs l"><div class="bg dv"><div class="dv l"><div class="dv wv ww wx wy wz xa xb xc xd xe xf xg xh"><div class="xi"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Generative AI with Enterprise Data" href="https://medium.com/@Sachin.Kulkarni.NL/generative-ai-with-enterprise-data-3c81a8bffaf2" rel="noopener follow"><div class="xk xl xm xn xo"><img alt="Generative AI with Enterprise Data" class="bg xp xq xr xs bw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20Wj6mJ7SvnfJturBYGtZ-vQ.png" loading="lazy"></div></a></div><div class="xj ab ca cn"><div class="xt xu xv xw xx ab"><div class="go l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@Sachin.Kulkarni.NL" rel="noopener follow"><div class="l ff"><img alt="Sachin Kulkarni" class="l fa bx xy xz cw" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1%20ymKe7pqq11CT2fLERt8RRA.jpg" loading="lazy" width="20" height="20"><div class="fn bx l xy xz fo n ax ja"></div></div></a></div></div></div><div class="ya l"><div><div class="bl" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jk ab q" href="https://medium.com/@Sachin.Kulkarni.NL" rel="noopener follow"><p class="be b du z kb kc kd ke kf kg kh ki bj">Sachin Kulkarni</p></a></div></div></div></div><div class="yb yc yd ye yf yg yh yi yj yk l gt"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@Sachin.Kulkarni.NL/generative-ai-with-enterprise-data-3c81a8bffaf2" rel="noopener follow"><div title=""><h2 class="be hb pg hw yl ym pi pj hz yn yo pl oq qw yp yq qx ou qz yr ys ra oy rc yt yu rd kb kd ke kg ki bj">Generative AI with Enterprise Data</h2></div><div class="yv l"><h3 class="be b ji z kb yw kd ke yx kg ki dt">Create business value add Enterprise knowledge to Large Language Models</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/@Sachin.Kulkarni.NL/generative-ai-with-enterprise-data-3c81a8bffaf2" rel="noopener follow"><span class="be b du z dt"><div class="ab q"><span>6 min read</span><span class="jo l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Jul 25</span></div></span></a><div class="yy yz za zb zc l"><div class="ab co"><div class="am zd ze zf zg zh zi zj zk zl zm ab q"><div class="ab q lr"><div class="pw-multi-vote-icon ff gq ls lt lu"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F3c81a8bffaf2&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40Sachin.Kulkarni.NL%2Fgenerative-ai-with-enterprise-data-3c81a8bffaf2&amp;user=Sachin+Kulkarni&amp;userId=953df644ac5a" rel="noopener follow"><div class="lv ao lw lx ly lz am ma mb mc lu"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></a></span></div><div class="pw-multi-vote-count l md me mf mg mh mi mj"><p class="be b du z dt"><span class="mk">--</span></p></div></div><div class="zn l"><div><div class="bl" aria-hidden="false"><a class="af fg ah lv aj ak al mn an ao ap aq ar as at mm ab q mo mp" aria-label="responses" href="https://medium.com/@Sachin.Kulkarni.NL/generative-ai-with-enterprise-data-3c81a8bffaf2?responsesOpen=true&amp;sortBy=REVERSE_CHRON" rel="noopener follow"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count ml hr">5</span></p></a></div></div></div></div><div class="ab q zo zp"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F3c81a8bffaf2&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40Sachin.Kulkarni.NL%2Fgenerative-ai-with-enterprise-data-3c81a8bffaf2" rel="noopener follow"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="mr"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="#292929"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="um bg un dj dk zr zs zt"></div><a class="be b bf z bj sg zx zy zz aba mo abb es et eu abc abd abe ex abf abg abh abi abj ey ez fa bl fb" href="https://medium.com/" rel="noopener follow"><div class="l od">See more recommendations</div></a></div></div></div><div class="h k j"><div class="um bg un ut"></div><div class="ab ca"><div class="ch bg fv fw fx fy"><div class="uu ab lr jx"><div class="uv uw l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us" rel="noopener follow"><p class="be b du z dt">Help</p></a></div><div class="uv uw l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/" rel="noopener follow"><p class="be b du z dt">Status</p></a></div><div class="uv uw l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://about.medium.com/creators/" rel="noopener follow"><p class="be b du z dt">Writers</p></a></div><div class="uv uw l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/" rel="noopener follow"><p class="be b du z dt">Blog</p></a></div><div class="uv uw l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e" rel="noopener follow"><p class="be b du z dt">Careers</p></a></div><div class="uv uw l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9" rel="noopener follow"><p class="be b du z dt">Privacy</p></a></div><div class="uv uw l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f" rel="noopener follow"><p class="be b du z dt">Terms</p></a></div><div class="uv uw l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1" rel="noopener follow"><p class="be b du z dt">About</p></a></div><div class="uv uw l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium" rel="noopener follow"><p class="be b du z dt">Text to speech</p></a></div><div class="uv l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business" rel="noopener follow"><p class="be b du z dt">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20230915-185240-aa1462aaf7"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"This request is not using the cache middleware worker","group":"disabled","tags":["group-edgeCachePosts","post-8daf784f46f8","user-741c1c8fcfbd","collection-7f60cf5620c9"],"serverVariantState":"","middlewareEnabled":false,"cacheStatus":"DYNAMIC","shouldUseCache":false,"vary":[],"inDisabledExperiment":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":true},"debug":{"requestId":"ccc621e8-0750-4b80-90c6-b71869d8ae0f","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"117f05f37c83a5b8","ot-tracer-traceid":"20f4f3fd27e9d293","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fcatch-up-on-large-language-models-8daf784f46f8","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false},"config":{"nodeEnv":"production","version":"main-20230915-185240-aa1462aaf7","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20230915-185240-aa1462aaf7","commit":"aa1462aaf7778ef18c0e1e890e5cb62b56414d30"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"variantFlags":[{"__typename":"VariantFlag","name":"enable_digest_generation_pipeline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_homepage","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_user_follows","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pill_based_home_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_new_user_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_send_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_updated_follower_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards_byline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_email_sign_in_captcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_dynamic_aspirational_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_aspiriational","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_twitter_auth_suggestions","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"onboarding_tags_from_top_views","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"disable_partner_program_enrollment","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_reading_history","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signin_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_cache_less_following_feed","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_app_flirty_thirty","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_author_cards","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_marketing_emails","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_monthly_plan","valueType":{"__typename":"VariantFlagString","value":"60e220181034"}},{"__typename":"VariantFlag","name":"enable_starspace","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"signup_services","valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"}},{"__typename":"VariantFlag","name":"enable_mastodon_avatar_upload","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_seamless_social_sharing","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_digest_tagline","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_apple_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_aurora_pub_follower_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"covid_19_cdc_banner","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"glyph_font_set","valueType":{"__typename":"VariantFlagString","value":"m2-unbound-source-serif-pro"}},{"__typename":"VariantFlag","name":"allow_test_auth","valueType":{"__typename":"VariantFlagString","value":"disallow"}},{"__typename":"VariantFlag","name":"enable_android_miro_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_about_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_response_markup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_server_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"browsable_stream_config_bucket","valueType":{"__typename":"VariantFlagString","value":"curated-topics"}},{"__typename":"VariantFlag","name":"enable_members_only_audio","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_archive_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_lock_responses","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_sign_in_recaptcha","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"can_receive_tips_v0","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_triton_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_signup","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_client","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_legacy_feed_in_iceland","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_recirc_model","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_sprig","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_verifications_service","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_two_hour_refresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tribute_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_one_tap","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_new_push_notification_endpoint","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tick_landing_page","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"skip_fs_cache_user_vals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_syntax_highlight","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"custom_moc_preview_weight_threshold","valueType":{"__typename":"VariantFlagString","value":"8"}},{"__typename":"VariantFlag","name":"android_enable_editor_new_publishing_flow","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_plan","valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"}},{"__typename":"VariantFlag","name":"ios_iceland_nux","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_social_share_sheet","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"limit_post_referrers","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_google_pay","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_medium2_kbfd","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ml_rank_rex_anno","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_creator_welcome_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tag_recs","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_automod","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_import","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_partner_program_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_lite_continue_this_thread","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_branch_io","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_newsletter_lo_flow_custom_domains","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_yearly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"reader_fair_distribution_non_qp","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"explicit_signals_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"price_smoke_test_monthly","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_simplified_digest_v2_b","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_auto_follow_on_subscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_widget","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"allow_access","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_annual_premium_plan","valueType":{"__typename":"VariantFlagString","value":"4a442ace1476"}},{"__typename":"VariantFlag","name":"enable_android_dynamic_programming_paywall","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_in_app_free_trial","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_pp_dashboard_referred_earnings","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_speechify_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_autorefresh","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_display_paywall_after_onboarding","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_verified_book_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_maim_the_meter","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_easy_resubscribe","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_enable_home_post_menu","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"coronavirus_topic_recirc","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_group_gifting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_paypal","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rex_aggregator_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_iceland_forced_android","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_ios_dynamic_paywall_programming","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"author_fair_distribution_non_qp3","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_verified_author","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"available_monthly_premium_plan","valueType":{"__typename":"VariantFlagString","value":"12a660186432"}},{"__typename":"VariantFlag","name":"bevy_rds_double_write","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_lists_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_topic_portals","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_tipping_v0_ios","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"redefined_top_posts","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_google_webhook","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"web_enable_syntax_highlighting","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_rito_upstream_deadlines","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"android_enable_image_sharer","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_mastodon_for_members_username_selection","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_android_offline_reading","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_annual_renewal_reminder_email","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_entities_to_follow_v2","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_footer_app_buttons","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_trial_membership","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_braintree_integration","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"textshots_userid","valueType":{"__typename":"VariantFlagString","value":""}},{"__typename":"VariantFlag","name":"enable_pre_pp_v4","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_signup_friction","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"enable_apple_sign_in","valueType":{"__typename":"VariantFlagBoolean","value":true}},{"__typename":"VariantFlag","name":"ios_remove_twitter_onboarding_step","valueType":{"__typename":"VariantFlagBoolean","value":true}}],"collectionByDomainOrSlug({\"domainOrSlug\":\"towardsdatascience.com\"})":{"__ref":"Collection:7f60cf5620c9"},"postResult({\"id\":\"8daf784f46f8\"})":{"__ref":"Post:8daf784f46f8"},"post({\"id\":\"8daf784f46f8\"})":{"__ref":"Post:8daf784f46f8"},"authorCollectionRecircFeed({\"input\":{\"authorId\":\"741c1c8fcfbd\",\"collectionId\":\"7f60cf5620c9\",\"paging\":{\"limit\":4},\"postId\":\"8daf784f46f8\"}})":{"__typename":"AuthorCollectionRecircFeedResult","items":[{"__typename":"HomeFeedItem","post":{"__ref":"Post:9fd028a0c9ee"},"feedId":"5fa22b32-2ef4-43a3-805e-702fd81d69ba"},{"__typename":"HomeFeedItem","post":{"__ref":"Post:94654b1eaba7"},"feedId":"5fa22b32-2ef4-43a3-805e-702fd81d69ba"},{"__typename":"HomeFeedItem","post":{"__ref":"Post:56f49746aa7b"},"feedId":"5fa22b32-2ef4-43a3-805e-702fd81d69ba"},{"__typename":"HomeFeedItem","post":{"__ref":"Post:70d476bfe775"},"feedId":"5fa22b32-2ef4-43a3-805e-702fd81d69ba"}]},"recirc({\"paging\":{\"limit\":6},\"postId\":\"8daf784f46f8\"})":{"__typename":"RexRecircResult","items":[{"__typename":"RexRecircItem","feedId":"b89fae87-3752-4aed-ae86-afe43101b8c6","post":{"__ref":"Post:426d5e3f7d05"}},{"__typename":"RexRecircItem","feedId":"b89fae87-3752-4aed-ae86-afe43101b8c6","post":{"__ref":"Post:f07f9e55fe01"}},{"__typename":"RexRecircItem","feedId":"b89fae87-3752-4aed-ae86-afe43101b8c6","post":{"__ref":"Post:2379699e2b51"}},{"__typename":"RexRecircItem","feedId":"b89fae87-3752-4aed-ae86-afe43101b8c6","post":{"__ref":"Post:d7b83f94c4e"}},{"__typename":"RexRecircItem","feedId":"b89fae87-3752-4aed-ae86-afe43101b8c6","post":{"__ref":"Post:ed197f252c6a"}},{"__typename":"RexRecircItem","feedId":"b89fae87-3752-4aed-ae86-afe43101b8c6","post":{"__ref":"Post:3c81a8bffaf2"}}]},"postCatalogRecirc({\"pagingOptions\":{\"limit\":4},\"postId\":\"8daf784f46f8\"})":{"__typename":"CatalogsConnection","catalogs":[{"__ref":"Catalog:0a856388a93a"},{"__ref":"Catalog:dfa78dfd2438"},{"__ref":"Catalog:b4c47b8e12ee"},{"__ref":"Catalog:3742c7a4727d"}]}},"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png":{"__typename":"ImageMetadata","id":"1*VzTUkfeGymHP4Bvav-T-lA.png"},"Collection:7f60cf5620c9":{"__typename":"Collection","id":"7f60cf5620c9","favicon":{"__ref":"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png"},"customStyleSheet":null,"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"googleAnalyticsId":null,"editors":[{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:7e12c71dfa81"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:e6ad8abedec9"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:895063a310f4"}}],"name":"Towards Data Science","avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"domain":"towardsdatascience.com","slug":"towards-data-science","description":"Your home for data science. A Medium publication sharing concepts, ideas and codes.","subscriberCount":673078,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_f623f4931b0c"},"twitterUsername":"TDataScience","facebookPageId":null,"logo":{"__ref":"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"User:7e12c71dfa81":{"__typename":"User","id":"7e12c71dfa81"},"User:e6ad8abedec9":{"__typename":"User","id":"e6ad8abedec9"},"User:895063a310f4":{"__typename":"User","id":"895063a310f4"},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"__typename":"ImageMetadata","id":"1*CJe3891yB1A1mzMdqemkdg.jpeg"},"LinkedAccounts:741c1c8fcfbd":{"__typename":"LinkedAccounts","mastodon":null,"id":"741c1c8fcfbd"},"UserViewerEdge:userId:741c1c8fcfbd-viewerId:lo_f623f4931b0c":{"__typename":"UserViewerEdge","id":"userId:741c1c8fcfbd-viewerId:lo_f623f4931b0c","isFollowing":false,"isUser":false},"NewsletterV3:9835bccb3d51":{"__typename":"NewsletterV3","id":"9835bccb3d51","type":"NEWSLETTER_TYPE_AUTHOR","slug":"741c1c8fcfbd","name":"741c1c8fcfbd","collection":null,"user":{"__ref":"User:741c1c8fcfbd"}},"User:741c1c8fcfbd":{"__typename":"User","id":"741c1c8fcfbd","name":"Marco Peixeiro","username":"marcopeixeiro","newsletterV3":{"__ref":"NewsletterV3:9835bccb3d51"},"linkedAccounts":{"__ref":"LinkedAccounts:741c1c8fcfbd"},"isSuspended":false,"imageId":"1*0HKbgLGe-BeQE3o240uafw.jpeg","mediumMemberAt":0,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":true},"socialStats":{"__typename":"SocialStats","followerCount":10573},"customDomainState":null,"hasSubdomain":false,"bio":"Senior data scientist | Author | Instructor. I write hands-on articles with a focus on practical skills.","isPartnerProgramEnrolled":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:741c1c8fcfbd-viewerId:lo_f623f4931b0c"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"membership":null,"twitterScreenName":""},"Topic:1af65db9c2f8":{"__typename":"Topic","slug":"artificial-intelligence","id":"1af65db9c2f8","name":"Artificial Intelligence"},"Paragraph:95a88e34a47d_0":{"__typename":"Paragraph","id":"95a88e34a47d_0","name":"2e03","type":"H3","href":null,"layout":null,"metadata":null,"text":"Catch Up On Large Language Models","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_1":{"__typename":"Paragraph","id":"95a88e34a47d_1","name":"b445","type":"H4","href":null,"layout":null,"metadata":null,"text":"A practical guide to large language models without the hype","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*0sgM1HGAs_IcVD2U":{"__typename":"ImageMetadata","id":"0*0sgM1HGAs_IcVD2U","originalHeight":3648,"originalWidth":5472,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_2":{"__typename":"Paragraph","id":"95a88e34a47d_2","name":"77be","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*0sgM1HGAs_IcVD2U"},"text":"Photo by Gary Bendig on Unsplash","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":9,"end":20,"href":"https:\u002F\u002Funsplash.com\u002F@kris_ricepees?utm_source=medium&utm_medium=referral","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"A","start":24,"end":32,"href":"https:\u002F\u002Funsplash.com?utm_source=medium&utm_medium=referral","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_3":{"__typename":"Paragraph","id":"95a88e34a47d_3","name":"a456","type":"P","href":null,"layout":null,"metadata":null,"text":"If you are here, it means that like me you were overwhelmed by the constant flow of information, and hype posts surrounding large language models (LLMs).","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":124,"end":145,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_4":{"__typename":"Paragraph","id":"95a88e34a47d_4","name":"5d3d","type":"P","href":null,"layout":null,"metadata":null,"text":"This article is my attempt at helping you catch up on the subject of large language models without the hype. After all, it is a transformative technology, and I believe it is important for us to understand it, hopefully making you curious to learn even more and build something with it.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_5":{"__typename":"Paragraph","id":"95a88e34a47d_5","name":"2881","type":"P","href":null,"layout":null,"metadata":null,"text":"In the following sections, we will define what LLMs are and how they work, of course covering the Transformer architecture. We also explore the different methods of training LLMs and conclude the article with a hands-on project where we use Flan-T5 for sentiment analysis using Python.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_6":{"__typename":"Paragraph","id":"95a88e34a47d_6","name":"72ef","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s get started!","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_7":{"__typename":"Paragraph","id":"95a88e34a47d_7","name":"cd3e","type":"H3","href":null,"layout":null,"metadata":null,"text":"LLMs and generative AI: are they the same thing?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_8":{"__typename":"Paragraph","id":"95a88e34a47d_8","name":"cf4d","type":"P","href":null,"layout":null,"metadata":null,"text":"Generative AI is a subset of machine learning that focuses on models who’s primary function is to generate something: text, images, video, code, etc.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":107,"end":116,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_9":{"__typename":"Paragraph","id":"95a88e34a47d_9","name":"1d26","type":"P","href":null,"layout":null,"metadata":null,"text":"Generative models train on enormous amounts of data created by humans to learn patterns and structure which allow them to create new data.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_10":{"__typename":"Paragraph","id":"95a88e34a47d_10","name":"6699","type":"P","href":null,"layout":null,"metadata":null,"text":"Examples of generative models include:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_11":{"__typename":"Paragraph","id":"95a88e34a47d_11","name":"557f","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Image generation: DALL-E, Midjourney","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_12":{"__typename":"Paragraph","id":"95a88e34a47d_12","name":"5b28","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Code generation: OpenAI Codex","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_13":{"__typename":"Paragraph","id":"95a88e34a47d_13","name":"6009","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Text generation: GPT-3, Flan-T5, LLaMA","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":15,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_14":{"__typename":"Paragraph","id":"95a88e34a47d_14","name":"4441","type":"P","href":null,"layout":null,"metadata":null,"text":"Large language models are part of the generative AI landscape, since they take an input text and repeatedly predict the next word until the output is complete.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_15":{"__typename":"Paragraph","id":"95a88e34a47d_15","name":"0960","type":"P","href":null,"layout":null,"metadata":null,"text":"However, as language models grew larger, they were able to perform other tasks in natural language processing, like summarization, sentiment analysis, named entity recognition, translation and more.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_16":{"__typename":"Paragraph","id":"95a88e34a47d_16","name":"7f42","type":"P","href":null,"layout":null,"metadata":null,"text":"With that in mind, let’s now focus our attention on how LLMs work.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_17":{"__typename":"Paragraph","id":"95a88e34a47d_17","name":"bf72","type":"H3","href":null,"layout":null,"metadata":null,"text":"How LLMs work","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_18":{"__typename":"Paragraph","id":"95a88e34a47d_18","name":"482a","type":"P","href":null,"layout":null,"metadata":null,"text":"One of the reasons why we now have large language models is because of the seminal work of Google and University of Toronto when they released the paper Attention Is All You Need in 2017.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":153,"end":178,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.03762","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_19":{"__typename":"Paragraph","id":"95a88e34a47d_19","name":"6c51","type":"P","href":null,"layout":null,"metadata":null,"text":"This paper introduced the Transformer architecture, which is behind the LLMs we know and use today.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":26,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_20":{"__typename":"Paragraph","id":"95a88e34a47d_20","name":"3706","type":"P","href":null,"layout":null,"metadata":null,"text":"This architecture unlocked large scale models, making it possible to train very large models on multiple GPUs, and the models are able to process the inputs in parallel, giving them the opportunity to treat very large sequences of data.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_21":{"__typename":"Paragraph","id":"95a88e34a47d_21","name":"e2b0","type":"H4","href":null,"layout":null,"metadata":null,"text":"Overview of the Transformer architecture","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_22":{"__typename":"Paragraph","id":"95a88e34a47d_22","name":"7596","type":"P","href":null,"layout":null,"metadata":null,"text":"The following is meant to be a high-level overview of the Transformer architecture. There are many resources that dive deeper into it, but the goal here is just to understand the way it works so we can understand how different LLMs specialize in different tasks.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_23":{"__typename":"Paragraph","id":"95a88e34a47d_23","name":"339f","type":"P","href":null,"layout":null,"metadata":null,"text":"At any time, for more details, I suggest you read the original paper.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":54,"end":68,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F1706.03762.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_24":{"__typename":"Paragraph","id":"95a88e34a47d_24","name":"ba14","type":"P","href":null,"layout":null,"metadata":null,"text":"So, let’s start with a simplified visualization of the Transformer architecture.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*R6-UardPkvP1qGuwuZYIxA.png":{"__typename":"ImageMetadata","id":"1*R6-UardPkvP1qGuwuZYIxA.png","originalHeight":1185,"originalWidth":772,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_25":{"__typename":"Paragraph","id":"95a88e34a47d_25","name":"8ef5","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*R6-UardPkvP1qGuwuZYIxA.png"},"text":"A simplified visualization of the Transformer architecture. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_26":{"__typename":"Paragraph","id":"95a88e34a47d_26","name":"8f06","type":"P","href":null,"layout":null,"metadata":null,"text":"From the figure above, we can see that the main components of the Transformer are the encoder and decoder. Inside each, we also find the attention component.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":137,"end":146,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_27":{"__typename":"Paragraph","id":"95a88e34a47d_27","name":"64d2","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s explore each component in more detail to understand how the Transformer architecture works.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_28":{"__typename":"Paragraph","id":"95a88e34a47d_28","name":"a633","type":"H4","href":null,"layout":null,"metadata":null,"text":"Tokenize the inputs","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_29":{"__typename":"Paragraph","id":"95a88e34a47d_29","name":"801f","type":"P","href":null,"layout":null,"metadata":null,"text":"We know LLMs work with text, but computers work with numbers, not letters. Therefore, the input must be tokenized.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":104,"end":113,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_30":{"__typename":"Paragraph","id":"95a88e34a47d_30","name":"d199","type":"P","href":null,"layout":null,"metadata":null,"text":"Tokenization is the process in which words of a sentence are represented as numbers.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_31":{"__typename":"Paragraph","id":"95a88e34a47d_31","name":"007a","type":"P","href":null,"layout":null,"metadata":null,"text":"Basically, every possible word a model can work with is in a dictionary with a number associated to it. With tokenization, we can retrieve the number associated with the word, to represent a sentence as a sequence of numbers, as shown below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*yeSEOW_WS0Cv5De_rUwpTQ.png":{"__typename":"ImageMetadata","id":"1*yeSEOW_WS0Cv5De_rUwpTQ.png","originalHeight":860,"originalWidth":1245,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_32":{"__typename":"Paragraph","id":"95a88e34a47d_32","name":"4ad0","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*yeSEOW_WS0Cv5De_rUwpTQ.png"},"text":"Example of tokenization. The sentence is tokenized and then sent to the embedding of the Transformer. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_33":{"__typename":"Paragraph","id":"95a88e34a47d_33","name":"1279","type":"P","href":null,"layout":null,"metadata":null,"text":"In the figure above, we see an example of how the sentence “It rained this morning” can be tokenized before being set to the embedding layer of the Transformer.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_34":{"__typename":"Paragraph","id":"95a88e34a47d_34","name":"690d","type":"P","href":null,"layout":null,"metadata":null,"text":"Note that there are many ways of tokenizing a sentence. In the example above, the tokenizer can represents parts of a word, which is why rained is separated into rain and ed. Other tokenizers would have a number for full words only.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":137,"end":143,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":162,"end":167,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":171,"end":173,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_35":{"__typename":"Paragraph","id":"95a88e34a47d_35","name":"9fd1","type":"H4","href":null,"layout":null,"metadata":null,"text":"The word embedding layer","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_36":{"__typename":"Paragraph","id":"95a88e34a47d_36","name":"2c76","type":"P","href":null,"layout":null,"metadata":null,"text":"At this point, we have a series of numbers that represent words, but how can the computer understand their meaning?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_37":{"__typename":"Paragraph","id":"95a88e34a47d_37","name":"7adc","type":"P","href":null,"layout":null,"metadata":null,"text":"This is achieved by the word embedding layers.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_38":{"__typename":"Paragraph","id":"95a88e34a47d_38","name":"8b01","type":"P","href":null,"layout":null,"metadata":null,"text":"Word embedding is a learned representation of words, such that words with a similar meaning will have a similar representation. The model will learn different properties of words and represent them in a fixed space, where each axis can represent the property of a word.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*1jCTO4aexx_rlTIByr8TTw.png":{"__typename":"ImageMetadata","id":"1*1jCTO4aexx_rlTIByr8TTw.png","originalHeight":808,"originalWidth":908,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_39":{"__typename":"Paragraph","id":"95a88e34a47d_39","name":"1645","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*1jCTO4aexx_rlTIByr8TTw.png"},"text":"Visualization of word embeddings. We can see that “morning” and “sunrise” have a similar representation since the angle in the 3D space is smaller. Similarly, “rain” and “thunder” are closer to one another. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_40":{"__typename":"Paragraph","id":"95a88e34a47d_40","name":"edc7","type":"P","href":null,"layout":null,"metadata":null,"text":"In the figure above, we can see how a 3D word embedding can look like. We see that “morning” and “sunrise” are closer to one another, and therefore have a similar representation. This can be can be computed using cosine similarity.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_41":{"__typename":"Paragraph","id":"95a88e34a47d_41","name":"0f7a","type":"P","href":null,"layout":null,"metadata":null,"text":"On the other hand, “rain” and “thunder” are close to each other, and far from “morning” and “sunrise”.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_42":{"__typename":"Paragraph","id":"95a88e34a47d_42","name":"70f3","type":"P","href":null,"layout":null,"metadata":null,"text":"Now, we can only show a 3D space, but in reality, embeddings can have hundreds of dimensions. In fact, the original Transformer architecture used an embedding space of 512 dimensions. This means that the model could learn 512 different properties of words to represent them in a space of 512 dimensions.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_43":{"__typename":"Paragraph","id":"95a88e34a47d_43","name":"00ee","type":"H4","href":null,"layout":null,"metadata":null,"text":"What about word order?","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_44":{"__typename":"Paragraph","id":"95a88e34a47d_44","name":"e761","type":"P","href":null,"layout":null,"metadata":null,"text":"You may have noticed that by representing words in embeddings, we lose their order in the sentence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_45":{"__typename":"Paragraph","id":"95a88e34a47d_45","name":"aef1","type":"P","href":null,"layout":null,"metadata":null,"text":"Of course, with natural language, word order is very important, and so that’s why we use positional encoding, so the model knows the order of the words in a sentence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_46":{"__typename":"Paragraph","id":"95a88e34a47d_46","name":"f865","type":"P","href":null,"layout":null,"metadata":null,"text":"It is the combination of the word embeddings and the positional encoding that gets sent to the encoder.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_47":{"__typename":"Paragraph","id":"95a88e34a47d_47","name":"7c1f","type":"H4","href":null,"layout":null,"metadata":null,"text":"Inside the encoder","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_48":{"__typename":"Paragraph","id":"95a88e34a47d_48","name":"1f71","type":"P","href":null,"layout":null,"metadata":null,"text":"Our inputs travel inside the encoder where they will go through the self-attention mechanism.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":68,"end":82,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_49":{"__typename":"Paragraph","id":"95a88e34a47d_49","name":"5351","type":"P","href":null,"layout":null,"metadata":null,"text":"This is where the model can learn the dependencies between each token in a sentence. It learns the importance of each word in relation to all other words in a sentence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*67N0T5Gl0WsShGMtU8Dcyg.png":{"__typename":"ImageMetadata","id":"1*67N0T5Gl0WsShGMtU8Dcyg.png","originalHeight":433,"originalWidth":693,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_50":{"__typename":"Paragraph","id":"95a88e34a47d_50","name":"b8f5","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*67N0T5Gl0WsShGMtU8Dcyg.png"},"text":"Example of an attention map for the word “rained”. The stroke width is representative of the importance. Here, we can see that “rained” is strongly connected to “this” and “morning”. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_51":{"__typename":"Paragraph","id":"95a88e34a47d_51","name":"f7bd","type":"P","href":null,"layout":null,"metadata":null,"text":"In the figure above, we have a stylized example of an attention map for the word “rained”. The stroke width represents the importance.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_52":{"__typename":"Paragraph","id":"95a88e34a47d_52","name":"961c","type":"P","href":null,"layout":null,"metadata":null,"text":"In this example, we can see that self-attention captures the importance of “rained” with “this” and “morning”, meaning that it understands the context of this sentence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_53":{"__typename":"Paragraph","id":"95a88e34a47d_53","name":"7a69","type":"P","href":null,"layout":null,"metadata":null,"text":"While this example remains simple, since we have a very short sentence, the self-attention mechanism works very well on longer sentences, effectively capturing context and the overall meaning of a sentence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_54":{"__typename":"Paragraph","id":"95a88e34a47d_54","name":"5c17","type":"P","href":null,"layout":null,"metadata":null,"text":"Furthermore, the model does not have a single attention head. In fact, it has multiple attention heads, also called multi-headed self-attention, where each head can learn a different aspect of language.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":116,"end":143,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_55":{"__typename":"Paragraph","id":"95a88e34a47d_55","name":"b263","type":"P","href":null,"layout":null,"metadata":null,"text":"For example, in the paper Attention Is All You Need, the authors found that one head was involved in anaphora resolution, which is identifying the link between an entity and its repeated references.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":26,"end":51,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F1706.03762.pdf","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":101,"end":120,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*NNf9gN5H9oa7g_Eevf0AUw.png":{"__typename":"ImageMetadata","id":"1*NNf9gN5H9oa7g_Eevf0AUw.png","originalHeight":191,"originalWidth":1415,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_56":{"__typename":"Paragraph","id":"95a88e34a47d_56","name":"f99f","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*NNf9gN5H9oa7g_Eevf0AUw.png"},"text":"Example of anaphora resolution. Here, the word “keys” is referenced again in the sentence as “they”. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_57":{"__typename":"Paragraph","id":"95a88e34a47d_57","name":"7fc3","type":"P","href":null,"layout":null,"metadata":null,"text":"Above, we see an example of anaphora resolution, where the word “keys” is later referenced as “they”, and so one attention head can specialize in identifying those links.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_58":{"__typename":"Paragraph","id":"95a88e34a47d_58","name":"68f6","type":"P","href":null,"layout":null,"metadata":null,"text":"Note that we do not decide what aspect of language each attention head will learn.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_59":{"__typename":"Paragraph","id":"95a88e34a47d_59","name":"aa31","type":"P","href":null,"layout":null,"metadata":null,"text":"At this point, the model has a deep representation of the structure of meaning of a sentence. This is sent to the decoder.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_60":{"__typename":"Paragraph","id":"95a88e34a47d_60","name":"22b1","type":"H4","href":null,"layout":null,"metadata":null,"text":"Inside the decoder","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_61":{"__typename":"Paragraph","id":"95a88e34a47d_61","name":"4afe","type":"P","href":null,"layout":null,"metadata":null,"text":"The decoder accepts a deep representation of the input tokens. This informs the self-attention mechanism inside the decoder.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_62":{"__typename":"Paragraph","id":"95a88e34a47d_62","name":"7751","type":"P","href":null,"layout":null,"metadata":null,"text":"As a reminder, here is the Transformer architecture again, so we can remember what it looks like.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_63":{"__typename":"Paragraph","id":"95a88e34a47d_63","name":"ab15","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*R6-UardPkvP1qGuwuZYIxA.png"},"text":"A simplified visualization of the Transformer architecture. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_64":{"__typename":"Paragraph","id":"95a88e34a47d_64","name":"00ab","type":"P","href":null,"layout":null,"metadata":null,"text":"A start-of-sequence token is inserted as an input of the decoder, to signal it to start generating new tokens.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":2,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_65":{"__typename":"Paragraph","id":"95a88e34a47d_65","name":"51ed","type":"P","href":null,"layout":null,"metadata":null,"text":"New tokens are generated according to the understanding of the input sequence generated by the encoder and its self-attention mechanism.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_66":{"__typename":"Paragraph","id":"95a88e34a47d_66","name":"e0a5","type":"P","href":null,"layout":null,"metadata":null,"text":"In the figure above, we can see that the output of the decoder gets sent to a softmax layer. This generates a vector of probabilities for each possible token. The one with the largest probability is then output by the model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_67":{"__typename":"Paragraph","id":"95a88e34a47d_67","name":"f063","type":"P","href":null,"layout":null,"metadata":null,"text":"That output token is then sent back to the embeddings as an input to the decoder, until an end-of-sequence token is generated by the model. At that point, the output sequence is complete.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":91,"end":106,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_68":{"__typename":"Paragraph","id":"95a88e34a47d_68","name":"545a","type":"P","href":null,"layout":null,"metadata":null,"text":"This concludes the basic architecture behind large language models. With the Transformer architecture and its ability to process data in parallel, it was possible to train models on huge amounts of data, making LLMs a reality.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_69":{"__typename":"Paragraph","id":"95a88e34a47d_69","name":"da16","type":"P","href":null,"layout":null,"metadata":null,"text":"Now, there is more to this, as LLMs do not all use the full Transformer architecture, and that influences the way they are trained. Let’s explore this in more detail.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_70":{"__typename":"Paragraph","id":"95a88e34a47d_70","name":"34f3","type":"H3","href":null,"layout":null,"metadata":null,"text":"How LLMs are trained","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_71":{"__typename":"Paragraph","id":"95a88e34a47d_71","name":"bf67","type":"P","href":null,"layout":null,"metadata":null,"text":"We have seen the underlying mechanisms that power large language models, and as mentioned, not all models use the full Transformer architecture.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_72":{"__typename":"Paragraph","id":"95a88e34a47d_72","name":"9974","type":"P","href":null,"layout":null,"metadata":null,"text":"In fact, some models may use the encoder portion only, while others use the decoder portion only.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_73":{"__typename":"Paragraph","id":"95a88e34a47d_73","name":"1c04","type":"P","href":null,"layout":null,"metadata":null,"text":"This means that the models are also trained differently and will therefore specialize in particular tasks.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_74":{"__typename":"Paragraph","id":"95a88e34a47d_74","name":"d70e","type":"H4","href":null,"layout":null,"metadata":null,"text":"Encoder-only models","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_75":{"__typename":"Paragraph","id":"95a88e34a47d_75","name":"0eab","type":"P","href":null,"layout":null,"metadata":null,"text":"Encoder-only models, also called autoencoding models are best suited for tasks like sentiment analysis, named entity recognition, and word classification","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":33,"end":45,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_76":{"__typename":"Paragraph","id":"95a88e34a47d_76","name":"0b56","type":"P","href":null,"layout":null,"metadata":null,"text":"Popular examples of autoencoding models are BERT and ROBERTA.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_77":{"__typename":"Paragraph","id":"95a88e34a47d_77","name":"8ed3","type":"P","href":null,"layout":null,"metadata":null,"text":"Those models are trained using masked language modeling (MLM). With that training method, words in an input sentence are randomly masked, and the objective of the model is then to reconstruct the original text.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":31,"end":55,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*wt6YLLnOl_bLCFiUUjzaGw.png":{"__typename":"ImageMetadata","id":"1*wt6YLLnOl_bLCFiUUjzaGw.png","originalHeight":838,"originalWidth":818,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_78":{"__typename":"Paragraph","id":"95a88e34a47d_78","name":"d680","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*wt6YLLnOl_bLCFiUUjzaGw.png"},"text":"Illustrating masked language modeling (MLM) for autoencoding models. Here, a random word was masked in the input sentence, and the model must reconstruct the original sentence. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_79":{"__typename":"Paragraph","id":"95a88e34a47d_79","name":"fc39","type":"P","href":null,"layout":null,"metadata":null,"text":"In the figure above, we can see what masked language modeling looks like. A word is hidden and the sentence is fed to the model, which must then learn to predict the right word to get the correct original sentence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_80":{"__typename":"Paragraph","id":"95a88e34a47d_80","name":"1486","type":"P","href":null,"layout":null,"metadata":null,"text":"With that method, autoencoding models develop bidrectional context, since they see what precedes and follows the token they must predict, and not just what comes before.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":46,"end":66,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_81":{"__typename":"Paragraph","id":"95a88e34a47d_81","name":"d033","type":"P","href":null,"layout":null,"metadata":null,"text":"Again, in the figure above, the model sees “it rained” and “morning”, so it sees both the beginning and the end of the sentence, allowing it to predict the word “this” to reconstruct the sentence correctly.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_82":{"__typename":"Paragraph","id":"95a88e34a47d_82","name":"a528","type":"P","href":null,"layout":null,"metadata":null,"text":"Note that with autoencoding models, the input and output sequences have the same length.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_83":{"__typename":"Paragraph","id":"95a88e34a47d_83","name":"d4c1","type":"H4","href":null,"layout":null,"metadata":null,"text":"Decoder-only models","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_84":{"__typename":"Paragraph","id":"95a88e34a47d_84","name":"b28c","type":"P","href":null,"layout":null,"metadata":null,"text":"Decoder-only models are also called autoregressive models. These models are best suited for text generation, but new functions arise when the models get very large.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":36,"end":51,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_85":{"__typename":"Paragraph","id":"95a88e34a47d_85","name":"6177","type":"P","href":null,"layout":null,"metadata":null,"text":"Example of autoregressive models are GPT and BLOOM.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_86":{"__typename":"Paragraph","id":"95a88e34a47d_86","name":"89fc","type":"P","href":null,"layout":null,"metadata":null,"text":"These models are trained using causal language modeling (CLM). With causal language modeling, the model only sees the tokens preceding the mask, meaning that it does not see the end of the sequence.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":31,"end":55,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*aKCJpE4rEvP8Gg4MhweBeA.png":{"__typename":"ImageMetadata","id":"1*aKCJpE4rEvP8Gg4MhweBeA.png","originalHeight":838,"originalWidth":888,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_87":{"__typename":"Paragraph","id":"95a88e34a47d_87","name":"7df7","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*aKCJpE4rEvP8Gg4MhweBeA.png"},"text":"Illustrating causal language modeling. Here, the model only sees the tokens leading to the mask. Then, it must infer the next tokens until the sentence is complete. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_88":{"__typename":"Paragraph","id":"95a88e34a47d_88","name":"d500","type":"P","href":null,"layout":null,"metadata":null,"text":"As we see above, with causal language modeling, the model only sees the tokens leading to the mask, and not what comes after. Then, it must predict the next tokens until the sentence is complete.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_89":{"__typename":"Paragraph","id":"95a88e34a47d_89","name":"8976","type":"P","href":null,"layout":null,"metadata":null,"text":"In the example above, the model would output “this”, and that token would be fed back as an input, so the model can then predict “morning”.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_90":{"__typename":"Paragraph","id":"95a88e34a47d_90","name":"fd66","type":"P","href":null,"layout":null,"metadata":null,"text":"Unlike masked language modeling, model build unidirectional context, since they do not see what comes after the mask.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_91":{"__typename":"Paragraph","id":"95a88e34a47d_91","name":"f1b8","type":"P","href":null,"layout":null,"metadata":null,"text":"Of course, with decoder-only models, the output sequence can have a different length than the input sequence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_92":{"__typename":"Paragraph","id":"95a88e34a47d_92","name":"aa17","type":"H4","href":null,"layout":null,"metadata":null,"text":"Encoder-decoder models","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_93":{"__typename":"Paragraph","id":"95a88e34a47d_93","name":"3aa4","type":"P","href":null,"layout":null,"metadata":null,"text":"Encoder-decoder models are also called sequence-to-sequence models, and they use the full Transformer architecture.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":39,"end":60,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_94":{"__typename":"Paragraph","id":"95a88e34a47d_94","name":"d8d9","type":"P","href":null,"layout":null,"metadata":null,"text":"Those models are often used for translation, text summarization and question answering.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_95":{"__typename":"Paragraph","id":"95a88e34a47d_95","name":"6cf4","type":"P","href":null,"layout":null,"metadata":null,"text":"Popular examples of sequence-to-sequence models are T5 and BART.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_96":{"__typename":"Paragraph","id":"95a88e34a47d_96","name":"028c","type":"P","href":null,"layout":null,"metadata":null,"text":"To train these models, the span corruption method is used. Here, a random sequence of tokens is masked and designated as a sentinel token. Then, the model must reconstruct the masked sequence autoregressively.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":27,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":123,"end":131,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*D6wZ3fShZXtUsOCpJo3Esg.png":{"__typename":"ImageMetadata","id":"1*D6wZ3fShZXtUsOCpJo3Esg.png","originalHeight":982,"originalWidth":820,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_97":{"__typename":"Paragraph","id":"95a88e34a47d_97","name":"ee3b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*D6wZ3fShZXtUsOCpJo3Esg.png"},"text":"Illustration of span corruption. Here, a sequence of tokens is masked and replaced by a sentinel token. The model must then reconstructed the masked sequence autoregressively. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_98":{"__typename":"Paragraph","id":"95a88e34a47d_98","name":"5856","type":"P","href":null,"layout":null,"metadata":null,"text":"In the figure above, we can see that a sequence of two tokens were masked and replaced by a sentinel token. The model is then trained to reconstruct the sentinel token to obtain the original sentence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_99":{"__typename":"Paragraph","id":"95a88e34a47d_99","name":"6973","type":"P","href":null,"layout":null,"metadata":null,"text":"Here, the masked input is sent to the encoder, and the decoder is responsible for reconstructing the masked sequence.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_100":{"__typename":"Paragraph","id":"95a88e34a47d_100","name":"2bd1","type":"H4","href":null,"layout":null,"metadata":null,"text":"A note on model size","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_101":{"__typename":"Paragraph","id":"95a88e34a47d_101","name":"1c43","type":"P","href":null,"layout":null,"metadata":null,"text":"While we have specified certain tasks for which certain models perform best, researchers have observed that large models are capable of various tasks.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_102":{"__typename":"Paragraph","id":"95a88e34a47d_102","name":"453a","type":"P","href":null,"layout":null,"metadata":null,"text":"Therefore, very large decoder-only models can be very good at translation, even though encoder-decoder models specialize in that task.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_103":{"__typename":"Paragraph","id":"95a88e34a47d_103","name":"184c","type":"P","href":null,"layout":null,"metadata":null,"text":"With all of that in mind, let’s now start working with a large language in Python.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_104":{"__typename":"Paragraph","id":"95a88e34a47d_104","name":"da1a","type":"H3","href":null,"layout":null,"metadata":null,"text":"Work with a large language model","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_105":{"__typename":"Paragraph","id":"95a88e34a47d_105","name":"3c05","type":"P","href":null,"layout":null,"metadata":null,"text":"Before we get hands-on experience with a large language model, let’s just cover some technical terms involved when working with LLMs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_106":{"__typename":"Paragraph","id":"95a88e34a47d_106","name":"e53f","type":"P","href":null,"layout":null,"metadata":null,"text":"First, the text that we feed the LLM is called prompt, and the output of the model is called completion.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":47,"end":53,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":93,"end":103,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*kl7LZTzyN81aQdRe5dqSDA.png":{"__typename":"ImageMetadata","id":"1*kl7LZTzyN81aQdRe5dqSDA.png","originalHeight":250,"originalWidth":1416,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_107":{"__typename":"Paragraph","id":"95a88e34a47d_107","name":"c48d","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*kl7LZTzyN81aQdRe5dqSDA.png"},"text":"The prompt is the text we feed to the model with the instructions. The output of the model is called completion. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_108":{"__typename":"Paragraph","id":"95a88e34a47d_108","name":"3553","type":"P","href":null,"layout":null,"metadata":null,"text":"Inside the prompt is where we give the instructions to the LLM to achieve the task that we want.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_109":{"__typename":"Paragraph","id":"95a88e34a47d_109","name":"e3a5","type":"P","href":null,"layout":null,"metadata":null,"text":"This is also where prompt engineering is performed. With prompt engineering, we can perform in-context learning, which is when we give examples to the model of how certain tasks should be performed. We will see an example of that later on.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":19,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":92,"end":111,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_110":{"__typename":"Paragraph","id":"95a88e34a47d_110","name":"086f","type":"P","href":null,"layout":null,"metadata":null,"text":"For now, let’s interact with an LLM using Python for sentiment analysis.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_111":{"__typename":"Paragraph","id":"95a88e34a47d_111","name":"c084","type":"H3","href":null,"layout":null,"metadata":null,"text":"Hands-on project: sentiment analysis with Flan-T5","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_112":{"__typename":"Paragraph","id":"95a88e34a47d_112","name":"10e1","type":"P","href":null,"layout":null,"metadata":null,"text":"For this mini project, we use Flan-T5 for sentiment analysis of various financial news.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_113":{"__typename":"Paragraph","id":"95a88e34a47d_113","name":"6069","type":"P","href":null,"layout":null,"metadata":null,"text":"Flan-T5 is an improved version of the T5 model, which is a sequence-to-sequence model. Researchers basically took the T5 model and fine-tuned it on different tasks covering more languages. For more details, you can refer to the original paper.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":228,"end":242,"href":"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2210.11416.pdf","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_114":{"__typename":"Paragraph","id":"95a88e34a47d_114","name":"dc44","type":"P","href":null,"layout":null,"metadata":null,"text":"As for the dataset, we will use the financial_phrasebank dataset published by Pekka Malo and Ankur Sinha under the Creative Commons Attribute license.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":36,"end":56,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_115":{"__typename":"Paragraph","id":"95a88e34a47d_115","name":"e014","type":"P","href":null,"layout":null,"metadata":null,"text":"The dataset contains a total of 4840 sentences from English language financial news that were categorized as positive, negative or neutral. A group of five to eight annotators classified each sentence, and depending on the agreement rate, the size of the dataset will vary (4850 rows for a 50% agreement rate, and 2260 rows for a 100% agreement rate).","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_116":{"__typename":"Paragraph","id":"95a88e34a47d_116","name":"10bc","type":"P","href":null,"layout":null,"metadata":null,"text":"For more information on the dataset and how it was compiled, refer to the full dataset details page.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":74,"end":100,"href":"https:\u002F\u002Fhuggingface.co\u002Fdatasets\u002Ffinancial_phrasebank","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_117":{"__typename":"Paragraph","id":"95a88e34a47d_117","name":"d327","type":"P","href":null,"layout":null,"metadata":null,"text":"Of course, all code show below is available on GitHub.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":47,"end":53,"href":"https:\u002F\u002Fgithub.com\u002Fmarcopeix\u002Flearn_llm\u002Fblob\u002Fmain\u002F1_llm_get_started.ipynb","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_118":{"__typename":"Paragraph","id":"95a88e34a47d_118","name":"88df","type":"H4","href":null,"layout":null,"metadata":null,"text":"Setup your environment","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_119":{"__typename":"Paragraph","id":"95a88e34a47d_119","name":"8313","type":"P","href":null,"layout":null,"metadata":null,"text":"For the following experiment to work, make sure to have a virtual environment with the following packages installed:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_120":{"__typename":"Paragraph","id":"95a88e34a47d_120","name":"f6be","type":"ULI","href":null,"layout":null,"metadata":null,"text":"torch","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_121":{"__typename":"Paragraph","id":"95a88e34a47d_121","name":"4deb","type":"ULI","href":null,"layout":null,"metadata":null,"text":"torchdata","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_122":{"__typename":"Paragraph","id":"95a88e34a47d_122","name":"8d40","type":"ULI","href":null,"layout":null,"metadata":null,"text":"transformers","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_123":{"__typename":"Paragraph","id":"95a88e34a47d_123","name":"ffe1","type":"ULI","href":null,"layout":null,"metadata":null,"text":"datasets","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_124":{"__typename":"Paragraph","id":"95a88e34a47d_124","name":"4622","type":"ULI","href":null,"layout":null,"metadata":null,"text":"pandas","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_125":{"__typename":"Paragraph","id":"95a88e34a47d_125","name":"9d7c","type":"ULI","href":null,"layout":null,"metadata":null,"text":"matplotlib","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_126":{"__typename":"Paragraph","id":"95a88e34a47d_126","name":"1ae5","type":"ULI","href":null,"layout":null,"metadata":null,"text":"scikit-learn","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_127":{"__typename":"Paragraph","id":"95a88e34a47d_127","name":"4863","type":"P","href":null,"layout":null,"metadata":null,"text":"Note that the libraries transformers and datasets are from HuggingFace, making it super easy for us to access and experiment with LLMs.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":24,"end":37,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":41,"end":49,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_128":{"__typename":"Paragraph","id":"95a88e34a47d_128","name":"5450","type":"P","href":null,"layout":null,"metadata":null,"text":"Once the environment is setup, we can start by importing the required libraries.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_129":{"__typename":"Paragraph","id":"95a88e34a47d_129","name":"46a9","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom datasets import load_dataset\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_130":{"__typename":"Paragraph","id":"95a88e34a47d_130","name":"5a55","type":"H4","href":null,"layout":null,"metadata":null,"text":"Load the data","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_131":{"__typename":"Paragraph","id":"95a88e34a47d_131","name":"d0e3","type":"P","href":null,"layout":null,"metadata":null,"text":"Then, we can load our dataset. Here, we use the dataset with 100% agreement rate.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_132":{"__typename":"Paragraph","id":"95a88e34a47d_132","name":"317e","type":"PRE","href":null,"layout":null,"metadata":null,"text":"dataset_name = \"financial_phrasebank\"\n\ndataset = load_dataset(dataset_name, \"sentences_allagree\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_133":{"__typename":"Paragraph","id":"95a88e34a47d_133","name":"0404","type":"P","href":null,"layout":null,"metadata":null,"text":"This dataset contains a total of 2264 sentences.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_134":{"__typename":"Paragraph","id":"95a88e34a47d_134","name":"4d56","type":"P","href":null,"layout":null,"metadata":null,"text":"Note that the label is encoded. 1 means neutral, 0 means negative and 2 means positive. The count of each label is shown below.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*c8vK07LrsZCQMxpgszREbw.png":{"__typename":"ImageMetadata","id":"1*c8vK07LrsZCQMxpgszREbw.png","originalHeight":519,"originalWidth":705,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_135":{"__typename":"Paragraph","id":"95a88e34a47d_135","name":"01c8","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*c8vK07LrsZCQMxpgszREbw.png"},"text":"Frequency of each sentiment in the dataset. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_136":{"__typename":"Paragraph","id":"95a88e34a47d_136","name":"fba0","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s store the actual label of each sentence in a DataFrame, making it easier for us to evaluate the model later on.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_137":{"__typename":"Paragraph","id":"95a88e34a47d_137","name":"2fc0","type":"PRE","href":null,"layout":null,"metadata":null,"text":"labels_df = pd.DataFrame()\n\nlabels_from_dataset = [dataset['train'][i]['label'] for i in range(2264)]\n\nlabels_df['labels'] = labels_from_dataset","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_138":{"__typename":"Paragraph","id":"95a88e34a47d_138","name":"b27b","type":"H4","href":null,"layout":null,"metadata":null,"text":"Load the model","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_139":{"__typename":"Paragraph","id":"95a88e34a47d_139","name":"64e5","type":"P","href":null,"layout":null,"metadata":null,"text":"Now, let’s load the model as well as the tokenizer. As mentioned above, we will load the Flan-T5 model. Note that the model is available in different sizes, but I decided to use the base version.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_140":{"__typename":"Paragraph","id":"95a88e34a47d_140","name":"cc5d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"model_name = \"google\u002Fflan-t5-base\"\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_141":{"__typename":"Paragraph","id":"95a88e34a47d_141","name":"dfcc","type":"P","href":null,"layout":null,"metadata":null,"text":"That’s it! We can now use this LLM to perform sentiment analysis on our dataset.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_142":{"__typename":"Paragraph","id":"95a88e34a47d_142","name":"7517","type":"H4","href":null,"layout":null,"metadata":null,"text":"Prompt the model for sentiment analysis","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_143":{"__typename":"Paragraph","id":"95a88e34a47d_143","name":"7a96","type":"P","href":null,"layout":null,"metadata":null,"text":"For the model to perform sentiment analysis, we need to do prompt engineering to specify that task.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_144":{"__typename":"Paragraph","id":"95a88e34a47d_144","name":"1ffe","type":"P","href":null,"layout":null,"metadata":null,"text":"In this case we simply use “Is the following sentence positive, negative or neutral?”. We then pass the sentence of our dataset and let the model infer.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":28,"end":84,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_145":{"__typename":"Paragraph","id":"95a88e34a47d_145","name":"d6b1","type":"P","href":null,"layout":null,"metadata":null,"text":"Note that this is called zero-shot inference, since the model was not specifically trained for this particular task on this specific dataset.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":25,"end":44,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_146":{"__typename":"Paragraph","id":"95a88e34a47d_146","name":"2c5d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"zero_shot_sentiment = []\n\nfor i in range(2264):\n    sentence = dataset['train'][i]['sentence']\n\n    prompt = f\"\"\"\nIs the follwing sentence positive, negative or neutral?\n\n{sentence}\n    \"\"\"\n\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"],\n            max_new_tokens=50\n        )[0],\n        skip_special_tokens=True\n    )\n\n    zero_shot_sentiment.append(output)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_147":{"__typename":"Paragraph","id":"95a88e34a47d_147","name":"2818","type":"P","href":null,"layout":null,"metadata":null,"text":"In the Python code block above, we loop over each sentence in the dataset and pass it in our prompt. The prompt is tokenized and set to the model. We then decode the output to obtain a natural language response. Finally, we store the prediction of the model in a list.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_148":{"__typename":"Paragraph","id":"95a88e34a47d_148","name":"5293","type":"P","href":null,"layout":null,"metadata":null,"text":"Then, let’s add these predictions to our DataFrame.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_149":{"__typename":"Paragraph","id":"95a88e34a47d_149","name":"1df9","type":"PRE","href":null,"layout":null,"metadata":null,"text":"labels_df['zero_shot_sentiment'] = zero_shot_sentiment\nlabels_df['zero_shot_sentiment'] = labels_df['zero_shot_sentiment'].map({'neutral':1, 'positive':2, 'negative':0})","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_150":{"__typename":"Paragraph","id":"95a88e34a47d_150","name":"4184","type":"H4","href":null,"layout":null,"metadata":null,"text":"Evaluate the model","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_151":{"__typename":"Paragraph","id":"95a88e34a47d_151","name":"55e2","type":"P","href":null,"layout":null,"metadata":null,"text":"To evaluate our model, let’s display the confusion matrix of the predictions, as well as the classification report.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_152":{"__typename":"Paragraph","id":"95a88e34a47d_152","name":"3b79","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report\n\ncm = confusion_matrix(labels_df['labels'], labels_df['zero_shot_sentiment'], labels=[0,1,2])\n\ndisp_cm = ConfusionMatrixDisplay(cm, display_labels=[0,1,2])\n\ndisp_cm.plot();\n\nplt.grid(False)\nplt.tight_layout()\n\n\nclf_report = classification_report(labels_df['labels'], labels_df['zero_shot_sentiment'], labels=[0,1,2])\n\nprint(clf_report)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*QRuJ5Bz08a0cfbC8FVS3Lw.png":{"__typename":"ImageMetadata","id":"1*QRuJ5Bz08a0cfbC8FVS3Lw.png","originalHeight":562,"originalWidth":691,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_153":{"__typename":"Paragraph","id":"95a88e34a47d_153","name":"990a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*QRuJ5Bz08a0cfbC8FVS3Lw.png"},"text":"Confusion matrix of zero-shot sentiment analysis on financial news using Flan-T5. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*a5AUQlUFvwgyxE7TJhUV_Q.png":{"__typename":"ImageMetadata","id":"1*a5AUQlUFvwgyxE7TJhUV_Q.png","originalHeight":271,"originalWidth":638,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_154":{"__typename":"Paragraph","id":"95a88e34a47d_154","name":"e9f6","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*a5AUQlUFvwgyxE7TJhUV_Q.png"},"text":"Classification report for zero-shot sentiment analysis. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_155":{"__typename":"Paragraph","id":"95a88e34a47d_155","name":"5d8b","type":"P","href":null,"layout":null,"metadata":null,"text":"From the figure above, we can see that the model found all negative sentences, at the cost of precision since it mislabelled 611 neutral sentences and 92 positive sentences. Also, we can see a clear problem with identifying neutral sentences, as it mislabelled the vast majority.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_156":{"__typename":"Paragraph","id":"95a88e34a47d_156","name":"8d8c","type":"P","href":null,"layout":null,"metadata":null,"text":"Therefore, let’s try to change our prompt to see if we can improve the model’s performance.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_157":{"__typename":"Paragraph","id":"95a88e34a47d_157","name":"84e7","type":"H4","href":null,"layout":null,"metadata":null,"text":"One-shot inference with in-context learning","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_158":{"__typename":"Paragraph","id":"95a88e34a47d_158","name":"bb00","type":"P","href":null,"layout":null,"metadata":null,"text":"Here, we modify our prompt to include an example of a neutral sentence. This technique is called in-context learning, as we pass an example of how the model should behave inside the prompt.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":97,"end":116,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_159":{"__typename":"Paragraph","id":"95a88e34a47d_159","name":"f15a","type":"P","href":null,"layout":null,"metadata":null,"text":"Passing one example is called one-shot inference. It is possible to pass more examples, in which case it becomes few-shot inference.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":30,"end":48,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":113,"end":131,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_160":{"__typename":"Paragraph","id":"95a88e34a47d_160","name":"82eb","type":"P","href":null,"layout":null,"metadata":null,"text":"It is normal to show up to five examples to the LLM. If the performance does not improve, then it is likely that we need to fine-tune the model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_161":{"__typename":"Paragraph","id":"95a88e34a47d_161","name":"6b30","type":"P","href":null,"layout":null,"metadata":null,"text":"For now, let’s see how one example impacts the performance.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_162":{"__typename":"Paragraph","id":"95a88e34a47d_162","name":"dc00","type":"PRE","href":null,"layout":null,"metadata":null,"text":"one_shot_sentiment = []\n\nfor i in range(2264):\n    sentence = dataset['train'][i]['sentence']\n\n    prompt = f\"\"\"\n\nIs the follwing sentence positive, negative or neutral?\n\nStatement: \"According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\"\nneutral\n\nIs the follwing sentence positive, negative or neutral?\nStatement: {sentence}\n\n{sentence}\n    \"\"\"\n\n    inputs = tokenizer(prompt, return_tensors='pt')\n    output = tokenizer.decode(\n        model.generate(\n            inputs[\"input_ids\"],\n            max_new_tokens=50\n        )[0],\n        skip_special_tokens=True\n    )\n\n    one_shot_sentiment.append(output)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_163":{"__typename":"Paragraph","id":"95a88e34a47d_163","name":"da08","type":"P","href":null,"layout":null,"metadata":null,"text":"In the code block above, we see that we give an example of a neutral sentence to help the model identify them. Then, we pass each sentence for the model to classify.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_164":{"__typename":"Paragraph","id":"95a88e34a47d_164","name":"d403","type":"P","href":null,"layout":null,"metadata":null,"text":"Afterwards, we follow the same steps of adding a new columns containing the new predictions, and displaying the confusion matrix.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_165":{"__typename":"Paragraph","id":"95a88e34a47d_165","name":"4c51","type":"PRE","href":null,"layout":null,"metadata":null,"text":"labels_df['one_shot_sentiment'] = one_shot_sentiment\nlabels_df['one_shot_sentiment'] = labels_df['one_shot_sentiment'].map({'neutral':1, 'positive':2, 'negative':0})\n\ncm = confusion_matrix(labels_df['labels'], labels_df['one_shot_sentiment'], labels=[0,1,2])\n\ndisp_cm = ConfusionMatrixDisplay(cm, display_labels=[0,1,2])\n\ndisp_cm.plot();\n\nplt.grid(False)\nplt.tight_layout()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*V5cM_64w0ebsi4_dLUVR8Q.png":{"__typename":"ImageMetadata","id":"1*V5cM_64w0ebsi4_dLUVR8Q.png","originalHeight":733,"originalWidth":866,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_166":{"__typename":"Paragraph","id":"95a88e34a47d_166","name":"8bc2","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*V5cM_64w0ebsi4_dLUVR8Q.png"},"text":"Confusion matrix of one-shot sentiment analysis of financial news using Flan-T5. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*9B1lgOkSfALAyhV8MvmTiA.png":{"__typename":"ImageMetadata","id":"1*9B1lgOkSfALAyhV8MvmTiA.png","originalHeight":263,"originalWidth":624,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_167":{"__typename":"Paragraph","id":"95a88e34a47d_167","name":"9f1c","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*9B1lgOkSfALAyhV8MvmTiA.png"},"text":"Classification report for one-shot sentiment analysis. Image by the author.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_168":{"__typename":"Paragraph","id":"95a88e34a47d_168","name":"c5b7","type":"P","href":null,"layout":null,"metadata":null,"text":"From the figure above, we can see a slight improvement. The weighted F1-score increased from 0.40 to 0.44. The model did better on the neutral class, but at the cost of a worse performance on the positive class.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_169":{"__typename":"Paragraph","id":"95a88e34a47d_169","name":"f6d5","type":"P","href":null,"layout":null,"metadata":null,"text":"Adding examples of positive, negative, and neutral sentences may help, but I did not test it out. Otherwise, fine-tuning the model would be necessary, but that is the subject of another article.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_170":{"__typename":"Paragraph","id":"95a88e34a47d_170","name":"9c3a","type":"H3","href":null,"layout":null,"metadata":null,"text":"Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_171":{"__typename":"Paragraph","id":"95a88e34a47d_171","name":"55d1","type":"P","href":null,"layout":null,"metadata":null,"text":"A lot of concepts were covered in this article, from the understanding the basics of LLMs, to actually using Flan-T5 for sentiment analysis in Python.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_172":{"__typename":"Paragraph","id":"95a88e34a47d_172","name":"6cfd","type":"P","href":null,"layout":null,"metadata":null,"text":"You now have the foundational knowledge to explore this world on your own and see how we can fine-tune LLMs, how we can train one, and how we can build applications around them.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_173":{"__typename":"Paragraph","id":"95a88e34a47d_173","name":"f63c","type":"P","href":null,"layout":null,"metadata":null,"text":"I hope that you learned something new, and that you are curious to learn even more.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_174":{"__typename":"Paragraph","id":"95a88e34a47d_174","name":"04b0","type":"P","href":null,"layout":null,"metadata":null,"text":"Cheers 🍻","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_175":{"__typename":"Paragraph","id":"95a88e34a47d_175","name":"da04","type":"H3","href":null,"layout":null,"metadata":null,"text":"Support me","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_176":{"__typename":"Paragraph","id":"95a88e34a47d_176","name":"2cc1","type":"P","href":null,"layout":null,"metadata":null,"text":"Enjoying my work? Show your support with Buy me a coffee, a simple way for you to encourage me, and I get to enjoy a cup of coffee! If you feel like it, just click the button below 👇","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":41,"end":56,"href":"http:\u002F\u002Fbuymeacoffee.com\u002Fdswm","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*18ybLoAAqbDSo_meOx9xew.png":{"__typename":"ImageMetadata","id":"1*18ybLoAAqbDSo_meOx9xew.png","originalHeight":89,"originalWidth":305,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:95a88e34a47d_177":{"__typename":"Paragraph","id":"95a88e34a47d_177","name":"2610","type":"IMG","href":"http:\u002F\u002Fbuymeacoffee.com\u002Fdswm","layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*18ybLoAAqbDSo_meOx9xew.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_178":{"__typename":"Paragraph","id":"95a88e34a47d_178","name":"0dfa","type":"H3","href":null,"layout":null,"metadata":null,"text":"References","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_179":{"__typename":"Paragraph","id":"95a88e34a47d_179","name":"e291","type":"P","href":null,"layout":null,"metadata":null,"text":"Attention is All You Need — Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":25,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1706.03762","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:95a88e34a47d_180":{"__typename":"Paragraph","id":"95a88e34a47d_180","name":"60fd","type":"P","href":null,"layout":null,"metadata":null,"text":"Generative AI with LLMs — deeplearning.ai","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":22,"href":"https:\u002F\u002Fwww.deeplearning.ai\u002Fcourses\u002Fgenerative-ai-with-llms\u002F","anchorType":"LINK","userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_f623f4931b0c":{"__typename":"CollectionViewerEdge","id":"collectionId:7f60cf5620c9-viewerId:lo_f623f4931b0c","isEditor":false},"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png":{"__typename":"ImageMetadata","id":"1*cFFKn8rFH4ZndmaYeAs6iQ.png","originalWidth":2381,"originalHeight":743},"Tag:artificial-intelligence":{"__typename":"Tag","id":"artificial-intelligence","displayTitle":"Artificial Intelligence","normalizedTagSlug":"artificial-intelligence"},"Tag:nlp":{"__typename":"Tag","id":"nlp","displayTitle":"NLP","normalizedTagSlug":"nlp"},"Tag:large-language-models":{"__typename":"Tag","id":"large-language-models","displayTitle":"Large Language Models","normalizedTagSlug":"large-language-models"},"Tag:deep-learning":{"__typename":"Tag","id":"deep-learning","displayTitle":"Deep Learning","normalizedTagSlug":"deep-learning"},"Tag:editors-pick":{"__typename":"Tag","id":"editors-pick","displayTitle":"Editors Pick","normalizedTagSlug":"editors-pick"},"Post:8daf784f46f8":{"__typename":"Post","id":"8daf784f46f8","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"43b8","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:95a88e34a47d_0"},{"__ref":"Paragraph:95a88e34a47d_1"},{"__ref":"Paragraph:95a88e34a47d_2"},{"__ref":"Paragraph:95a88e34a47d_3"},{"__ref":"Paragraph:95a88e34a47d_4"},{"__ref":"Paragraph:95a88e34a47d_5"},{"__ref":"Paragraph:95a88e34a47d_6"},{"__ref":"Paragraph:95a88e34a47d_7"},{"__ref":"Paragraph:95a88e34a47d_8"},{"__ref":"Paragraph:95a88e34a47d_9"},{"__ref":"Paragraph:95a88e34a47d_10"},{"__ref":"Paragraph:95a88e34a47d_11"},{"__ref":"Paragraph:95a88e34a47d_12"},{"__ref":"Paragraph:95a88e34a47d_13"},{"__ref":"Paragraph:95a88e34a47d_14"},{"__ref":"Paragraph:95a88e34a47d_15"},{"__ref":"Paragraph:95a88e34a47d_16"},{"__ref":"Paragraph:95a88e34a47d_17"},{"__ref":"Paragraph:95a88e34a47d_18"},{"__ref":"Paragraph:95a88e34a47d_19"},{"__ref":"Paragraph:95a88e34a47d_20"},{"__ref":"Paragraph:95a88e34a47d_21"},{"__ref":"Paragraph:95a88e34a47d_22"},{"__ref":"Paragraph:95a88e34a47d_23"},{"__ref":"Paragraph:95a88e34a47d_24"},{"__ref":"Paragraph:95a88e34a47d_25"},{"__ref":"Paragraph:95a88e34a47d_26"},{"__ref":"Paragraph:95a88e34a47d_27"},{"__ref":"Paragraph:95a88e34a47d_28"},{"__ref":"Paragraph:95a88e34a47d_29"},{"__ref":"Paragraph:95a88e34a47d_30"},{"__ref":"Paragraph:95a88e34a47d_31"},{"__ref":"Paragraph:95a88e34a47d_32"},{"__ref":"Paragraph:95a88e34a47d_33"},{"__ref":"Paragraph:95a88e34a47d_34"},{"__ref":"Paragraph:95a88e34a47d_35"},{"__ref":"Paragraph:95a88e34a47d_36"},{"__ref":"Paragraph:95a88e34a47d_37"},{"__ref":"Paragraph:95a88e34a47d_38"},{"__ref":"Paragraph:95a88e34a47d_39"},{"__ref":"Paragraph:95a88e34a47d_40"},{"__ref":"Paragraph:95a88e34a47d_41"},{"__ref":"Paragraph:95a88e34a47d_42"},{"__ref":"Paragraph:95a88e34a47d_43"},{"__ref":"Paragraph:95a88e34a47d_44"},{"__ref":"Paragraph:95a88e34a47d_45"},{"__ref":"Paragraph:95a88e34a47d_46"},{"__ref":"Paragraph:95a88e34a47d_47"},{"__ref":"Paragraph:95a88e34a47d_48"},{"__ref":"Paragraph:95a88e34a47d_49"},{"__ref":"Paragraph:95a88e34a47d_50"},{"__ref":"Paragraph:95a88e34a47d_51"},{"__ref":"Paragraph:95a88e34a47d_52"},{"__ref":"Paragraph:95a88e34a47d_53"},{"__ref":"Paragraph:95a88e34a47d_54"},{"__ref":"Paragraph:95a88e34a47d_55"},{"__ref":"Paragraph:95a88e34a47d_56"},{"__ref":"Paragraph:95a88e34a47d_57"},{"__ref":"Paragraph:95a88e34a47d_58"},{"__ref":"Paragraph:95a88e34a47d_59"},{"__ref":"Paragraph:95a88e34a47d_60"},{"__ref":"Paragraph:95a88e34a47d_61"},{"__ref":"Paragraph:95a88e34a47d_62"},{"__ref":"Paragraph:95a88e34a47d_63"},{"__ref":"Paragraph:95a88e34a47d_64"},{"__ref":"Paragraph:95a88e34a47d_65"},{"__ref":"Paragraph:95a88e34a47d_66"},{"__ref":"Paragraph:95a88e34a47d_67"},{"__ref":"Paragraph:95a88e34a47d_68"},{"__ref":"Paragraph:95a88e34a47d_69"},{"__ref":"Paragraph:95a88e34a47d_70"},{"__ref":"Paragraph:95a88e34a47d_71"},{"__ref":"Paragraph:95a88e34a47d_72"},{"__ref":"Paragraph:95a88e34a47d_73"},{"__ref":"Paragraph:95a88e34a47d_74"},{"__ref":"Paragraph:95a88e34a47d_75"},{"__ref":"Paragraph:95a88e34a47d_76"},{"__ref":"Paragraph:95a88e34a47d_77"},{"__ref":"Paragraph:95a88e34a47d_78"},{"__ref":"Paragraph:95a88e34a47d_79"},{"__ref":"Paragraph:95a88e34a47d_80"},{"__ref":"Paragraph:95a88e34a47d_81"},{"__ref":"Paragraph:95a88e34a47d_82"},{"__ref":"Paragraph:95a88e34a47d_83"},{"__ref":"Paragraph:95a88e34a47d_84"},{"__ref":"Paragraph:95a88e34a47d_85"},{"__ref":"Paragraph:95a88e34a47d_86"},{"__ref":"Paragraph:95a88e34a47d_87"},{"__ref":"Paragraph:95a88e34a47d_88"},{"__ref":"Paragraph:95a88e34a47d_89"},{"__ref":"Paragraph:95a88e34a47d_90"},{"__ref":"Paragraph:95a88e34a47d_91"},{"__ref":"Paragraph:95a88e34a47d_92"},{"__ref":"Paragraph:95a88e34a47d_93"},{"__ref":"Paragraph:95a88e34a47d_94"},{"__ref":"Paragraph:95a88e34a47d_95"},{"__ref":"Paragraph:95a88e34a47d_96"},{"__ref":"Paragraph:95a88e34a47d_97"},{"__ref":"Paragraph:95a88e34a47d_98"},{"__ref":"Paragraph:95a88e34a47d_99"},{"__ref":"Paragraph:95a88e34a47d_100"},{"__ref":"Paragraph:95a88e34a47d_101"},{"__ref":"Paragraph:95a88e34a47d_102"},{"__ref":"Paragraph:95a88e34a47d_103"},{"__ref":"Paragraph:95a88e34a47d_104"},{"__ref":"Paragraph:95a88e34a47d_105"},{"__ref":"Paragraph:95a88e34a47d_106"},{"__ref":"Paragraph:95a88e34a47d_107"},{"__ref":"Paragraph:95a88e34a47d_108"},{"__ref":"Paragraph:95a88e34a47d_109"},{"__ref":"Paragraph:95a88e34a47d_110"},{"__ref":"Paragraph:95a88e34a47d_111"},{"__ref":"Paragraph:95a88e34a47d_112"},{"__ref":"Paragraph:95a88e34a47d_113"},{"__ref":"Paragraph:95a88e34a47d_114"},{"__ref":"Paragraph:95a88e34a47d_115"},{"__ref":"Paragraph:95a88e34a47d_116"},{"__ref":"Paragraph:95a88e34a47d_117"},{"__ref":"Paragraph:95a88e34a47d_118"},{"__ref":"Paragraph:95a88e34a47d_119"},{"__ref":"Paragraph:95a88e34a47d_120"},{"__ref":"Paragraph:95a88e34a47d_121"},{"__ref":"Paragraph:95a88e34a47d_122"},{"__ref":"Paragraph:95a88e34a47d_123"},{"__ref":"Paragraph:95a88e34a47d_124"},{"__ref":"Paragraph:95a88e34a47d_125"},{"__ref":"Paragraph:95a88e34a47d_126"},{"__ref":"Paragraph:95a88e34a47d_127"},{"__ref":"Paragraph:95a88e34a47d_128"},{"__ref":"Paragraph:95a88e34a47d_129"},{"__ref":"Paragraph:95a88e34a47d_130"},{"__ref":"Paragraph:95a88e34a47d_131"},{"__ref":"Paragraph:95a88e34a47d_132"},{"__ref":"Paragraph:95a88e34a47d_133"},{"__ref":"Paragraph:95a88e34a47d_134"},{"__ref":"Paragraph:95a88e34a47d_135"},{"__ref":"Paragraph:95a88e34a47d_136"},{"__ref":"Paragraph:95a88e34a47d_137"},{"__ref":"Paragraph:95a88e34a47d_138"},{"__ref":"Paragraph:95a88e34a47d_139"},{"__ref":"Paragraph:95a88e34a47d_140"},{"__ref":"Paragraph:95a88e34a47d_141"},{"__ref":"Paragraph:95a88e34a47d_142"},{"__ref":"Paragraph:95a88e34a47d_143"},{"__ref":"Paragraph:95a88e34a47d_144"},{"__ref":"Paragraph:95a88e34a47d_145"},{"__ref":"Paragraph:95a88e34a47d_146"},{"__ref":"Paragraph:95a88e34a47d_147"},{"__ref":"Paragraph:95a88e34a47d_148"},{"__ref":"Paragraph:95a88e34a47d_149"},{"__ref":"Paragraph:95a88e34a47d_150"},{"__ref":"Paragraph:95a88e34a47d_151"},{"__ref":"Paragraph:95a88e34a47d_152"},{"__ref":"Paragraph:95a88e34a47d_153"},{"__ref":"Paragraph:95a88e34a47d_154"},{"__ref":"Paragraph:95a88e34a47d_155"},{"__ref":"Paragraph:95a88e34a47d_156"},{"__ref":"Paragraph:95a88e34a47d_157"},{"__ref":"Paragraph:95a88e34a47d_158"},{"__ref":"Paragraph:95a88e34a47d_159"},{"__ref":"Paragraph:95a88e34a47d_160"},{"__ref":"Paragraph:95a88e34a47d_161"},{"__ref":"Paragraph:95a88e34a47d_162"},{"__ref":"Paragraph:95a88e34a47d_163"},{"__ref":"Paragraph:95a88e34a47d_164"},{"__ref":"Paragraph:95a88e34a47d_165"},{"__ref":"Paragraph:95a88e34a47d_166"},{"__ref":"Paragraph:95a88e34a47d_167"},{"__ref":"Paragraph:95a88e34a47d_168"},{"__ref":"Paragraph:95a88e34a47d_169"},{"__ref":"Paragraph:95a88e34a47d_170"},{"__ref":"Paragraph:95a88e34a47d_171"},{"__ref":"Paragraph:95a88e34a47d_172"},{"__ref":"Paragraph:95a88e34a47d_173"},{"__ref":"Paragraph:95a88e34a47d_174"},{"__ref":"Paragraph:95a88e34a47d_175"},{"__ref":"Paragraph:95a88e34a47d_176"},{"__ref":"Paragraph:95a88e34a47d_177"},{"__ref":"Paragraph:95a88e34a47d_178"},{"__ref":"Paragraph:95a88e34a47d_179"},{"__ref":"Paragraph:95a88e34a47d_180"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:741c1c8fcfbd"},"inResponseToEntityType":null,"isLocked":true,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_UGC","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fcatch-up-on-large-language-models-8daf784f46f8","primaryTopic":{"__ref":"Topic:1af65db9c2f8"},"topics":[{"__typename":"Topic","slug":"artificial-intelligence"},{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"data-science"}],"isPublished":true,"latestPublishedVersion":"95a88e34a47d","visibility":"LOCKED","postResponses":{"__typename":"PostResponses","count":2},"createdAt":1693174829059,"firstPublishedAt":1693908161832,"latestPublishedAt":1693923162987,"clapCount":144,"allowResponses":true,"isLimitedState":false,"title":"Catch Up On Large Language Models","isSeries":false,"sequence":null,"uniqueSlug":"catch-up-on-large-language-models-8daf784f46f8","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","readingTime":14.030188679245283,"previewContent":{"__typename":"PreviewContent","subtitle":"A practical guide to large language models without the hype"},"previewImage":{"__ref":"ImageMetadata:0*0sgM1HGAs_IcVD2U"},"isShortform":false,"seoTitle":"","updatedAt":1694283386089,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:artificial-intelligence"},{"__ref":"Tag:nlp"},{"__ref":"Tag:large-language-models"},{"__ref":"Tag:deep-learning"},{"__ref":"Tag:editors-pick"}],"pendingCollection":null,"statusForCollection":"APPROVED","layerCake":6,"detectedLanguage":"en","wordCount":3294,"inResponseToPostResult":null,"inResponseToCatalogResult":null,"curationEligibleAt":1693858298683,"isNewsletter":false,"isPublishToEmail":true},"ImageMetadata:0*4rpR5yY-wfW_78IL":{"__typename":"ImageMetadata","id":"0*4rpR5yY-wfW_78IL","focusPercentX":null,"focusPercentY":null,"alt":null},"Post:9fd028a0c9ee":{"__typename":"Post","id":"9fd028a0c9ee","title":"Forecasting Intermittent Time Series in Python","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"A complete guide on intermittent time series forecasting in Python with a capstone project","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:0*4rpR5yY-wfW_78IL"},"creator":{"__ref":"User:741c1c8fcfbd"},"isPublished":true,"mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fforecasting-intermittent-time-series-in-python-9fd028a0c9ee","collection":{"__ref":"Collection:7f60cf5620c9"},"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":1},"visibility":"LOCKED","clapCount":165,"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1691419634080,"firstPublishedAt":1691402513327,"readingTime":14.705660377358491,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"forecasting-intermittent-time-series-in-python-9fd028a0c9ee","content":{"__typename":"PostContent","validatedShareKey":""}},"ImageMetadata:1*Jq9bEbitg1Pv4oASwEQwJg.png":{"__typename":"ImageMetadata","id":"1*Jq9bEbitg1Pv4oASwEQwJg.png","focusPercentX":null,"focusPercentY":null,"alt":null},"User:993c21f1b30f":{"__typename":"User","id":"993c21f1b30f","name":"Heiko Hotz","username":"heiko-hotz","mediumMemberAt":1690055043000,"socialStats":{"__typename":"SocialStats","followerCount":1915},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"heiko-hotz.medium.com"}},"hasSubdomain":true,"bio":"Senior Solutions Architect for Generative AI @ AWS — All opinions are my own","imageId":"1*5VifPxEG2ZkTxCK2m4JcLQ.png","membership":{"__ref":"Membership:6a46231dc033"}},"Membership:6a46231dc033":{"__typename":"Membership","tier":"MEMBER","id":"6a46231dc033"},"Post:94654b1eaba7":{"__typename":"Post","id":"94654b1eaba7","title":"RAG vs Finetuning — Which Is the Best Tool to Boost Your LLM Application?","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"The definitive guide for choosing the right method for your use case","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:1*Jq9bEbitg1Pv4oASwEQwJg.png"},"creator":{"__ref":"User:993c21f1b30f"},"isPublished":true,"mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Frag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7","collection":{"__ref":"Collection:7f60cf5620c9"},"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":16},"visibility":"LOCKED","clapCount":1902,"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1693315571966,"firstPublishedAt":1692908254317,"readingTime":18.27672955974843,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7","content":{"__typename":"PostContent","validatedShareKey":""}},"ImageMetadata:1*SO1Nys1yLSFX9Ka-tOoR8A.png":{"__typename":"ImageMetadata","id":"1*SO1Nys1yLSFX9Ka-tOoR8A.png","focusPercentX":null,"focusPercentY":null,"alt":"Man in a room holding a book and ethereal computation on the walls"},"User:e039aa8b7221":{"__typename":"User","id":"e039aa8b7221","name":"Giuseppe Scalamogna","username":"hominum_universalis","mediumMemberAt":1633697809000,"socialStats":{"__typename":"SocialStats","followerCount":285},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"AI\u002FBlockchain\u002FInnovation Enthusiast • Strategic Advisor\u002FPlatform Architect @ Project Moon Hut Foundation","imageId":"1*-G8aVXnU_tDQVRDkJ4PtCA@2x.jpeg","membership":{"__ref":"Membership:ccb15d1abbea"}},"Membership:ccb15d1abbea":{"__typename":"Membership","tier":"MEMBER","id":"ccb15d1abbea"},"Post:56f49746aa7b":{"__typename":"Post","id":"56f49746aa7b","title":"New ChatGPT Prompt Engineering Technique: Program Simulation","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"A potentially novel technique for turning a ChatGPT prompt into a mini-app.","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:1*SO1Nys1yLSFX9Ka-tOoR8A.png"},"creator":{"__ref":"User:e039aa8b7221"},"isPublished":true,"mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fnew-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b","collection":{"__ref":"Collection:7f60cf5620c9"},"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":11},"visibility":"PUBLIC","clapCount":1055,"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1693920023703,"firstPublishedAt":1693772292141,"readingTime":8.406603773584905,"isLocked":false,"sequence":null,"isSeries":false,"uniqueSlug":"new-chatgpt-prompt-engineering-technique-program-simulation-56f49746aa7b","content":{"__typename":"PostContent","validatedShareKey":""}},"ImageMetadata:1*9xhiP7nD8Ur2c3nrnApQkQ.jpeg":{"__typename":"ImageMetadata","id":"1*9xhiP7nD8Ur2c3nrnApQkQ.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"Post:70d476bfe775":{"__typename":"Post","id":"70d476bfe775","title":"The Complete Guide to Time Series Analysis and Forecasting","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Understand moving average, exponential smoothing, stationarity, autocorrelation, SARIMA, and apply these techniques in two projects.","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:1*9xhiP7nD8Ur2c3nrnApQkQ.jpeg"},"creator":{"__ref":"User:741c1c8fcfbd"},"isPublished":true,"mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fthe-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775","collection":{"__ref":"Collection:7f60cf5620c9"},"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":18},"visibility":"LOCKED","clapCount":3334,"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1687886035487,"firstPublishedAt":1565181061296,"readingTime":12.928301886792454,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775","content":{"__typename":"PostContent","validatedShareKey":""}},"ImageMetadata:1*3FtLa-nHJB8KOb-Wu9bqbg.png":{"__typename":"ImageMetadata","id":"1*3FtLa-nHJB8KOb-Wu9bqbg.png","focusPercentX":null,"focusPercentY":null,"alt":null},"User:4a25c00139e6":{"__typename":"User","id":"4a25c00139e6","name":"AL Anany","username":"alanany","mediumMemberAt":1669211356000,"socialStats":{"__typename":"SocialStats","followerCount":17942},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":true},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"entreprenal.com"}},"hasSubdomain":true,"bio":"96% Of My Time Is Invested In My Newsletter → alanany.com | Entrepreneurship | CEO @ Albusi GmbH | Zurich, Switzerland | www.albusi.com","imageId":"1*zwwpG0St4jn5uH0VVyjQng.png","membership":{"__ref":"Membership:549e48fdfe29"}},"Membership:549e48fdfe29":{"__typename":"Membership","tier":"MEMBER","id":"549e48fdfe29"},"Post:426d5e3f7d05":{"__typename":"Post","id":"426d5e3f7d05","title":"The ChatGPT Hype Is Over — Now Watch How Google Will Kill ChatGPT.","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"It never happens instantly. The business game is longer than you know.","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:1*3FtLa-nHJB8KOb-Wu9bqbg.png"},"creator":{"__ref":"User:4a25c00139e6"},"isPublished":true,"mediumUrl":"https:\u002F\u002Fentreprenal.com\u002Fthe-chatgpt-hype-is-over-now-watch-how-google-will-kill-chatgpt-426d5e3f7d05","collection":null,"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":225},"visibility":"LOCKED","clapCount":6896,"pendingCollection":null,"statusForCollection":null,"pinnedAt":0,"latestPublishedAt":1693644346675,"firstPublishedAt":1693584748571,"readingTime":5.44811320754717,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"the-chatgpt-hype-is-over-now-watch-how-google-will-kill-chatgpt-426d5e3f7d05","content":{"__typename":"PostContent","validatedShareKey":""}},"ImageMetadata:1*d6yWsvLaLTfieYQP5lQf6w.jpeg":{"__typename":"ImageMetadata","id":"1*d6yWsvLaLTfieYQP5lQf6w.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"User:28aa6026c553":{"__typename":"User","id":"28aa6026c553","name":"Cameron R. Wolfe, Ph.D.","username":"wolfecameron","mediumMemberAt":1651663487000,"socialStats":{"__typename":"SocialStats","followerCount":3122},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"wolfecameron.medium.com"}},"hasSubdomain":true,"bio":"Director of AI @ Rebuy • Deep Learning Ph.D. • I make AI understandable","imageId":"1*wv4savxpgdp3RXjMrCYrXQ.png","membership":{"__ref":"Membership:7c6a23c6f777"}},"Membership:7c6a23c6f777":{"__typename":"Membership","tier":"MEMBER","id":"7c6a23c6f777"},"Post:f07f9e55fe01":{"__typename":"Post","id":"f07f9e55fe01","title":"Advanced Prompt Engineering","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"What to do when few-shot learning isn’t enough…","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:1*d6yWsvLaLTfieYQP5lQf6w.jpeg"},"creator":{"__ref":"User:28aa6026c553"},"isPublished":true,"mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fadvanced-prompt-engineering-f07f9e55fe01","collection":{"__ref":"Collection:7f60cf5620c9"},"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":11},"visibility":"LOCKED","clapCount":1363,"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1691418248329,"firstPublishedAt":1691418248329,"readingTime":16.59245283018868,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"advanced-prompt-engineering-f07f9e55fe01","content":{"__typename":"PostContent","validatedShareKey":""}},"ImageMetadata:1*RFS-lLJhNbaJOZoE9sOCwA.png":{"__typename":"ImageMetadata","id":"1*RFS-lLJhNbaJOZoE9sOCwA.png","focusPercentX":null,"focusPercentY":null,"alt":"Google Bert"},"User:b4f876ff8ab2":{"__typename":"User","id":"b4f876ff8ab2","name":"Rayyan Shaikh","username":"shaikhrayyan123","mediumMemberAt":0,"socialStats":{"__typename":"SocialStats","followerCount":133},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"Python | Backend Development | Web Application & API Development 🖥️🌐 | Data Analytics 📊 Scraping | Automation 🤖 | Startup 💡 | Digital Marketing💼🌟","imageId":"0*4GQ2Vm8ARj9hsvGt","membership":null},"Post:2379699e2b51":{"__typename":"Post","id":"2379699e2b51","title":"Mastering BERT: A Comprehensive Guide from Beginner to Advanced in Natural Language Processing…","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Introduction: A Guide to Unlocking BERT: From Beginner to Expert","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:1*RFS-lLJhNbaJOZoE9sOCwA.png"},"creator":{"__ref":"User:b4f876ff8ab2"},"isPublished":true,"mediumUrl":"https:\u002F\u002Fmedium.com\u002F@shaikhrayyan123\u002Fa-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51","collection":null,"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":13},"visibility":"PUBLIC","clapCount":917,"pendingCollection":null,"statusForCollection":null,"pinnedAt":0,"latestPublishedAt":1693300847895,"firstPublishedAt":1693043053438,"readingTime":18.671069182389935,"isLocked":false,"sequence":null,"isSeries":false,"uniqueSlug":"a-comprehensive-guide-to-understanding-bert-from-beginners-to-advanced-2379699e2b51","content":{"__typename":"PostContent","validatedShareKey":""}},"ImageMetadata:1*X0OFyPTgHIntKjgf87nyZA.png":{"__typename":"ImageMetadata","id":"1*X0OFyPTgHIntKjgf87nyZA.png","focusPercentX":null,"focusPercentY":null,"alt":null},"User:859af34925b7":{"__typename":"User","id":"859af34925b7","name":"Youssef Hosni","username":"yousefhosni","mediumMemberAt":1691325938000,"socialStats":{"__typename":"SocialStats","followerCount":16762},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"yousefhosni.medium.com"}},"hasSubdomain":true,"bio":"Computer Vision Researcher & Data Scientist | My Newsletter: https:\u002F\u002Fyoussefh.substack.com\u002F | Mentoring Services & E-Products: https:\u002F\u002Ftopmate.io\u002Fyoussef_hosni","imageId":"1*cBxasbWXomjJrHV2_Fh8zw.jpeg","membership":{"__ref":"Membership:9f31e95e23a2"}},"Collection:5517fd7b58a6":{"__typename":"Collection","id":"5517fd7b58a6","slug":"gitconnected","name":"Level Up Coding","domain":"levelup.gitconnected.com","description":"Coding tutorials and news. The developer homepage gitconnected.com && skilled.dev && levelup.dev","subscriberCount":92576,"avatar":{"__ref":"ImageMetadata:1*5D9oYBd58pyjMkV_5-zXXQ.jpeg"}},"Membership:9f31e95e23a2":{"__typename":"Membership","tier":"MEMBER","id":"9f31e95e23a2"},"ImageMetadata:1*5D9oYBd58pyjMkV_5-zXXQ.jpeg":{"__typename":"ImageMetadata","id":"1*5D9oYBd58pyjMkV_5-zXXQ.jpeg"},"Post:d7b83f94c4e":{"__typename":"Post","id":"d7b83f94c4e","title":"Top Large Language Models (LLMs) Interview Questions & Answers","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Demystifying Large Language Models (LLMs): Key Interview Questions and Expert Answers","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:1*X0OFyPTgHIntKjgf87nyZA.png"},"creator":{"__ref":"User:859af34925b7"},"isPublished":true,"mediumUrl":"https:\u002F\u002Flevelup.gitconnected.com\u002Ftop-large-language-models-llms-interview-questions-answers-d7b83f94c4e","collection":{"__ref":"Collection:5517fd7b58a6"},"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":3},"visibility":"LOCKED","clapCount":470,"pendingCollection":null,"statusForCollection":"APPROVED","pinnedAt":0,"latestPublishedAt":1693907857659,"firstPublishedAt":1693907857659,"readingTime":41.22641509433963,"isLocked":true,"sequence":null,"isSeries":false,"uniqueSlug":"top-large-language-models-llms-interview-questions-answers-d7b83f94c4e","content":{"__typename":"PostContent","validatedShareKey":""}},"ImageMetadata:1*xF5PSuatJOncVIF2EUP-jg.jpeg":{"__typename":"ImageMetadata","id":"1*xF5PSuatJOncVIF2EUP-jg.jpeg","focusPercentX":null,"focusPercentY":null,"alt":null},"User:757310c731ab":{"__typename":"User","id":"757310c731ab","name":"Nick Hilton","username":"nickfthilton","mediumMemberAt":1628151146000,"socialStats":{"__typename":"SocialStats","followerCount":52928},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":{"__typename":"CustomDomainState","live":{"__typename":"CustomDomain","domain":"nickfthilton.medium.com"}},"hasSubdomain":true,"bio":"Writer. Media entrepreneur. London. Interested in technology and the media. Co-founder podotpods.com Email: nick@podotpods.com.","imageId":"2*rK52B7-RuC6qsXN1rrHtcw.jpeg","membership":{"__ref":"Membership:ba8977bfc439"}},"Membership:ba8977bfc439":{"__typename":"Membership","tier":"MEMBER","id":"ba8977bfc439"},"Post:ed197f252c6a":{"__typename":"Post","id":"ed197f252c6a","title":"The End of the Subscription Era is Coming","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"You’re overpaying for your porn (and journalism)","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:1*xF5PSuatJOncVIF2EUP-jg.jpeg"},"creator":{"__ref":"User:757310c731ab"},"isPublished":true,"mediumUrl":"https:\u002F\u002Fnickfthilton.medium.com\u002Fthe-end-of-the-subscription-era-is-coming-ed197f252c6a","collection":null,"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":191},"visibility":"PUBLIC","clapCount":10190,"pendingCollection":null,"statusForCollection":null,"pinnedAt":0,"latestPublishedAt":1693402214752,"firstPublishedAt":1693402214752,"readingTime":9.636163522012579,"isLocked":false,"sequence":null,"isSeries":false,"uniqueSlug":"the-end-of-the-subscription-era-is-coming-ed197f252c6a","content":{"__typename":"PostContent","validatedShareKey":""}},"ImageMetadata:1*Wj6mJ7SvnfJturBYGtZ-vQ.png":{"__typename":"ImageMetadata","id":"1*Wj6mJ7SvnfJturBYGtZ-vQ.png","focusPercentX":null,"focusPercentY":null,"alt":null},"User:953df644ac5a":{"__typename":"User","id":"953df644ac5a","name":"Sachin Kulkarni","username":"Sachin.Kulkarni.NL","mediumMemberAt":0,"socialStats":{"__typename":"SocialStats","followerCount":53},"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"customDomainState":null,"hasSubdomain":false,"bio":"Experienced Banker turned Senior Solutions Architect at AWS. Creates business solutions by using latest technologies (Cloud, AI\u002FML) and banking domain knowledge","imageId":"1*ymKe7pqq11CT2fLERt8RRA.jpeg","membership":null},"Post:3c81a8bffaf2":{"__typename":"Post","id":"3c81a8bffaf2","title":"Generative AI with Enterprise Data","extendedPreviewContent":{"__typename":"PreviewContent","subtitle":"Create business value add Enterprise knowledge to Large Language Models","isFullContent":false},"previewImage":{"__ref":"ImageMetadata:1*Wj6mJ7SvnfJturBYGtZ-vQ.png"},"creator":{"__ref":"User:953df644ac5a"},"isPublished":true,"mediumUrl":"https:\u002F\u002Fmedium.com\u002F@Sachin.Kulkarni.NL\u002Fgenerative-ai-with-enterprise-data-3c81a8bffaf2","collection":null,"isLimitedState":false,"allowResponses":true,"postResponses":{"__typename":"PostResponses","count":5},"visibility":"PUBLIC","clapCount":191,"pendingCollection":null,"statusForCollection":null,"pinnedAt":0,"latestPublishedAt":1690311306458,"firstPublishedAt":1690291871209,"readingTime":5.458490566037736,"isLocked":false,"sequence":null,"isSeries":false,"uniqueSlug":"generative-ai-with-enterprise-data-3c81a8bffaf2","content":{"__typename":"PostContent","validatedShareKey":""}},"User:2eb23a991a63":{"__typename":"User","username":"AMGAS14","id":"2eb23a991a63"},"CatalogViewerEdge:catalogId:0a856388a93a-viewerId:lo_f623f4931b0c":{"__typename":"CatalogViewerEdge","followersCount":224,"id":"catalogId:0a856388a93a-viewerId:lo_f623f4931b0c"},"ImageMetadata:0*fJ9bDkUv2rDzGR9H.png":{"__typename":"ImageMetadata","id":"0*fJ9bDkUv2rDzGR9H.png","alt":null},"Post:52e635bea8ff":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*fJ9bDkUv2rDzGR9H.png"},"id":"52e635bea8ff"},"CatalogItemV2:{\"catalogItemId\":\"650706db27c1fe7f1164a056\"}":{"__typename":"CatalogItemV2","catalogItemId":"650706db27c1fe7f1164a056","entity":{"__ref":"Post:52e635bea8ff"}},"ImageMetadata:1*uGiG0jByu8VRexukk_JYyg.png":{"__typename":"ImageMetadata","id":"1*uGiG0jByu8VRexukk_JYyg.png","alt":null},"Post:df8646884390":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*uGiG0jByu8VRexukk_JYyg.png"},"id":"df8646884390"},"CatalogItemV2:{\"catalogItemId\":\"65057fa0a2291585ed9840fe\"}":{"__typename":"CatalogItemV2","catalogItemId":"65057fa0a2291585ed9840fe","entity":{"__ref":"Post:df8646884390"}},"ImageMetadata:0*L2JMa5UKK9Cmo9LG":{"__typename":"ImageMetadata","id":"0*L2JMa5UKK9Cmo9LG","alt":null},"Post:552701be8f4e":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*L2JMa5UKK9Cmo9LG"},"id":"552701be8f4e"},"CatalogItemV2:{\"catalogItemId\":\"65057f68303ebc7894ed97f1\"}":{"__typename":"CatalogItemV2","catalogItemId":"65057f68303ebc7894ed97f1","entity":{"__ref":"Post:552701be8f4e"}},"ImageMetadata:1*96oDmNryS7NDrry544aZ3Q.jpeg":{"__typename":"ImageMetadata","id":"1*96oDmNryS7NDrry544aZ3Q.jpeg","alt":null},"Post:6d8095c23322":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*96oDmNryS7NDrry544aZ3Q.jpeg"},"id":"6d8095c23322"},"CatalogItemV2:{\"catalogItemId\":\"65057d3972b56806bad0a5f1\"}":{"__typename":"CatalogItemV2","catalogItemId":"65057d3972b56806bad0a5f1","entity":{"__ref":"Post:6d8095c23322"}},"ImageMetadata:1*NaiWaewul-IkJfWK2P8AXQ.png":{"__typename":"ImageMetadata","id":"1*NaiWaewul-IkJfWK2P8AXQ.png","alt":null},"Post:1e9fa9ec7a5b":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*NaiWaewul-IkJfWK2P8AXQ.png"},"id":"1e9fa9ec7a5b"},"CatalogItemV2:{\"catalogItemId\":\"650431788233bdd3a550b8e7\"}":{"__typename":"CatalogItemV2","catalogItemId":"650431788233bdd3a550b8e7","entity":{"__ref":"Post:1e9fa9ec7a5b"}},"Catalog:0a856388a93a":{"__typename":"Catalog","id":"0a856388a93a","name":"Natural Language Processing","postItemsCount":608,"predefined":null,"creator":{"__ref":"User:2eb23a991a63"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:0a856388a93a-viewerId:lo_f623f4931b0c"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"650706db27c1fe7f1164a056\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"65057fa0a2291585ed9840fe\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"65057f68303ebc7894ed97f1\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"65057d3972b56806bad0a5f1\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"650431788233bdd3a550b8e7\"}"}]}},"User:a32c340ea342":{"__typename":"User","username":"MediumStaff","id":"a32c340ea342"},"CatalogViewerEdge:catalogId:dfa78dfd2438-viewerId:lo_f623f4931b0c":{"__typename":"CatalogViewerEdge","followersCount":122,"id":"catalogId:dfa78dfd2438-viewerId:lo_f623f4931b0c"},"ImageMetadata:1*era76EGCwdY2gWSFKutuSw.jpeg":{"__typename":"ImageMetadata","id":"1*era76EGCwdY2gWSFKutuSw.jpeg","alt":null},"Post:692c9842967b":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*era76EGCwdY2gWSFKutuSw.jpeg"},"id":"692c9842967b"},"CatalogItemV2:{\"catalogItemId\":\"64874f7d13d6e4dc5c530fc7\"}":{"__typename":"CatalogItemV2","catalogItemId":"64874f7d13d6e4dc5c530fc7","entity":{"__ref":"Post:692c9842967b"}},"ImageMetadata:1*AiTJDz5wwQFiUCf_SrBOQA.jpeg":{"__typename":"ImageMetadata","id":"1*AiTJDz5wwQFiUCf_SrBOQA.jpeg","alt":null},"Post:d0ca0d31ce80":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*AiTJDz5wwQFiUCf_SrBOQA.jpeg"},"id":"d0ca0d31ce80"},"CatalogItemV2:{\"catalogItemId\":\"64874495588355c03fb56000\"}":{"__typename":"CatalogItemV2","catalogItemId":"64874495588355c03fb56000","entity":{"__ref":"Post:d0ca0d31ce80"}},"ImageMetadata:1*zjPggFS8yoRtFbAP9R_3lw.jpeg":{"__typename":"ImageMetadata","id":"1*zjPggFS8yoRtFbAP9R_3lw.jpeg","alt":"A phone with a tweet on it describing a deepfake video of the Ukrainian president, with a labeled fake image in the background"},"Post:99a5b134502d":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*zjPggFS8yoRtFbAP9R_3lw.jpeg"},"id":"99a5b134502d"},"CatalogItemV2:{\"catalogItemId\":\"6487451a9b33cddec92ea632\"}":{"__typename":"CatalogItemV2","catalogItemId":"6487451a9b33cddec92ea632","entity":{"__ref":"Post:99a5b134502d"}},"ImageMetadata:0*if6GAXPQPCMY5v26":{"__typename":"ImageMetadata","id":"0*if6GAXPQPCMY5v26","alt":null},"Post:2eef9f75a5d9":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*if6GAXPQPCMY5v26"},"id":"2eef9f75a5d9"},"CatalogItemV2:{\"catalogItemId\":\"648744acc92d2e56166f2b70\"}":{"__typename":"CatalogItemV2","catalogItemId":"648744acc92d2e56166f2b70","entity":{"__ref":"Post:2eef9f75a5d9"}},"ImageMetadata:1*Md22IugtRlCB_bNnQEFmZQ.jpeg":{"__typename":"ImageMetadata","id":"1*Md22IugtRlCB_bNnQEFmZQ.jpeg","alt":null},"Post:17d954024454":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*Md22IugtRlCB_bNnQEFmZQ.jpeg"},"id":"17d954024454"},"CatalogItemV2:{\"catalogItemId\":\"648744b89b33cddec92ea62e\"}":{"__typename":"CatalogItemV2","catalogItemId":"648744b89b33cddec92ea62e","entity":{"__ref":"Post:17d954024454"}},"Catalog:dfa78dfd2438":{"__typename":"Catalog","id":"dfa78dfd2438","name":"AI Regulation","postItemsCount":6,"predefined":null,"creator":{"__ref":"User:a32c340ea342"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:dfa78dfd2438-viewerId:lo_f623f4931b0c"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"64874f7d13d6e4dc5c530fc7\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"64874495588355c03fb56000\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6487451a9b33cddec92ea632\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"648744acc92d2e56166f2b70\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"648744b89b33cddec92ea62e\"}"}]}},"User:eccabb7a94a0":{"__typename":"User","username":"nicholas.michael.janulewicz","id":"eccabb7a94a0"},"CatalogViewerEdge:catalogId:b4c47b8e12ee-viewerId:lo_f623f4931b0c":{"__typename":"CatalogViewerEdge","followersCount":383,"id":"catalogId:b4c47b8e12ee-viewerId:lo_f623f4931b0c"},"ImageMetadata:1*GHhSZx4-tYPOYtYojjwdAQ.jpeg":{"__typename":"ImageMetadata","id":"1*GHhSZx4-tYPOYtYojjwdAQ.jpeg","alt":null},"Post:15820678bc02":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*GHhSZx4-tYPOYtYojjwdAQ.jpeg"},"id":"15820678bc02"},"CatalogItemV2:{\"catalogItemId\":\"64ce2fd5e516caed08194475\"}":{"__typename":"CatalogItemV2","catalogItemId":"64ce2fd5e516caed08194475","entity":{"__ref":"Post:15820678bc02"}},"ImageMetadata:1*efsUAIea1J-UOIVLMD24ng.png":{"__typename":"ImageMetadata","id":"1*efsUAIea1J-UOIVLMD24ng.png","alt":null},"Post:445939e3833d":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*efsUAIea1J-UOIVLMD24ng.png"},"id":"445939e3833d"},"CatalogItemV2:{\"catalogItemId\":\"64c9f0dfdae530eec4a72dc0\"}":{"__typename":"CatalogItemV2","catalogItemId":"64c9f0dfdae530eec4a72dc0","entity":{"__ref":"Post:445939e3833d"}},"ImageMetadata:1*eX8r1Ctk5BCrKgtZ15YxKA.jpeg":{"__typename":"ImageMetadata","id":"1*eX8r1Ctk5BCrKgtZ15YxKA.jpeg","alt":null},"Post:c20ce9be3824":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*eX8r1Ctk5BCrKgtZ15YxKA.jpeg"},"id":"c20ce9be3824"},"CatalogItemV2:{\"catalogItemId\":\"64b4e0b4dc4e05c00bde6568\"}":{"__typename":"CatalogItemV2","catalogItemId":"64b4e0b4dc4e05c00bde6568","entity":{"__ref":"Post:c20ce9be3824"}},"ImageMetadata:1*TbfTSbQtO7R7svdDu_rfrg.jpeg":{"__typename":"ImageMetadata","id":"1*TbfTSbQtO7R7svdDu_rfrg.jpeg","alt":null},"Post:f8cd69e8323b":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*TbfTSbQtO7R7svdDu_rfrg.jpeg"},"id":"f8cd69e8323b"},"CatalogItemV2:{\"catalogItemId\":\"64b249a0242f2c016696f085\"}":{"__typename":"CatalogItemV2","catalogItemId":"64b249a0242f2c016696f085","entity":{"__ref":"Post:f8cd69e8323b"}},"ImageMetadata:1*62Sy4hG4ah0-yjppBxmcfw.jpeg":{"__typename":"ImageMetadata","id":"1*62Sy4hG4ah0-yjppBxmcfw.jpeg","alt":null},"Post:11abe5bf0487":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*62Sy4hG4ah0-yjppBxmcfw.jpeg"},"id":"11abe5bf0487"},"CatalogItemV2:{\"catalogItemId\":\"64b0e24ddb30a1381f61ba4d\"}":{"__typename":"CatalogItemV2","catalogItemId":"64b0e24ddb30a1381f61ba4d","entity":{"__ref":"Post:11abe5bf0487"}},"Catalog:b4c47b8e12ee":{"__typename":"Catalog","id":"b4c47b8e12ee","name":"ChatGPT prompts ","postItemsCount":24,"predefined":null,"creator":{"__ref":"User:eccabb7a94a0"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:b4c47b8e12ee-viewerId:lo_f623f4931b0c"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"64ce2fd5e516caed08194475\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"64c9f0dfdae530eec4a72dc0\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"64b4e0b4dc4e05c00bde6568\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"64b249a0242f2c016696f085\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"64b0e24ddb30a1381f61ba4d\"}"}]}},"User:631df0a86316":{"__typename":"User","username":"m.wasalski","id":"631df0a86316"},"CatalogViewerEdge:catalogId:3742c7a4727d-viewerId:lo_f623f4931b0c":{"__typename":"CatalogViewerEdge","followersCount":152,"id":"catalogId:3742c7a4727d-viewerId:lo_f623f4931b0c"},"ImageMetadata:1*dtz5Y7h7Dlc5TURKUUDaYw.gif":{"__typename":"ImageMetadata","id":"1*dtz5Y7h7Dlc5TURKUUDaYw.gif","alt":null},"Post:5e9923016597":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*dtz5Y7h7Dlc5TURKUUDaYw.gif"},"id":"5e9923016597"},"CatalogItemV2:{\"catalogItemId\":\"649c1da6f3135db1c45e3619\"}":{"__typename":"CatalogItemV2","catalogItemId":"649c1da6f3135db1c45e3619","entity":{"__ref":"Post:5e9923016597"}},"ImageMetadata:0*V3E5F6rH0O512mT3":{"__typename":"ImageMetadata","id":"0*V3E5F6rH0O512mT3","alt":null},"Post:7e98ca368410":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*V3E5F6rH0O512mT3"},"id":"7e98ca368410"},"CatalogItemV2:{\"catalogItemId\":\"6498ab12f157497830e6111a\"}":{"__typename":"CatalogItemV2","catalogItemId":"6498ab12f157497830e6111a","entity":{"__ref":"Post:7e98ca368410"}},"ImageMetadata:1*NQmmb6tdLZdSXfYv4Oli4w.png":{"__typename":"ImageMetadata","id":"1*NQmmb6tdLZdSXfYv4Oli4w.png","alt":null},"Post:5c3c95574442":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*NQmmb6tdLZdSXfYv4Oli4w.png"},"id":"5c3c95574442"},"CatalogItemV2:{\"catalogItemId\":\"6498ab0d9140fb1fcfc8ef07\"}":{"__typename":"CatalogItemV2","catalogItemId":"6498ab0d9140fb1fcfc8ef07","entity":{"__ref":"Post:5c3c95574442"}},"ImageMetadata:0*dpM2Yzu6u56rBwf7":{"__typename":"ImageMetadata","id":"0*dpM2Yzu6u56rBwf7","alt":null},"Post:c61d51c105b2":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:0*dpM2Yzu6u56rBwf7"},"id":"c61d51c105b2"},"CatalogItemV2:{\"catalogItemId\":\"64953c9515e3f0e8d0f0c8a1\"}":{"__typename":"CatalogItemV2","catalogItemId":"64953c9515e3f0e8d0f0c8a1","entity":{"__ref":"Post:c61d51c105b2"}},"ImageMetadata:1*Sucvet97XExUTqTnTVBYHA.jpeg":{"__typename":"ImageMetadata","id":"1*Sucvet97XExUTqTnTVBYHA.jpeg","alt":""},"Post:fd892551ee25":{"__typename":"Post","previewImage":{"__ref":"ImageMetadata:1*Sucvet97XExUTqTnTVBYHA.jpeg"},"id":"fd892551ee25"},"CatalogItemV2:{\"catalogItemId\":\"648967a8a9610fc2862ff30a\"}":{"__typename":"CatalogItemV2","catalogItemId":"648967a8a9610fc2862ff30a","entity":{"__ref":"Post:fd892551ee25"}},"Catalog:3742c7a4727d":{"__typename":"Catalog","id":"3742c7a4727d","name":"ChatGPT","postItemsCount":21,"predefined":null,"creator":{"__ref":"User:631df0a86316"},"viewerEdge":{"__ref":"CatalogViewerEdge:catalogId:3742c7a4727d-viewerId:lo_f623f4931b0c"},"itemsConnection:(limit:5)":{"__typename":"CatalogItemsConnection","items":[{"__ref":"CatalogItemV2:{\"catalogItemId\":\"649c1da6f3135db1c45e3619\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6498ab12f157497830e6111a\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"6498ab0d9140fb1fcfc8ef07\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"64953c9515e3f0e8d0f0c8a1\"}"},{"__ref":"CatalogItemV2:{\"catalogItemId\":\"648967a8a9610fc2862ff30a\"}"}]}}}</script><script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/manifest.7f9849e2.js"></script><script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/6036.d874957b.js"></script><script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/main.95b5ba59.js"></script><script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/instrumentation.63e6e68a.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/reporting.2021fe63.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/6068.466148a0.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/4398.780b79a2.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1752.a348f767.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/6733.c6c17f3e.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/4711.eb865124.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/8695.673263b3.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/9662.34febdc6.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/3154.8be4a205.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/5203.972fb599.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1957.8b8ca9f7.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/9599.0edb614e.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1711.6127e5e0.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/5268.340f7f3b.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/9114.0cf8f28e.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/5459.cfc2e69b.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/6804.2f4a4354.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/9174.c5af3983.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/4129.36dc9d8c.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/8580.2dd0c5ae.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1802.266129dd.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/4078.9fb8a750.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/8883.0a827231.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/923.f5e3d4bf.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/2550.97ddfb27.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/9408.f91ba3c5.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1743.4ea74641.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/9150.a9db6cd7.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/5005.fdfae8c9.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/2804.0e74df2c.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/1006.97cfd7bf.chunk.js"></script>
<script src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/PostPage.MainContent.e01dedc3.chunk.js"></script><script>window.main();</script><script defer="defer" src="Catch%20Up%20On%20Large%20Language%20Models%20by%20Marco%20Peixeiro%20Sep,%202023%20Towards%20Data%20Science_pliki/v8b253dfea2ab4077af8c6f58422dfbfd1689876627854" integrity="sha512-bjgnUKX4azu3dLTVtie9u6TKqgx29RBwfj3QXYt5EKfWM/9hPSAI/4qcV5NACjwAo8UtTeWefx6Zq5PHcMm7Tg==" data-cf-beacon="{&quot;rayId&quot;:&quot;80866fea58b84695&quot;,&quot;version&quot;:&quot;2023.8.0&quot;,&quot;b&quot;:1,&quot;token&quot;:&quot;0b5f665943484354a59c39c6833f7078&quot;,&quot;si&quot;:100}" crossorigin="anonymous"></script>
</div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>